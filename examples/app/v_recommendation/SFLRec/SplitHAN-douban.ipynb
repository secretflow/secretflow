{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 任务描述：\n",
    "\n",
    "    •   使用三条元路径的嵌入表示实现电影推荐，解决数据异构问题。\n",
    "    •   预测用户对某电影的潜在兴趣分数（分为高中低三类）\n",
    "    •   生成movie-embedding和user-embedding，以用于下游任务\n",
    "\n",
    "2. 元路径描述：\n",
    "    Alice提供一部分电影特征、用户评分数据，通过共同评分用户构建movie-user-movie元路径。\n",
    "    Bob提供另一部分电影特征、演员数据、导演数据，通过共同演员、共同导演构建movie-actor-movie、movie-director-movie元路径。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "sf.shutdown()\n",
    "sf.init(parties=['alice', 'bob'], address='local', debug_mode=True)\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "\n",
    "agg_mode = 'concat'\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import torch\n",
    "\n",
    "def process_and_save_douban_data(ratings_path, movies_path, movies_features_path, save_dir):\n",
    "    ratings = pd.read_csv(ratings_path, sep=',', engine='python', encoding='utf-8-sig')\n",
    "    movies = pd.read_csv(movies_path, sep=',', engine='python', encoding='utf-8-sig')\n",
    "    movies_features = np.load(movies_features_path, allow_pickle=True).item()\n",
    "\n",
    "    # 求电影 ID 的交集\n",
    "    alice_movie_ids = set(ratings['MOVIE_ID'].unique())\n",
    "    bob_movie_ids = set(movies['MOVIE_ID'].unique())\n",
    "    common_movie_ids = alice_movie_ids & bob_movie_ids\n",
    "\n",
    "    # 检查交集是否非空\n",
    "    if len(common_movie_ids) == 0:\n",
    "        raise ValueError(\"No common movie IDs found between ratings and movies!\")\n",
    "\n",
    "    # 过滤数据，保留交集的电影\n",
    "    ratings = ratings[ratings['MOVIE_ID'].isin(common_movie_ids)]\n",
    "    movies = movies[movies['MOVIE_ID'].isin(common_movie_ids)]\n",
    "\n",
    "    # 编码用户和电影 ID\n",
    "    user_encoder = {user: idx for idx, user in enumerate(ratings['USER_MD5'].unique())}\n",
    "    movie_encoder = {movie: idx for idx, movie in enumerate(movies['MOVIE_ID'].unique())}\n",
    "    \n",
    "    ratings['user_idx'] = ratings['USER_MD5'].map(user_encoder)\n",
    "    ratings['movie_idx'] = ratings['MOVIE_ID'].map(movie_encoder)\n",
    "    movies['movie_idx'] = movies['MOVIE_ID'].map(movie_encoder)\n",
    "    \n",
    "    # 构建电影特征矩阵\n",
    "    num_movies = len(movie_encoder)\n",
    "    movie_feature_matrix = np.zeros((num_movies, len(next(iter(movies_features.values())))))\n",
    "    for movie_id, embedding in movies_features.items():\n",
    "        if movie_id in movie_encoder:\n",
    "            movie_idx = movie_encoder[movie_id]\n",
    "            movie_feature_matrix[movie_idx] = embedding\n",
    "    movie_feature_matrix = torch.FloatTensor(movie_feature_matrix)\n",
    "\n",
    "    # 构建电影-用户元路径 (movie-user-movie)\n",
    "    num_users = len(user_encoder)\n",
    "    movie_user_adj = csr_matrix(\n",
    "        (ratings['RATING'], (ratings['movie_idx'], ratings['user_idx'])),\n",
    "        shape=(num_movies, num_users)\n",
    "    )\n",
    "    meta_path_movie_user_movie = movie_user_adj @ movie_user_adj.T\n",
    "    \n",
    "    # 提取导演和演员信息，将格式像 \"nconst:123|nconst:456|nconst:789\" 这样的字符串列解析为 [123, 456, 789] 的整数 ID 列表\n",
    "    def parse_ids(id_column):\n",
    "        if pd.isna(id_column) or not id_column.strip():\n",
    "            return []\n",
    "        ids = []\n",
    "        for entry in id_column.split('|'):\n",
    "            if ':' in entry:\n",
    "                try:\n",
    "                    ids.append(int(entry.split(':')[-1]))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        return ids\n",
    "\n",
    "    movies['director_ids'] = movies['DIRECTOR_IDS'].apply(parse_ids)\n",
    "    movies['actor_ids'] = movies['ACTOR_IDS'].apply(parse_ids)\n",
    "    \n",
    "    # 确保映射过程完整，所有导演和演员都有对应索引\n",
    "    unique_directors = sorted({d for ids in movies['director_ids'] for d in ids})\n",
    "    unique_actors = sorted({a for ids in movies['actor_ids'] for a in ids})\n",
    "\n",
    "    # 创建导演和演员的映射\n",
    "    director_map = {d: idx for idx, d in enumerate(unique_directors)}\n",
    "    actor_map = {a: idx for idx, a in enumerate(unique_actors)}\n",
    "\n",
    "    # 替换导演和演员 ID 为索引\n",
    "    movies['director_idx'] = movies['director_ids'].apply(lambda ids: [director_map[d] for d in ids if d in director_map])\n",
    "    movies['actor_idx'] = movies['actor_ids'].apply(lambda ids: [actor_map[a] for a in ids if a in actor_map])\n",
    "    # 保存数据\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # 保存映射到文件\n",
    "    with open(os.path.join(save_dir, \"user_idx_mapping.txt\"), \"w\") as f:\n",
    "        for user, idx in user_encoder.items():\n",
    "            f.write(f\"USER_MD5: {user} -> user_idx: {idx}\\n\")\n",
    "\n",
    "    with open(os.path.join(save_dir, \"movie_idx_mapping.txt\"), \"w\") as f:\n",
    "        for movie, idx in movie_encoder.items():\n",
    "            f.write(f\"MOVIE_ID: {movie} -> movie_idx: {idx}\\n\")\n",
    "\n",
    "    with open(os.path.join(save_dir, \"director_idx_mapping.txt\"), \"w\") as f:\n",
    "        for director, idx in director_map.items():\n",
    "            f.write(f\"DIRECTOR_ID: {director} -> director_idx: {idx}\\n\")\n",
    "\n",
    "    with open(os.path.join(save_dir, \"actor_idx_mapping.txt\"), \"w\") as f:\n",
    "        for actor, idx in actor_map.items():\n",
    "            f.write(f\"ACTOR_ID: {actor} -> actor_idx: {idx}\\n\")\n",
    "\n",
    "    # 检查索引是否超出范围\n",
    "    def validate_indices(idx_list, max_dim, label):\n",
    "        for i, ids in idx_list.items():\n",
    "            for idx in ids:\n",
    "                if idx >= max_dim:\n",
    "                    print(f\"Invalid {label} ID {idx} at movie index {i} (max allowed: {max_dim - 1})\")\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    if not validate_indices(movies['director_idx'], len(director_map), \"director\"):\n",
    "        raise ValueError(\"Invalid director indices found!\")\n",
    "    if not validate_indices(movies['actor_idx'], len(actor_map), \"actor\"):\n",
    "        raise ValueError(\"Invalid actor indices found!\")\n",
    "\n",
    "    # 构建电影-导演元路径\n",
    "    director_data = []\n",
    "    director_row = []\n",
    "    director_col = []\n",
    "\n",
    "    for movie_idx, director_ids in enumerate(movies['director_idx']):\n",
    "        for director_idx in director_ids:\n",
    "            director_data.append(1)  # 权重\n",
    "            director_row.append(movie_idx)  # 电影索引\n",
    "            director_col.append(director_idx)  # 导演索引\n",
    "\n",
    "    num_directors = len(director_map)\n",
    "    movie_director_adj = csr_matrix((director_data, (director_row, director_col)), shape=(num_movies, num_directors))\n",
    "    meta_path_movie_director_movie = movie_director_adj @ movie_director_adj.T\n",
    "\n",
    "    # 构建 user-movie 矩阵\n",
    "    user_movie_matrix = csr_matrix(\n",
    "        (ratings['RATING'], (ratings['user_idx'], ratings['movie_idx'])),\n",
    "        shape=(num_users, num_movies)\n",
    "    )\n",
    "    save_path = \"recommend\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # 保存 user-movie 矩阵\n",
    "    user_movie_matrix_path = \"recommend/user_movie_matrix.npz\"\n",
    "    from scipy.sparse import save_npz\n",
    "    save_npz(user_movie_matrix_path, user_movie_matrix)\n",
    "\n",
    "    print(f\"user_movie_matrix shape: {user_movie_matrix.shape}, saved to {user_movie_matrix_path}\")\n",
    "\n",
    "    # 构建电影-演员元路径\n",
    "    actor_data = []\n",
    "    actor_row = []\n",
    "    actor_col = []\n",
    "\n",
    "    for movie_idx, actor_ids in enumerate(movies['actor_idx']):\n",
    "        for actor_idx in actor_ids:\n",
    "            actor_data.append(1)  # 权重\n",
    "            actor_row.append(movie_idx)  # 电影索引\n",
    "            actor_col.append(actor_idx)  # 演员索引\n",
    "\n",
    "    num_actors = len(actor_map)\n",
    "    movie_actor_adj = csr_matrix((actor_data, (actor_row, actor_col)), shape=(num_movies, num_actors))\n",
    "    meta_path_movie_actor_movie = movie_actor_adj @ movie_actor_adj.T\n",
    "    \n",
    "    # 生成标签 (电影平均评分分类)\n",
    "    movie_avg_rating = ratings.groupby('movie_idx')['RATING'].mean()\n",
    "    y = np.zeros(num_movies, dtype=np.int64)\n",
    "    y[movie_avg_rating < 3] = 0  # 低评分\n",
    "    y[(movie_avg_rating >= 3) & (movie_avg_rating < 4)] = 1  # 中评分\n",
    "    y[movie_avg_rating >= 4] = 2  # 高评分\n",
    "    \n",
    "    # 划分训练、验证、测试集\n",
    "    idx_train = np.arange(0, int(0.7 * num_movies))\n",
    "    idx_val = np.arange(int(0.7 * num_movies), int(0.85 * num_movies))\n",
    "    idx_test = np.arange(int(0.85 * num_movies), num_movies)\n",
    "    \n",
    "    y_train = np.zeros_like(y)\n",
    "    y_val = np.zeros_like(y)\n",
    "    y_test = np.zeros_like(y)\n",
    "    \n",
    "    y_train[idx_train] = y[idx_train]\n",
    "    y_val[idx_val] = y[idx_val]\n",
    "    y_test[idx_test] = y[idx_test]\n",
    "\n",
    "    # movie_user_movie存在Alice方，movie_director_movie、movie_actor_movie存在Bob方\n",
    "    meta_path_alice = [meta_path_movie_user_movie]\n",
    "    meta_path_bob = [meta_path_movie_director_movie, meta_path_movie_actor_movie]\n",
    "    # movie_features可以划分一下存放在Alice和Bob作为features_alice和features_bob\n",
    "    features_alice = movie_feature_matrix.numpy()[:, :movie_feature_matrix.shape[1] // 2]\n",
    "    features_bob = movie_feature_matrix.numpy()[:, movie_feature_matrix.shape[1] // 2:]\n",
    "    \n",
    "    saved_files = [\n",
    "        os.path.join(save_dir, name)\n",
    "        for name in [\n",
    "            'meta_path_movie_user_movie.npy',\n",
    "            'meta_path_movie_genre_movie.npy',\n",
    "            'features_alice.npy',\n",
    "            'features_bob.npy',\n",
    "            'y_train.npy',\n",
    "            'y_val.npy',\n",
    "            'y_test.npy',\n",
    "            'idx_train.npy',\n",
    "            'idx_val.npy',\n",
    "            'idx_test.npy',\n",
    "        ]\n",
    "    ]\n",
    "    np.save(saved_files[0], meta_path_alice[0].toarray())\n",
    "    np.save(saved_files[1], meta_path_bob[0].toarray())\n",
    "    np.save(saved_files[2], features_alice)\n",
    "    np.save(saved_files[3], features_bob)\n",
    "    np.save(saved_files[4], y_train)\n",
    "    np.save(saved_files[5], y_val)\n",
    "    np.save(saved_files[6], y_test)\n",
    "    np.save(saved_files[7], idx_train)\n",
    "    np.save(saved_files[8], idx_val)\n",
    "    np.save(saved_files[9], idx_test)\n",
    "    \n",
    "    print(f\"meta_path_movie_user_movie shape: {meta_path_movie_user_movie.shape}\")\n",
    "    print(f\"meta_path_movie_director_movie shape: {meta_path_movie_director_movie.shape}\")\n",
    "    print(f\"meta_path_movie_actor_movie shape: {meta_path_movie_actor_movie.shape}\")\n",
    "    print(f\"movie_features shape: {movie_feature_matrix.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}, y_val shape: {y_val.shape}, y_test shape: {y_test.shape}\")\n",
    "    print(f\"Data saved to {save_dir}\")\n",
    "    return saved_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_movie_matrix shape: (265187, 18810), saved to recommend/user_movie_matrix.npz\n",
      "meta_path_movie_user_movie shape: (18810, 18810)\n",
      "meta_path_movie_director_movie shape: (18810, 18810)\n",
      "meta_path_movie_actor_movie shape: (18810, 18810)\n",
      "movie_features shape: torch.Size([18810, 2996])\n",
      "y_train shape: (18810,), y_val shape: (18810,), y_test shape: (18810,)\n",
      "Data saved to ./saved_files_douban_partitial\n"
     ]
    }
   ],
   "source": [
    "ratings_path = './moviedata_partitial/ratings.csv'\n",
    "movies_path = './moviedata_partitial/movies.csv'\n",
    "movies_features_path = './moviedata_partitial/movie_embeddings_dict.npy'\n",
    "save_dir = './saved_files_douban_partitial'\n",
    "\n",
    "saved_files = process_and_save_douban_data(ratings_path, movies_path, movies_features_path, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape_alice: (18810, 1498), input_shape_bob: (18810, 1498)\n",
      "meta_path alice shape: (18810, 18810), meta_path bob shape: (18810, 18810)\n",
      "y shape alice: (18810,)\n"
     ]
    }
   ],
   "source": [
    "from secretflow.data.ndarray import load\n",
    "\n",
    "meta_path_list = load({alice: saved_files[0], bob: saved_files[1]})\n",
    "features = load({alice: saved_files[2], bob: saved_files[3]})\n",
    "Y_train = load({alice: saved_files[4]})\n",
    "Y_val = load({alice: saved_files[5]})\n",
    "Y_test = load({alice: saved_files[6]})\n",
    "idx_train = load({alice: saved_files[7]})\n",
    "idx_val = load({alice: saved_files[8]})\n",
    "idx_test = load({alice: saved_files[9]})\n",
    "\n",
    "partition_shapes = features.partition_shape()\n",
    "input_shape_alice = partition_shapes[alice]\n",
    "input_shape_bob = partition_shapes[bob]\n",
    "print(f\"input_shape_alice: {input_shape_alice}, input_shape_bob: {input_shape_bob}\")\n",
    "meta_path_shapes = meta_path_list.partition_shape()\n",
    "meta_path_alice_shape = meta_path_shapes[alice]\n",
    "meta_path_bob_shape = meta_path_shapes[bob]\n",
    "print(f\"meta_path alice shape: {meta_path_alice_shape}, meta_path bob shape: {meta_path_bob_shape}\")\n",
    "y_shape = Y_train.partition_shape()\n",
    "y_shape_alice = y_shape[alice]\n",
    "print(f\"y shape alice: {y_shape_alice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.nn.core.torch import BaseModule\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NodeAttentionLayer(BaseModule):\n",
    "    \"\"\"\n",
    "    Adapted from Diego999/pyGAT\n",
    "    \"\"\"\n",
    "    def __init__(self, in_feature_dim, out_feature_dim, dropout, alpha):\n",
    "        super(NodeAttentionLayer, self).__init__()\n",
    "        self.in_feature_dim = in_feature_dim\n",
    "        self.out_feature_dim = out_feature_dim\n",
    "        self.dropout = dropout\n",
    "        # The paper didn't specify but the author used the default 0.2 in tensorflow.\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        self.weight = nn.Parameter(torch.empty(size=(self.in_feature_dim, self.out_feature_dim)))\n",
    "        self.attention_coef = nn.Parameter(torch.empty(size=(self.out_feature_dim * 2, 1)))\n",
    "        # Initiate with the recommended value of the leaky relu with a slope of 0.2.\n",
    "        nn.init.xavier_uniform_(self.weight, gain=1.387)\n",
    "        nn.init.xavier_uniform_(self.attention_coef, gain=1.387)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        Wh = torch.mm(x, self.weight)      # Wh: (N, out_feature_dim)\n",
    "        e = self._prepare_attention(Wh)    # e: (N, N) So this could be seen as an interaction matrix\n",
    "\n",
    "        infneg_vector = -1e12 * torch.ones_like(e)\n",
    "        attention = torch.where(adj > 0, e, infneg_vector)\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        h_prime = torch.matmul(attention, Wh)  # h_prime: (N, out_feature_dim)\n",
    "\n",
    "        return F.elu(h_prime)\n",
    "\n",
    "    def _prepare_attention(self, Wh):\n",
    "        Wh1 = torch.matmul(Wh, self.attention_coef[:self.out_feature_dim, :])  # Wh1 & Wh2: (N, 1)\n",
    "        Wh2 = torch.matmul(Wh, self.attention_coef[self.out_feature_dim:, :])\n",
    "        e = Wh1 + Wh2.T  # Broadcast add\n",
    "\n",
    "        return self.leakyrelu(e)\n",
    "\n",
    "\n",
    "class SemanticAttentionLayer(BaseModule):\n",
    "    def __init__(self, in_feature_dim, q_vector):\n",
    "        super(SemanticAttentionLayer, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.empty(size=(in_feature_dim, q_vector)))\n",
    "        self.bias = nn.Parameter(torch.empty(size=(1, q_vector)))\n",
    "        self.q = nn.Parameter(torch.empty(size=(q_vector, 1)))\n",
    "\n",
    "        # Similarly, the recommended gain value for tanh\n",
    "        nn.init.xavier_uniform_(self.weight, gain=1.667)\n",
    "        nn.init.xavier_uniform_(self.bias, gain=1.667)\n",
    "        nn.init.xavier_uniform_(self.q, gain=1.667)\n",
    "\n",
    "    def forward(self, z):\n",
    "        Wh = torch.matmul(z, self.weight) + self.bias    # z: (N, M, hidden_dim * num_classes)\n",
    "        Wh = F.tanh(Wh)                 # Wh: (N, M, q_vector)\n",
    "        w = torch.matmul(Wh, self.q)    # w: (N, M, 1)\n",
    "        w = w.mean(0)                   # w: (M, 1)\n",
    "        beta = F.softmax(w, dim=1)\n",
    "        beta = beta.expand((z.shape[0],) + beta.shape)    # beta: (N, M, 1)\n",
    "\n",
    "        return (beta * z).sum(1)       # (N, hidden_dim * num_classes)\n",
    "\n",
    "class HAN(BaseModule):\n",
    "    def __init__(self, feature_dim, hidden_dim, dropout, num_heads, alpha, q_vector):\n",
    "        super(HAN, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.q_vector = q_vector\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.attentions = [NodeAttentionLayer(feature_dim, hidden_dim, self.dropout, alpha) for _ in range(num_heads)]\n",
    "        for i, attention in enumerate(self.attentions):\n",
    "            self.add_module('attention_{}'.format(i), attention)\n",
    "        self.semantic_attention = SemanticAttentionLayer(hidden_dim * num_heads, q_vector)\n",
    "        \n",
    "        # self.out_layer = nn.Linear(hidden_dim * num_heads, num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if inputs is None:\n",
    "            raise ValueError(\"Received None as input to HAN model.\")\n",
    "        # 从扩展的维度中取出真实输入\n",
    "        x = inputs[0]\n",
    "        meta_path_list = [inputs[1]]\n",
    "        # meta_path_list = meta_path_list.permute(2, 0, 1)\n",
    "        semantic_embeddings = []\n",
    "        for meta_path_adj in meta_path_list:\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            Z = torch.cat([attention(x, meta_path_adj) for attention in self.attentions], dim=1) # 节点级注意力\n",
    "            Z = F.dropout(Z, self.dropout, training=self.training)\n",
    "            semantic_embeddings.append(Z)\n",
    "\n",
    "        semantic_embeddings = torch.stack(semantic_embeddings, dim=1) # 元路径级注意力\n",
    "        final_embedding = self.semantic_attention(semantic_embeddings)\n",
    "        return final_embedding\n",
    "        # return self.out_layer(final_embedding)\n",
    "    \n",
    "    def output_num(self):\n",
    "        return 1\n",
    "\n",
    "class ServerNet(BaseModule):\n",
    "    def __init__(self, input_shape, num_classes, save_path='recommend'):\n",
    "        super(ServerNet, self).__init__()\n",
    "        self.out_layer = nn.Linear(input_shape, num_classes)\n",
    "        self.save_path = save_path\n",
    "        if self.save_path and not os.path.exists(self.save_path):\n",
    "            os.makedirs(self.save_path)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        if len(inputs) != 2:\n",
    "            raise ValueError(\"Expected two inputs to concatenate, got {}\".format(len(inputs)))\n",
    "        \n",
    "        # Check if the two inputs have the same batch size\n",
    "        if inputs[0].size(0) != inputs[1].size(0):\n",
    "            raise ValueError(\"Batch size mismatch between alice and bob's inputs\")\n",
    "        if agg_mode == 'average':\n",
    "            embeddings = torch.mean(torch.stack(inputs), dim=0) # 平均化embedding\n",
    "        else:\n",
    "            embeddings = torch.cat(inputs, dim=1) # 拼接embedding进行计算\n",
    "        # return self.out_layer(embeddings)\n",
    "        if self.training:\n",
    "            return self.out_layer(embeddings)\n",
    "        else:\n",
    "            # save embeddings\n",
    "            if self.save_path:\n",
    "                # 将 embeddings 转为 numpy 格式并保存\n",
    "                embeddings = sf.reveal(embeddings)\n",
    "                embeddings_np = embeddings.detach().cpu().numpy()\n",
    "                file_path = os.path.join(self.save_path, f\"movie_embedding.npy\")\n",
    "                np.save(file_path, embeddings_np)\n",
    "            return self.out_layer(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(feature_dim, hidden_dim, dropout, num_heads, alpha, q_vector):\n",
    "    def base_model():\n",
    "        model = HAN(feature_dim, hidden_dim, dropout, num_heads, alpha, q_vector)\n",
    "        return model\n",
    "    return base_model\n",
    "\n",
    "def create_fuse_model(hidden_dim, num_heads, num_classes):\n",
    "    def fuse_model():\n",
    "        if agg_mode == 'average':\n",
    "            input_shape = hidden_dim * num_heads\n",
    "        else:\n",
    "            input_shape = 2 * hidden_dim * num_heads\n",
    "        model = ServerNet(input_shape, num_classes)\n",
    "        return model\n",
    "    return fuse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'abc.ActorPYUSLTorchModel'> with party alice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'abc.ActorPYUSLTorchModel'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "from secretflow.ml.nn.core.torch import metric_wrapper,optim_wrapper,TorchModel\n",
    "from secretflow.ml.nn import SLModel\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Recall, Accuracy, Precision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ArcFaceLoss(nn.Module):\n",
    "    def __init__(self, s=30.0, m=0.50):\n",
    "        super(ArcFaceLoss, self).__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        one_hot = F.one_hot(target, num_classes=input.size(1)).float()\n",
    "        theta = torch.acos(torch.clamp(input, -1.0+1e-7, 1.0-1e-7))\n",
    "        target_logits = torch.cos(theta + self.m)\n",
    "        logits = input * (1 - one_hot) + target_logits * one_hot\n",
    "        return F.cross_entropy(self.s * logits, target)\n",
    "\n",
    "lr = 0.0002\n",
    "weight_decay = 0.0001\n",
    "hidden_dim = 64\n",
    "num_heads = 8\n",
    "dropout = 0.4\n",
    "alpha = 0.2\n",
    "q_vector = 128\n",
    "patience = 100\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss\n",
    "loss_fn = ArcFaceLoss\n",
    "optim_fn = optim_wrapper(optim.Adam, lr=lr)\n",
    "base_model_alice = TorchModel(\n",
    "    model_fn = create_base_model(feature_dim=input_shape_alice[1],\n",
    "                                    hidden_dim=hidden_dim,\n",
    "                                    dropout=dropout,\n",
    "                                    num_heads=num_heads,\n",
    "                                    alpha=alpha,\n",
    "                                    q_vector=q_vector),\n",
    "    loss_fn = loss_fn,\n",
    "    optim_fn = optim_fn,\n",
    "    metrics= [\n",
    "        metric_wrapper(Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Precision, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Recall, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "    ],\n",
    ")\n",
    "base_model_bob = TorchModel(\n",
    "    model_fn = create_base_model(feature_dim=input_shape_bob[1],\n",
    "                                    hidden_dim=hidden_dim,\n",
    "                                    dropout=dropout,\n",
    "                                    num_heads=num_heads,\n",
    "                                    alpha=alpha,\n",
    "                                    q_vector=q_vector),\n",
    "    loss_fn = loss_fn,\n",
    "    optim_fn = optim_fn,\n",
    "    metrics= [\n",
    "        metric_wrapper(Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Precision, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Recall, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fuse_model = TorchModel(\n",
    "    model_fn = create_fuse_model(hidden_dim=hidden_dim, \n",
    "                                    num_heads=num_heads, \n",
    "                                    num_classes=num_classes),\n",
    "    loss_fn = loss_fn,\n",
    "    optim_fn = optim_fn,\n",
    "    metrics= [\n",
    "        metric_wrapper(Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Precision, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "        metric_wrapper(Recall, task=\"multiclass\", num_classes=num_classes, average='micro'),\n",
    "    ],\n",
    ")\n",
    "\n",
    "base_model_dict = {\n",
    "    alice: base_model_alice,\n",
    "    bob: base_model_bob,\n",
    "}\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=alice,\n",
    "    model_fuse=fuse_model,\n",
    "    random_seed=1234,\n",
    "    backend='torch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:SL Train Params: {'self': <secretflow.ml.nn.sl.sl_model.SLModel object at 0x7f9e112836d0>, 'x': [FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f9e11263a60>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f9e11263ca0>}, partition_way=<PartitionWay.VERTICAL: 'vertical'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f9e11262a70>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7f9e11263f10>}, partition_way=<PartitionWay.VERTICAL: 'vertical'>)], 'y': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7f9e11263fd0>}, partition_way=<PartitionWay.VERTICAL: 'vertical'>), 'batch_size': 18810, 'epochs': 6, 'verbose': 1, 'callbacks': None, 'validation_data': None, 'shuffle': False, 'sample_weight': None, 'validation_freq': 1, 'dp_spent_step_freq': None, 'dataset_builder': None, 'audit_log_params': {}, 'early_stopping_batch_step': 0, 'early_stopping_warmup_step': 0, 'random_seed': 15354, 'audit_log_dir': None}\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:38<?, ?it/s, {'train_loss': array(21.194305, dtype=float32), 'train_MulticlassAccuracy': array(0.31807548, dtype=float32), 'train_MulticlassPrecision': array(0.31807548, dtype=float32), 'train_MulticlassRecall': array(0.31807548, dtype=float32)}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:38<?, ?it/s, {'train_loss': array(16.220493, dtype=float32), 'train_MulticlassAccuracy': array(0.53636366, dtype=float32), 'train_MulticlassPrecision': array(0.53636366, dtype=float32), 'train_MulticlassRecall': array(0.53636366, dtype=float32)}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:39<?, ?it/s, {'train_loss': array(17.088148, dtype=float32), 'train_MulticlassAccuracy': array(0.5879851, dtype=float32), 'train_MulticlassPrecision': array(0.5879851, dtype=float32), 'train_MulticlassRecall': array(0.5879851, dtype=float32)}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:39<?, ?it/s, {'train_loss': array(16.729155, dtype=float32), 'train_MulticlassAccuracy': array(0.5854865, dtype=float32), 'train_MulticlassPrecision': array(0.5854865, dtype=float32), 'train_MulticlassRecall': array(0.5854865, dtype=float32)}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:38<?, ?it/s, {'train_loss': array(15.826693, dtype=float32), 'train_MulticlassAccuracy': array(0.5579479, dtype=float32), 'train_MulticlassPrecision': array(0.5579479, dtype=float32), 'train_MulticlassRecall': array(0.5579479, dtype=float32)}]\n",
      "Train Processing: :   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Processing: :   0%|          | 0/1 [00:38<?, ?it/s, {'train_loss': array(15.536063, dtype=float32), 'train_MulticlassAccuracy': array(0.5180223, dtype=float32), 'train_MulticlassPrecision': array(0.5180223, dtype=float32), 'train_MulticlassRecall': array(0.5180223, dtype=float32)}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [array(21.194305, dtype=float32),\n",
       "  array(16.220493, dtype=float32),\n",
       "  array(17.088148, dtype=float32),\n",
       "  array(16.729155, dtype=float32),\n",
       "  array(15.826693, dtype=float32),\n",
       "  array(15.536063, dtype=float32)],\n",
       " 'train_MulticlassAccuracy': [array(0.31807548, dtype=float32),\n",
       "  array(0.53636366, dtype=float32),\n",
       "  array(0.5879851, dtype=float32),\n",
       "  array(0.5854865, dtype=float32),\n",
       "  array(0.5579479, dtype=float32),\n",
       "  array(0.5180223, dtype=float32)],\n",
       " 'train_MulticlassPrecision': [array(0.31807548, dtype=float32),\n",
       "  array(0.53636366, dtype=float32),\n",
       "  array(0.5879851, dtype=float32),\n",
       "  array(0.5854865, dtype=float32),\n",
       "  array(0.5579479, dtype=float32),\n",
       "  array(0.5180223, dtype=float32)],\n",
       " 'train_MulticlassRecall': [array(0.31807548, dtype=float32),\n",
       "  array(0.53636366, dtype=float32),\n",
       "  array(0.5879851, dtype=float32),\n",
       "  array(0.5854865, dtype=float32),\n",
       "  array(0.5579479, dtype=float32),\n",
       "  array(0.5180223, dtype=float32)]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "sl_model.fit(\n",
    "    x = [features, meta_path_list],\n",
    "    y = Y_train,\n",
    "    epochs = epochs,\n",
    "    batch_size = input_shape_alice[0],\n",
    "    # sample_weight = idx_train,\n",
    "    # validation_data = ([features, meta_path_list], Y_val, idx_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate Processing: :   0%|          | 0/1 [00:14<?, ?it/s, loss=12.608366, MulticlassAccuracy=0.84949493, MulticlassPrecision=0.84949493, MulticlassRecall=0.84949493]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': array(12.608366, dtype=float32),\n",
       " 'MulticlassAccuracy': array(0.84949493, dtype=float32),\n",
       " 'MulticlassPrecision': array(0.84949493, dtype=float32),\n",
       " 'MulticlassRecall': array(0.84949493, dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl_model.evaluate(\n",
    "    x = [features, meta_path_list],\n",
    "    y = Y_test,\n",
    "    batch_size = input_shape_alice[0],\n",
    "    # sample_weight = idx_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18810, 1024)\n",
      "(265187, 18810)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "movie_embedding = np.load(\"recommend/movie_embedding.npy\")\n",
    "print(movie_embedding.shape)\n",
    "\n",
    "user_movie_matrix = load_npz(\"recommend/user_movie_matrix.npz\")\n",
    "print(user_movie_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此得到了movie的embedding，后面可以用它做下游任务，完成推荐任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户特征 shape: (265187, 1024)\n"
     ]
    }
   ],
   "source": [
    "# 聚合用户特征：用户特征为用户交互电影 embedding 的加权平均\n",
    "user_embedding = user_movie_matrix.dot(movie_embedding) / (user_movie_matrix.sum(axis=1) + 1e-10)  # 防止除以 0\n",
    "user_embedding_path = \"recommend/user_embedding.npy\"\n",
    "np.save(user_embedding_path, user_embedding)\n",
    "print(\"用户特征 shape:\", user_embedding.shape)  # [num_users, embedding_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户 0 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 1 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 2 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 3 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 4 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 5 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 6 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 7 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 8 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 9 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 10000 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 10001 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 10002 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 10003 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 10004 推荐的电影: [[ 7053  2049 17250 11774 15204]]\n",
      "用户 10005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 10006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 10007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 10008 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 10009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 20000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 20001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 20002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 20003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 20004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 20005 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 20006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 20007 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 20008 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 20009 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 30000 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 30001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 30002 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 30003 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 30004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 30005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 30006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 30007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 30008 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 30009 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 40000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 40001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 40002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 40003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 40004 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 40005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 40006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 40007 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 40008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 40009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 50000 推荐的电影: [[ 7053  2296  1547  2050 12678]]\n",
      "用户 50001 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 50002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 50003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 50004 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 50005 推荐的电影: [[ 7053  2296  1547  2050 12678]]\n",
      "用户 50006 推荐的电影: [[ 7053  2296  1547  2050 12678]]\n",
      "用户 50007 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 50008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 50009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 60000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 60001 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 60002 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 60003 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 60004 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 60005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 60006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 60007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 60008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 60009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 70007 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 70008 推荐的电影: [[7053 2296 8055 1547 3906]]\n",
      "用户 70009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 80000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 80001 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 80002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 80003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 80004 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 80005 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 80006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 80007 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 80008 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 80009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 90005 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 90006 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 90007 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 90008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 90009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 100000 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 100001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100005 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 100006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 100008 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 100009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 110000 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110001 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110002 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110003 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110004 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110005 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110006 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110007 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110008 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 110009 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 120000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 120001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 120008 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 120009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 130000 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 130001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 130002 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 130003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 130004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 130005 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 130006 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 130007 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 130008 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 130009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 140000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 140001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 140002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 140003 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 140004 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 140005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 140006 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 140007 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 140008 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 140009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 150000 推荐的电影: [[ 7053  8055  2296  1547 15204]]\n",
      "用户 150001 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 150002 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 150003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 150004 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 150005 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 150006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 150007 推荐的电影: [[ 7053  2296  1547  8055 12678]]\n",
      "用户 150008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 150009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 160000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 160003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160008 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 160009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 170000 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170001 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170002 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170003 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170004 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170005 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170006 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170007 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170008 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 170009 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 180000 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 180001 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 180002 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 180003 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 180004 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 180005 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 180006 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 180007 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 180008 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 180009 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 190000 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 190001 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 190002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190004 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 190005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190008 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 190009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 200000 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 200001 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 200002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 200003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 200004 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 200005 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 200006 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 200007 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 200008 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 200009 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 210000 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 210001 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 210002 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 210003 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 210004 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 210005 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 210006 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 210007 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 210008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 210009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220001 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220004 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220005 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 220006 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 220007 推荐的电影: [[ 7053  8055  2296  1547 12678]]\n",
      "用户 220008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 220009 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 230000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 230001 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 230002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 230003 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 230004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 230005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 230006 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 230007 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 230008 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 230009 推荐的电影: [[7053 2296 2050 1547 8055]]\n",
      "用户 240000 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 240001 推荐的电影: [[7053 2296 1547 2050 8055]]\n",
      "用户 240002 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240003 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240006 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240007 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240008 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 240009 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 250000 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250001 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250002 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250003 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250004 推荐的电影: [[ 7053 15204  8055 11774  7468]]\n",
      "用户 250005 推荐的电影: [[ 7053 15204  8055 11774  7468]]\n",
      "用户 250006 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250007 推荐的电影: [[ 7053  2296  8055  1547 12678]]\n",
      "用户 250008 推荐的电影: [[7053 2296 1547 8055 7923]]\n",
      "用户 250009 推荐的电影: [[ 7343  5706 17771 15204  7053]]\n",
      "用户 260000 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260001 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260002 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260003 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260004 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 260005 推荐的电影: [[7053 2296 8055 1547 2050]]\n",
      "用户 260006 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260007 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260008 推荐的电影: [[7053 2296 1547 8055 2050]]\n",
      "用户 260009 推荐的电影: [[7053 2296 1547 8055 2050]]\n"
     ]
    }
   ],
   "source": [
    "# 按步长 10000 取出用户（每隔 10000 个用户取 10 个）\n",
    "step = 10000\n",
    "num_per_step = 10\n",
    "selected_user_indices = []\n",
    "for start in range(0, len(user_embedding), step):\n",
    "    selected_user_indices.extend(range(start, min(start + num_per_step, len(user_embedding))))\n",
    "\n",
    "# 根据选定的用户索引取出用户特征和交互矩阵\n",
    "limited_user_features = user_embedding[selected_user_indices]  # [num_selected_users, embedding_dim]\n",
    "limited_user_movie_matrix = user_movie_matrix[selected_user_indices]  # [num_selected_users, num_movies]\n",
    "\n",
    "# 计算用户对电影的相似度\n",
    "similarity_matrix = np.dot(limited_user_features, movie_embedding.T)  # [num_selected_users, num_movies]\n",
    "\n",
    "# 避免推荐用户已交互过的电影\n",
    "for user_idx in range(limited_user_movie_matrix.shape[0]):\n",
    "    interacted_movies = np.where(limited_user_movie_matrix[user_idx].toarray().flatten() > 0)[0]  # 获取已交互电影索引\n",
    "    similarity_matrix[user_idx, interacted_movies] = -np.inf  # 设置已交互电影的分数为 -np.inf\n",
    "    \n",
    "# 推荐前 5 部电影\n",
    "top_k = 5\n",
    "recommended_movies = np.argsort(similarity_matrix, axis=1)[:, -top_k:]\n",
    "recommended_movies = np.flip(recommended_movies, axis=1)\n",
    "\n",
    "# 输出推荐结果\n",
    "for idx, movie_ids in zip(selected_user_indices, recommended_movies):\n",
    "    print(f\"用户 {idx} 推荐的电影: {movie_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
