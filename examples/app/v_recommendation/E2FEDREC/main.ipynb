{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c286857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Ant Group Co., Ltd.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import secretflow as sf\n",
    "\n",
    "from E2FEDREC import Model\n",
    "from trainer import Trainer\n",
    "from server import Server\n",
    "from secretflow import PYUObject, proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f413562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(K_size):\n",
    "    \"\"\"\n",
    "    Parse and return command-line arguments for training configuration.\n",
    "\n",
    "    Args:\n",
    "        K_size (int): Initial embedding dimension size\n",
    "\n",
    "    Returns:\n",
    "        argparse.Namespace: Parsed training arguments\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Cross-Domain Recommendation System Options\"\n",
    "    )\n",
    "\n",
    "    # Training hyperparameters\n",
    "    parser.add_argument(\n",
    "        \"-negNum\",\n",
    "        default=7,\n",
    "        type=int,\n",
    "        help=\"Number of negative samples per positive sample\",\n",
    "    )\n",
    "    parser.add_argument(\"-lr\", default=0.001, type=float, help=\"Learning rate\")\n",
    "    parser.add_argument(\n",
    "        \"-maxEpochs\", default=5, type=int, help=\"Maximum number of training epochs\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-batchSize\", default=512, type=int, help=\"Mini-batch size for training\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-earlyStop\", default=5, type=int, help=\"Early stopping patience\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-checkPoint\", default=\"./checkPoint/\", help=\"Directory to save checkpoints\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-topK\", default=10, type=int, help=\"Top-K value for evaluation metrics\"\n",
    "    )\n",
    "\n",
    "    # Model architecture configuration\n",
    "    parser.add_argument(\n",
    "        \"-userLayer\",\n",
    "        default=[K_size, 2 * K_size, K_size],\n",
    "        help=\"Sizes of user encoder layers\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-itemLayer\",\n",
    "        default=[K_size, 2 * K_size, K_size],\n",
    "        help=\"Sizes of item encoder layers\",\n",
    "    )\n",
    "    parser.add_argument(\"-KSize\", default=K_size, help=\"Embedding dimension size\")\n",
    "\n",
    "    # Regularization settings\n",
    "    parser.add_argument(\n",
    "        \"-reg\", default=1e-3, type=float, help=\"L2 regularization coefficient\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-lambdad\", default=0.001, type=float, help=\"Weight for domain alignment loss\"\n",
    "    )\n",
    "\n",
    "    # Contrastive learning settings\n",
    "    parser.add_argument(\n",
    "        \"-ssl_temp\", default=1, type=float, help=\"Temperature for contrastive loss\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ssl_reg_intra\",\n",
    "        default=0.3,\n",
    "        type=float,\n",
    "        help=\"Weight for intra-domain contrastive loss\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-ssl_reg_inter\",\n",
    "        default=0.2,\n",
    "        type=float,\n",
    "        help=\"Weight for inter-domain contrastive loss\",\n",
    "    )\n",
    "\n",
    "    # Empty list to prevent CLI parsing conflict when called from code\n",
    "    return parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28bfc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(records, server, max_epochs):\n",
    "    \"\"\"\n",
    "    Train models across domains for a given number of epochs.\n",
    "\n",
    "    Args:\n",
    "        records (dict): Dictionary storing trainer instances and metrics\n",
    "        server (Server): Server instance for aggregation\n",
    "        max_epochs (int): Maximum number of training epochs\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Starting epoch training...\")\n",
    "\n",
    "    dataset_names = list(records.keys())\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"\\n[INFO] === Epoch {epoch} ===\")\n",
    "\n",
    "        # Step 1: Collect representations from each trainer\n",
    "        trainer_weights = []\n",
    "        for dataset_name in dataset_names:\n",
    "            trainer = records[dataset_name][\"trainer\"]\n",
    "            weights = trainer.get_reps_shared()\n",
    "            if weights is None:\n",
    "                raise ValueError(\n",
    "                    f\"[ERROR] {dataset_name}: get_reps_shared() returned None.\"\n",
    "                )\n",
    "            trainer_weights.append(weights.to(server.device))\n",
    "\n",
    "        # Step 2: Aggregate representations at the server\n",
    "        global_weights = server.aggregate_reps(trainer_weights)\n",
    "\n",
    "        # Step 3: Distribute global representations back to trainers\n",
    "        setting = []\n",
    "        for dataset_name in dataset_names:\n",
    "            trainer = records[dataset_name][\"trainer\"]\n",
    "            ret = trainer.set_global_reps(global_weights.to(trainer.device))\n",
    "            setting.append(ret)\n",
    "\n",
    "        sf.wait(setting)  # Ensure all trainers have synchronized\n",
    "\n",
    "        # Step 4: Train and evaluate\n",
    "        for dataset_name in dataset_names:\n",
    "            trainer = records[dataset_name][\"trainer\"]\n",
    "            print(f\"[INFO] Training for {dataset_name}...\")\n",
    "            loss, hr, ndcg = sf.reveal(trainer.run_one_epoch(epoch))\n",
    "\n",
    "            records[dataset_name][\"loss_list\"].append(loss)\n",
    "            records[dataset_name][\"hr_list\"].append(hr)\n",
    "            records[dataset_name][\"NDCG_list\"].append(ndcg)\n",
    "\n",
    "            if hr > records[dataset_name][\"best_hr\"]:\n",
    "                records[dataset_name][\"best_hr\"] = hr\n",
    "                records[dataset_name][\"best_NDCG\"] = ndcg\n",
    "\n",
    "            print(\n",
    "                f\"[RESULT] {dataset_name} | Epoch {epoch} | Loss: {loss:.4f}, HR@10: {hr:.4f}, NDCG@10: {ndcg:.4f}\"\n",
    "            )\n",
    "\n",
    "    print(\"[INFO] Epoch training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "849946ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataName_A, dataName_B, K_size):\n",
    "    \"\"\"\n",
    "    Main entry point for running cross-domain federated training.\n",
    "\n",
    "    Args:\n",
    "        dataName_A (str): Name of source domain dataset\n",
    "        dataName_B (str): Name of target domain dataset\n",
    "        K_size (int): Embedding dimension size\n",
    "    \"\"\"\n",
    "    print(\n",
    "        f\"[INFO] Starting training with:\\n  - Domain A: {dataName_A}\\n  - Domain B: {dataName_B}\\n  - K size: {K_size}\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        # === Setup section ===\n",
    "        args = get_args(K_size)\n",
    "        np.random.seed(42)\n",
    "\n",
    "        sf.shutdown()  # Clean up any previous session (optional)\n",
    "        sf.init([dataName_A, dataName_B, \"server\"], address=\"local\", num_gpus=1)\n",
    "        print(\"[INFO] SecretFlow initialized successfully.\")\n",
    "\n",
    "        dataName_A_pyu = sf.PYU(dataName_A)\n",
    "        dataName_B_pyu = sf.PYU(dataName_B)\n",
    "        server_pyu = sf.PYU(\"server\")\n",
    "\n",
    "        # Create trainers and server\n",
    "        trainer_A = Trainer(args, dataName_A, dataName_B, 0, device=dataName_A_pyu)\n",
    "        trainer_B = Trainer(args, dataName_B, dataName_A, 0, device=dataName_B_pyu)\n",
    "        server = Server(args, [dataName_A, dataName_B], device=server_pyu)\n",
    "\n",
    "        # Initialize metrics recorder\n",
    "        records = {\n",
    "            dataName_A: {\n",
    "                \"trainer\": trainer_A,\n",
    "                \"loss_list\": [],\n",
    "                \"hr_list\": [],\n",
    "                \"NDCG_list\": [],\n",
    "                \"best_hr\": -1,\n",
    "                \"best_NDCG\": -1,\n",
    "            },\n",
    "            dataName_B: {\n",
    "                \"trainer\": trainer_B,\n",
    "                \"loss_list\": [],\n",
    "                \"hr_list\": [],\n",
    "                \"NDCG_list\": [],\n",
    "                \"best_hr\": -1,\n",
    "                \"best_NDCG\": -1,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # === Training section ===\n",
    "        max_epochs = args.maxEpochs\n",
    "        train_epochs(records, server, max_epochs)\n",
    "\n",
    "        # Save results\n",
    "        for dataset_name in [dataName_A, dataName_B]:\n",
    "            trainer = records[dataset_name][\"trainer\"]\n",
    "            matname = f\"E2FEDREC_{dataset_name}_KSize_{K_size}_Result.pt\"\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"loss_list\": records[dataset_name][\"loss_list\"],\n",
    "                    \"hr_list\": records[dataset_name][\"hr_list\"],\n",
    "                    \"NDCG_list\": records[dataset_name][\"NDCG_list\"],\n",
    "                    \"bestPerformance\": [\n",
    "                        records[dataset_name][\"best_hr\"],\n",
    "                        records[dataset_name][\"best_NDCG\"],\n",
    "                    ],\n",
    "                },\n",
    "                matname,\n",
    "            )\n",
    "            print(f\"[INFO] Results for {dataset_name} saved to {matname}\")\n",
    "\n",
    "        print(\"[INFO] Training completed successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"[ERROR] Exception occurred during training:\")\n",
    "        print(e)\n",
    "\n",
    "    print(\"[INFO] Program execution finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6b6f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting training with:\n",
      "  - Domain A: book\n",
      "  - Domain B: movie\n",
      "  - K size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 16:23:59,754\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "INFO:root:Create proxy actor <class 'trainer.Trainer'> with party book.\n",
      "INFO:root:Create proxy actor <class 'trainer.Trainer'> with party movie.\n",
      "INFO:root:Create proxy actor <class 'server.Server'> with party server.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] SecretFlow initialized successfully.\n",
      "[INFO] Starting epoch training...\n",
      "\n",
      "[INFO] === Epoch 0 ===\n",
      "[INFO] Training for book...\n",
      "[RESULT] book | Epoch 0 | Loss: 1349.8745, HR@10: 0.2404, NDCG@10: 0.1206\n",
      "[INFO] Training for movie...\n",
      "[RESULT] movie | Epoch 0 | Loss: 1343.9980, HR@10: 0.3607, NDCG@10: 0.1965\n",
      "\n",
      "[INFO] === Epoch 1 ===\n",
      "[INFO] Training for book...\n",
      "[RESULT] book | Epoch 1 | Loss: 1324.6570, HR@10: 0.3176, NDCG@10: 0.1693\n",
      "[INFO] Training for movie...\n",
      "[RESULT] movie | Epoch 1 | Loss: 1326.1514, HR@10: 0.4213, NDCG@10: 0.2463\n",
      "\n",
      "[INFO] === Epoch 2 ===\n",
      "[INFO] Training for book...\n",
      "[RESULT] book | Epoch 2 | Loss: 1322.8991, HR@10: 0.3254, NDCG@10: 0.1781\n",
      "[INFO] Training for movie...\n",
      "[RESULT] movie | Epoch 2 | Loss: 1319.3948, HR@10: 0.4180, NDCG@10: 0.2469\n",
      "\n",
      "[INFO] === Epoch 3 ===\n",
      "[INFO] Training for book...\n",
      "[RESULT] book | Epoch 3 | Loss: 1319.9362, HR@10: 0.3278, NDCG@10: 0.1821\n",
      "[INFO] Training for movie...\n",
      "[RESULT] movie | Epoch 3 | Loss: 1315.6518, HR@10: 0.4289, NDCG@10: 0.2582\n",
      "\n",
      "[INFO] === Epoch 4 ===\n",
      "[INFO] Training for book...\n",
      "[RESULT] book | Epoch 4 | Loss: 1318.4426, HR@10: 0.3361, NDCG@10: 0.1892\n",
      "[INFO] Training for movie...\n",
      "[RESULT] movie | Epoch 4 | Loss: 1308.6521, HR@10: 0.4251, NDCG@10: 0.2500\n",
      "[INFO] Epoch training completed.\n",
      "[ERROR] Exception occurred during training:\n",
      "'ActorProxy(Trainer)' object has no attribute 'dataName'\n",
      "[INFO] Program execution finished.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tasks = [[\"book\", \"movie\"]]\n",
    "    KList = [8]\n",
    "\n",
    "    for K_size in KList:\n",
    "        for domain_A, domain_B in tasks:\n",
    "            main(domain_A, domain_B, K_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b645e86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
