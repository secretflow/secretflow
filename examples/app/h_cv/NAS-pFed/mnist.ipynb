{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-16T22:04:53.855589Z",
     "start_time": "2025-05-16T04:34:29.782396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import time\n",
    "import secretflow as sf\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from darts.model import NetworkEMNIST\n",
    "from dataSplit.mnist.mnist import split_mnist\n",
    "from model.Server import Server\n",
    "from model.Client import Client\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "def add_args(parser):\n",
    "    parser.add_argument(\n",
    "        '--stage', type=str, default='search', help='stage: search; train'\n",
    "    )\n",
    "    parser.add_argument('--device', type=str, default='cuda:0', help='cpu or gpu')\n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default='mnist',\n",
    "        metavar='N',\n",
    "        help='dataset used for training',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        type=int,\n",
    "        default=64,\n",
    "        metavar='N',\n",
    "        help='input batch size for training (default: 64)',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--client_number',\n",
    "        type=int,\n",
    "        default=20,\n",
    "        metavar='NN',\n",
    "        help='number of workers in a distributed cluster',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--comm_round',\n",
    "        type=int,\n",
    "        default=50,\n",
    "        help='how many round of communications we shoud use',\n",
    "    )\n",
    "    parser.add_argument('--layers', type=int, default=3, help='DARTS layers')\n",
    "    parser.add_argument(\n",
    "        '--dirichlet',\n",
    "        type=float,\n",
    "        default=0.6,\n",
    "        help='狄利克雷分布的参数，用于分割数据集',\n",
    "    )\n",
    "    parser.add_argument('--num_classes', type=int, default=10, help='数据集类别个数')\n",
    "    parser.add_argument('--temperature', type=float, default=5, help='设置蒸馏温度')\n",
    "    parser.add_argument(\n",
    "        '--model',\n",
    "        type=str,\n",
    "        default='resnet',\n",
    "        metavar='N',\n",
    "        help='neural network used in training',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--wd', help='weight decay parameter;', type=float, default=0.001\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--epochs',\n",
    "        type=int,\n",
    "        default=5,\n",
    "        metavar='EP',\n",
    "        help='how many epochs will be trained locally',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--local_points',\n",
    "        type=int,\n",
    "        default=5000,\n",
    "        metavar='LP',\n",
    "        help='the approximate fixed number of data points we will have on each local worker',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--init_channels', type=int, default=16, help='num of init channels'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning_rate', type=float, default=0.025, help='init learning rate'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--learning_rate_min', type=float, default=0.001, help='min learning rate'\n",
    "    )\n",
    "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
    "    parser.add_argument('--weight_decay', type=float, default=3e-4, help='weight decay')\n",
    "    parser.add_argument(\n",
    "        '--arch_learning_rate',\n",
    "        type=float,\n",
    "        default=3e-4,\n",
    "        help='learning rate for arch encoding',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--arch_weight_decay',\n",
    "        type=float,\n",
    "        default=1e-3,\n",
    "        help='weight decay for arch encoding',\n",
    "    )\n",
    "    parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "    parser.add_argument(\n",
    "        '--lambda_train_regularizer',\n",
    "        type=float,\n",
    "        default=1,\n",
    "        help='train regularizer parameter',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--lambda_valid_regularizer',\n",
    "        type=float,\n",
    "        default=1,\n",
    "        help='validation regularizer parameter',\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--report_freq', type=float, default=10, help='report frequency'\n",
    "    )\n",
    "    parser.add_argument('--tau_max', type=float, default=10, help='initial tau')\n",
    "    parser.add_argument('--tau_min', type=float, default=1, help='minimum tau')\n",
    "    parser.add_argument(\n",
    "        '--auxiliary', action='store_true', default=False, help='use auxiliary tower'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--arch', type=str, default='FedNAS_V1', help='which architecture to use'\n",
    "    )\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = add_args(parser)\n",
    "    print(\n",
    "        str(args.num_classes)\n",
    "        + \" \"\n",
    "        + str(args.client_number)\n",
    "        + \" \"\n",
    "        + str(args.comm_round)\n",
    "    )\n",
    "    device = torch.device(args.device)\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    train_dataset = datasets.MNIST(\n",
    "        './dataset', train=True, download=True, transform=transform\n",
    "    )\n",
    "    test_dataset = datasets.MNIST(\n",
    "        './dataset', train=False, download=True, transform=transform\n",
    "    )\n",
    "    train_client_samples, test_client_samples = split_mnist(\n",
    "        args.dirichlet, args.client_number\n",
    "    )\n",
    "    train_dataloader, test_dataloader = [], []\n",
    "    search_dataloader, val_dataloader = [], []\n",
    "    for i in range(args.client_number):\n",
    "        random.shuffle(train_client_samples[i])\n",
    "        half_size = len(train_client_samples[i]) // 2\n",
    "        first_half = train_client_samples[i][:half_size]\n",
    "        second_half = train_client_samples[i][half_size:]\n",
    "        search_subset = torch.utils.data.Subset(train_dataset, indices=first_half)\n",
    "        search_sub_loader = torch.utils.data.DataLoader(\n",
    "            search_subset, batch_size=args.batch_size\n",
    "        )\n",
    "        val_subset = torch.utils.data.Subset(train_dataset, indices=second_half)\n",
    "        val_sub_loader = torch.utils.data.DataLoader(\n",
    "            val_subset, batch_size=args.batch_size\n",
    "        )\n",
    "        train_subset = torch.utils.data.Subset(\n",
    "            train_dataset, indices=train_client_samples[i]\n",
    "        )\n",
    "        train_sub_loader = torch.utils.data.DataLoader(\n",
    "            train_subset, batch_size=args.batch_size\n",
    "        )\n",
    "        test_subset = torch.utils.data.Subset(\n",
    "            test_dataset, indices=test_client_samples[i]\n",
    "        )\n",
    "        test_sub_loader = torch.utils.data.DataLoader(\n",
    "            test_subset, batch_size=args.batch_size\n",
    "        )\n",
    "        search_dataloader.append(search_sub_loader)\n",
    "        val_dataloader.append(val_sub_loader)\n",
    "        train_dataloader.append(train_sub_loader)\n",
    "        test_dataloader.append(test_sub_loader)\n",
    "\n",
    "    clients_name = ['client' + str(i + 1) for i in range(args.client_number)]\n",
    "    # print(clients_name)\n",
    "    clients_id = []\n",
    "    sf.init(clients_name, address='local', num_gpus=1, debug_mode=True)\n",
    "    for i in clients_name:\n",
    "        clients_id.append(sf.PYU(i))\n",
    "    server_pyu = sf.PYU(\"server\")\n",
    "\n",
    "    server = Server(\n",
    "        None, None, 60000, args.client_number, device, args, device=server_pyu\n",
    "    )\n",
    "\n",
    "    clients = []\n",
    "    for client_id in range(args.client_number):\n",
    "        clients.append(\n",
    "            Client(\n",
    "                client_id + 1,\n",
    "                search_dataloader[client_id],\n",
    "                val_dataloader[client_id],\n",
    "                train_dataloader[client_id],\n",
    "                test_dataloader[client_id],\n",
    "                60000 / args.client_number,\n",
    "                device,\n",
    "                args,\n",
    "                device=clients_id[client_id],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    global_model_params = None\n",
    "    global_arch_params = None\n",
    "\n",
    "    print(\"**************开始搜索全局模型**************\")\n",
    "    for i in tqdm(range(args.comm_round)):\n",
    "        weights_list, alphas_list, local_sample_num_list = [], [], []\n",
    "        if global_model_params is None:\n",
    "            global_model_params = server.get_model_weight()\n",
    "            global_arch_params = server.get_arch_parameters()\n",
    "        for j in range(len(clients)):\n",
    "            clients[j].update_model(global_model_params.to(clients[j].device))\n",
    "            clients[j].update_arch(global_arch_params.to(clients[j].device))\n",
    "            start_time = time.time()\n",
    "            clients[j].search()\n",
    "            train_finished_time = time.time()\n",
    "            client_weight = clients[j].get_weights()\n",
    "            client_alphas = clients[j].get_alphas()\n",
    "            client_local_sample_number = clients[j].get_local_sample_number()\n",
    "            weights_list.append(client_weight.to(server.device))\n",
    "            alphas_list.append(client_alphas.to(server.device))\n",
    "            local_sample_num_list.append(client_local_sample_number.to(server.device))\n",
    "        for j in range(len(clients)):\n",
    "            server.add_local_trained_result(\n",
    "                j, weights_list[j], alphas_list[j], local_sample_num_list[j]\n",
    "            )\n",
    "        server.aggregate()\n",
    "    print(\"**************全局模型已经搜索完毕**************\")\n",
    "    print(\n",
    "        \"**************通过全局模型，指导客户端模型进行本地搜索与训练*****************\"\n",
    "    )\n",
    "    for j in tqdm(range(len(clients))):\n",
    "        clients[j].init_history_normal_reduce()\n",
    "        server_weight = server.get_model_weight()\n",
    "        clients[j].init_server_model(server_weight.to(clients[j].device))\n",
    "        for m in range(10):\n",
    "            start_time = time.time()\n",
    "            clients[j].distillation_search()\n",
    "            train_finished_time = time.time()\n",
    "        genotype = clients[j].get_genotype().data\n",
    "        search_model_weights = clients[j].get_weights().data\n",
    "        model = NetworkEMNIST(\n",
    "            args.init_channels, args.num_classes, args.layers, args.auxiliary, genotype\n",
    "        )\n",
    "        model.load_state_dict(search_model_weights, strict=False)\n",
    "        clients[j].set_model(model)\n",
    "        max = 0.0\n",
    "        for n in range(500):\n",
    "            clients[j].train()\n",
    "            clients[j].test()\n",
    "            test_acc = clients[j].get_test_acc().data\n",
    "            test_loss = clients[j].get_test_loss().data\n",
    "            if test_acc > max:\n",
    "                max = test_acc\n",
    "            with open('./result/mnist/client' + str(j) + '.txt', 'a') as file:\n",
    "                file.write(f\"{test_acc} {test_loss}\\n\")\n",
    "        print(f\"第{j}个客户端准确率为{max}\")"
   ],
   "id": "71d21406",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "10 20 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/Private/v2/dataSplit/mnist/mnist.py:73: RuntimeWarning: invalid value encountered in divide\n",
      "  train_multinomial_vals = (train_multinomial_vals / train_multinomial_vals.sum(axis=1)[:, None])\n",
      "/home/Private/v2/dataSplit/mnist/mnist.py:81: RuntimeWarning: invalid value encountered in divide\n",
      "  test_multinomial_vals = (test_multinomial_vals / test_multinomial_vals.sum(axis=1)[:, None])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************开始搜索全局模型**************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/root/miniconda3/envs/sf2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:809: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "100%|██████████| 50/50 [6:49:32<00:00, 491.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************全局模型已经搜索完毕**************\n",
      "**************通过全局模型，指导客户端模型进行本地搜索与训练*****************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [30:16<9:35:15, 1816.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个客户端准确率为0.984\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [1:04:58<9:51:49, 1972.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1个客户端准确率为0.994\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [1:32:33<8:37:46, 1827.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第2个客户端准确率为0.988\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [2:05:15<8:21:32, 1880.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第3个客户端准确率为0.996\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [2:38:02<7:57:55, 1911.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第4个客户端准确率为0.986\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [3:06:41<7:10:47, 1846.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第5个客户端准确率为0.988\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [3:39:21<6:48:04, 1883.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第6个客户端准确率为0.992\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [4:07:59<6:06:11, 1830.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第7个客户端准确率为0.99\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [4:43:44<5:53:39, 1929.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第8个客户端准确率为0.996\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [5:12:29<5:11:00, 1866.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第9个客户端准确率为0.992\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [5:48:02<4:52:10, 1947.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第10个客户端准确率为0.996\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [6:20:42<4:20:10, 1951.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第11个客户端准确率为0.994\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [6:55:56<3:53:25, 2000.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第12个客户端准确率为0.996\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [7:29:15<3:20:00, 2000.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第13个客户端准确率为1.0\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [8:03:02<2:47:20, 2008.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第14个客户端准确率为1.0\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [8:36:53<2:14:20, 2015.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第15个客户端准确率为0.99\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [9:08:46<1:39:13, 1984.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第16个客户端准确率为0.992\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [9:35:54<1:02:34, 1877.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第17个客户端准确率为0.986\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [10:05:50<30:52, 1852.89s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第18个客户端准确率为0.998\n",
      "48 48 16\n",
      "48 64 32\n",
      "64 128 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:40:48<00:00, 1922.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第19个客户端准确率为1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
