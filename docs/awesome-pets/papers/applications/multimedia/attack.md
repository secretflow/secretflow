## Attack Methods

- MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation.  
  *Sanjay Kariyappaï¼ŒAtul Prakash, Moinuddin K Qureshi*  
  CVPR 2021, [eprint](https://ieeexplore.ieee.org/document/9577631)

- Data-Free Model Extraction.  
  *Truong Jean-Baptiste, Maini Pratyush, Walls Robert J, Papernot Nicolas*  
  CVPR 2021, [eprint](https://arxiv.org/abs/2011.14779)

- Model Inversion Attack by Integration of Deep Generative Models: Privacy-Sensitive Face Generation From a Face Recognition System.  
  *Mahdi Khosravy, Kazuaki Nakamura, Yuki Hirose, Naoko Nitta, Noboru Babaguchi*  
  TIFS 2022, [eprint](https://dl.acm.org/doi/abs/10.1109/TIFS.2022.3140687)
  
- Plug & Play Attacks: Towards Robust and Flexible Model Inversion Attacks.  
  *Struppek Lukas, Hintersdorf Dominik, Correia Antonio De Almeida, Adler Antonia, Kersting Kristian*  
  ICML 2022, [eprint](https://arxiv.org/pdf/2201.12179.pdf)
  
 - See through gradients: Image batch recovery via gradinversion.  
  *Yin Hongxu, Mallya Arun, Vahdat Arash, Alvarez Jose M, Kautz Jan, Molchanov Pavlo*  
  CVPR 2021, [eprint](https://arxiv.org/pdf/2007.13635.pdf)

- ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning.  
  *Jingtao Li, Adnan Siraj Rakin, Xing Chen, Zhezhi He, Deliang Fan, Chaitali Chakrabarti*  
  CVPR 2022, [eprint](https://openaccess.thecvf.com/content/CVPR2022/html/Li_ResSFL_A_Resistance_Transfer_Framework_for_Defending_Model_Inversion_Attack_CVPR_2022_paper.html)  
  
- Soteria: Provable defense against privacy leakage in federated learning from representation perspective.  
  *Jingwei Sun, Ang Li, Binghui Wang, Huanrui Yang, Hai Li, Yiran Chen*  
  CVPR 2021, [eprint](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.pdf)  
- Label-Only Membership Inference Attack.  
  *Christopher A. Choquette-Choo, Florian Tramer, Nicholas Carlini, Nicolas Papernot*  
  ICML 2021, [eprint](http://proceedings.mlr.press/v139/choquette-choo21a/choquette-choo21a.pdf)  
  
- Bilateral Dependency Optimization: Defending Against Model-inversion Attacks.  
  *Xiong Peng, Feng Liu, Jingfen Zhang, Long Lan, Junjie Ye, Tongliang Liu, Bo Han*  
  KDD 2022, [eprint](https://arxiv.org/abs/2206.05483)
  
- Feature inference attack on model predictions in vertical federated learning.  
  *Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, Beng Chin Ooi*  
  ICDE 2021, [eprint](https://arxiv.org/abs/2010.10152)
