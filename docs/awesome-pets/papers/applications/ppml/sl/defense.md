## Detection and Defenses against Attacks on Split Learning

- [Shredder: Learning Noise Distributions to Protect Inference Privacy](https://dl.acm.org/doi/10.1145/3373376.3378522)(ASPLOS, CCF-A)

- [Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud](https://dl.acm.org/doi/10.1145/3219819.3220106)(KDD, CCF-A)

- [Certified Robustness to Adversarial Examples with Differential Privacy](https://arxiv.org/pdf/1802.03471.pdf)( IEEE Symposium on Security and Privacy, S&P, CCF-A)

- [NoPeek: Information leakage reduction to share activations in distributed deep learning](https://arxiv.org/pdf/2008.09161.pdf)(ICDM workshop, CCF-B)

- [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong)(USENIX Security,CCF-A)

- [Adversarial Learning of Privacy-Preserving and Task-Oriented Representations](https://arxiv.org/pdf/1911.10143.pdf)(AAAI, CCF-A)

- [ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning](https://arxiv.org/pdf/2205.04007.pdf)(CVPR, CCF-A)

- [Improving Robustness to Model Inversion Attacks via Mutual Information Regularization](https://arxiv.org/pdf/2009.05241.pdf)(AAAI, CCF-A)

- [SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split Learning](https://arxiv.org/pdf/2108.09052.pdf)(WPES@CCS)

- [DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep neural networks](https://arxiv.org/pdf/2012.11025.pdf)(CVPR, CCF-A)
