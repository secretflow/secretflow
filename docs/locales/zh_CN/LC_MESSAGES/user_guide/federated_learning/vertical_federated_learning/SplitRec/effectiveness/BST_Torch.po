# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Ant Group Co., Ltd.
# This file is distributed under the same license as the SecretFlow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
msgid ""
msgstr ""
"Project-Id-Version: SecretFlow \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-06-25 11:09+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:9
msgid "SplitRec：在隐语中使用拆分 BST 算法（Torch 后端）"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:20
msgid ""
"阿里搜索推荐团队在 2019 年 arXiv 上发布文章《Behavior Sequence Transformer for E-commerce"
" Recommendation in Alibaba》，提出 BST 模型。BST 利用 Transformer 结构捕捉用户行为序列信息，解决 "
"WDL、DIN 等模型忽略序列信息的问题，因而受到关注。本文将介绍如何在隐语中使用拆分 BST 算法。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:32
msgid "BST 模型"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:34
msgid "BST 模型在 DNN 模型基础上，使用 Transformer Layer 捕捉用户行为序列中的信息，整体结构如下 |bst|"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:-1
#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:36
msgid "bst"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:47
msgid "其中 Transformer Layer 使用一层 multi-head self-attention 结构，如图右侧所示。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:49
msgid "Transformer layer 的输入是序列特征的 Embedding 和位置 Embedding 的加和。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:61
msgid "隐语中的拆分 BST 模型"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:72
msgid ""
"隐语考虑两方拆分学习场景，两方各持有一些特征，包括序列特征和其他特，一方持有 label 。双方特征经过 base 模型处理后，将 base "
"模型的输出输入到 fuse 模型进行学习，根据对序列特征的处理不同分为拆分 BST 模型和拆分 BSTPlus 模型。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:84
msgid "拆分 BST 模型"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:86
msgid ""
"其中序列特征通过 Transformer Layer 处理，其他特征通过普通的 Embedding "
"处理，序列特征和其他特征是可选的，模型结构如图所示。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:92
msgid "拆分 BSTPlus 模型"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:94
msgid ""
"上述 BST "
"模型虽然能够有效捕捉序列信息，但对于同一用户不同商品的预估来说，序列信息都是相同的，并不能区分同一用户行为序列与不同商品的关联性，因此 "
"BSTPlus 模型在 BST 基础上叠加 DIN 中的 attention 思想，对 target item 和 Transformer "
"layer 的输出进行 attention pooling，通过计算 target item 对序列中 item 的注意力来挖掘用户行为序列与 "
"target item 之间的关联信息，结构如下图。由于 target item 存在于 label 方，暂不支持无 label 方有序列特征。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:109
msgid "隐语封装"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:111
msgid ""
"我们在隐语中提供了对于各种应用的封装。 关于 BST 的封装在 "
"secretflow/ml/nn/applications/sl_bst_torch.py，提供了 ``BSTBase`` "
"``BSTPlusBase`` 和 ``BSTFuse`` 几个类。 下面我们通过一个例子来看一下如何使用隐语封装的 BST 来进行训练。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:123
msgid "环境设置"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:203
msgid "数据集介绍"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:205
msgid "这里将使用最经典的 MovieLens 数据集进行演示。 MovieLens 是一个开放式的推荐系统数据集，包含了电影评分和电影元数据信息。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:207
msgid "`数据集官网 <https://grouplens.org/datasets/movielens/>`__"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:209
msgid ""
"`下载数据集 <https://secretflow-data.oss-"
"accelerate.aliyuncs.com/datasets/movielens/ml-1m.zip>`__"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:221
msgid "下载并处理数据"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:223
msgid "我们通过聚合同一用户按时间顺序评分过的电影生成用户行为序列，并对数据进行切分："
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:224
msgid "- alice: user_id, target_movie_id, sequence_movie_ids, label"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:225
msgid "- bob: gender, age_group, occupation"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:596
msgid "到这里，我们以及产出训练测试用的数据文件。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:608
msgid "构造 dataset_builder 处理数据"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:610
msgid "这里对特征进行 ID 化处理，rating > 3 作为正样本，否则作为负样本"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:706
msgid "定义模型结构"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:708
msgid "通过 mode 指定 base 模型结构 - mode=‘ori’: BSTBase - mode=‘plus’: BSTPlusBase"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:794
msgid "定义 SL Model"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:898
msgid "开始训练"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:1021
msgid "总结"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:1023
msgid ""
"本文通过 movieLens 数据集上的推荐任务来演示了如何通过隐语来训练拆分 BST 模型，您需要 1. 下载并处理数据集； 2. 构造 "
"dataset_builder 处理数据； 3. 定义模型结构，调用 ``BSTBase``\\ ， ``BSTPlusBase`` 和 "
"``BSTFuse`` 定义行模结构； 4. 使用 SLModel 进行训练，预测，评估即可。"
msgstr ""

#: ../../user_guide/federated_learning/vertical_federated_learning/SplitRec/effectiveness/BST_Torch.ipynb:1034
msgid "您可以在自己的数据集上进行尝试，如有任何问题，可以在 github 上进行讨论。"
msgstr ""

#~ msgid "|bst|"
#~ msgstr ""
