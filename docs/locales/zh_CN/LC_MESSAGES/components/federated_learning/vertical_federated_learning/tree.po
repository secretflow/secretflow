# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Ant Group Co., Ltd.
# This file is distributed under the same license as the SecretFlow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
msgid ""
msgstr ""
"Project-Id-Version: SecretFlow \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-04-05 01:02+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:1
msgid "Vertically Federated XGB (SecureBoost)"
msgstr "垂直联邦XGB (SecureBoost)"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:3
msgid ""
"In vertical federated learning scenarios, data is partitioned vertically "
"according to features, meaning that each participant's data samples are "
"consistent, but have different columns and types."
msgstr "在垂直联邦学习场景中，数据根据特征进行垂直分割，这意味着每个参与者的数据样本是一致的，但具有不同的列和类型。"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:5
msgid "Introduction to SecureBoost"
msgstr "SecureBoost简介"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:7
msgid "Original paper: [SecureBoost](https://arxiv.org/abs/1901.08755)"
msgstr "原始论文: [SecureBoost](https://arxiv.org/abs/1901.08755)"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:9
msgid ""
"In vertical federated learning scenarios, each party has data with the "
"same samples, but different feature spaces. SecureBoost prioritizes the "
"protection of label holder's information and is designed to be as "
"accurate as the original XGBoost algorithm."
msgstr "在垂直联邦学习场景中，每个参与方都拥有具有相同样本但不同特征空间的数据。SecureBoost优先保护标签持有者的信息，并旨在与原始的XGBoost算法一样准确。"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:11
msgid ""
"When compared to its MPC technology-powered counterpart, secret sharing-"
"based XGB, SecureBoost is often faster. More specifically, SecureBoost is"
" computationally more expensive than ss_xgb, but the latter is often "
"bound by network bandwidth. In other words, SecureBoost is much faster "
"when we have more CPU power but less network resources."
msgstr "与其MPC技术驱动的对应物——基于密钥共享的XGB相比，SecureBoost通常更快。更具体地说，SecureBoost的计算成本比ss_xgb高，但后者通常受到网络带宽的限制。换句话说，当我们拥有更多的CPU计算资源但较少的网络资源时，SecureBoost更快。"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:13
msgid ""
"Our implementation of SecureBoost offers high performance and cutting-"
"edge speed, supported by HEU devices."
msgstr "得到了HEU设备的支持, 我们的SecureBoost实现提供了高性能和尖端速度。"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:15
msgid "Tutorial"
msgstr "教程"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:17
msgid ""
"Please check out this simple "
"[tutorial](../../../tutorial/SecureBoost.ipynb)."
msgstr "请查看这个简单的[教程](../../../tutorial/SecureBoost.ipynb)"

#: ../../components/federated_learning/vertical_federated_learning/tree.md:19
msgid "Security Warning"
msgstr ""

#: ../../components/federated_learning/vertical_federated_learning/tree.md:21
msgid ""
"Please note that the federated tree model algorithm "
"(SecureBoost)[https://arxiv.org/abs/1901.08755] is not a provably secure "
"algorithm. There exist known "
"(attacks)[https://arxiv.org/pdf/2011.09290.pdf] that could lead to data "
"leakage. Therefore, we recommend using (MPC-"
"XGB)[https://arxiv.org/abs/2005.08479] instead of SecureBoost when data "
"security is a concern, which is implemented in [Decision "
"Trees](../../mpc_ml/decision_tree.rst)."
msgstr ""
"请注意，联邦树模型算法 (SecureBoost)[https://arxiv.org/abs/1901.08755] "
"不是可证明安全的算法。存在可能导致数据泄露的已知（攻击）[https://arxiv.org/pdf/2011.09290.pdf]。因此，当担心数据安全时，我们建议使用"
" (MPC-XGB)[https://arxiv.org/abs/2005.08479] 而不是 SecureBoost，隐语中的相关实现参见[决策树](../../mpc_ml/decision_tree.rst)。"

