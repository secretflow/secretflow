# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Ant Group Co., Ltd.
# This file is distributed under the same license as the SecretFlow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: SecretFlow \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-03-26 18:30+0800\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.17.0\n"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:9
msgid "Horizontal Federated Learning for Image Classification"
msgstr "水平联邦：图像分类"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:20
msgid ""
"The following codes are demos only. It’s **NOT for production** due to "
"system security concerns, please **DO NOT** use it directly in "
"production."
msgstr ""
"注意： "
"以下代码仅供演示用途，在演示过程中可能会揭露部分信息。** 请勿直接将此示例代码用于实际生产环境中。** 在实际部署前，请根据您的具体需求和安全标准进行必要的修改和调整。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:31
msgid ""
"In this tutorial, we will use the image classification task to show how "
"to complete the horizontal federated learning task in the ``SecretFlow`` "
"framework. The ``SecretFlow`` framework provides a user-friendly API that"
" makes it easy to apply your Keras or PyTorch model to a federated "
"learning scenario as a federated learning model. In the following "
"tutorial we will provide a step-by-step demonstration on how to transform"
" your existing model into a federated model using ``SecretFlow``, "
"enabling you to perform federated multi-party modeling tasks."
msgstr ""
"在这个教程中，我们将使用图像分类任务来介绍在 ``secretflow`` 框架下怎样来完成水平联邦学习任务。``secretflow`` "
"框架提供了一套用户友好的api，可以很方便的将您的keras模型或者pytorch模型应用到联邦学习场景，成为联邦学习模型。在接下来的教程中我们将手把手演示，如何将您已有的模型变成secretflow下的联邦模型，完成联邦多方建模任务。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:44
msgid "What is Federated Learning"
msgstr "水平联邦学习概念"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:55

msgid ""
"The federated learning discussed here specifically refers to horizontal "
"federated learning, which involves the collaboration of samples. This "
"approach is suitable for scenarios where all participating parties "
"operate in the same business domain but serve different customer groups. "
"By combining samples from multiple parties, a joint model with improved "
"overall performance or better generalization capability can be trained. "
"For example, in the medical field, each hospital has its own unique "
"patient group, and hospitals in different regions have little to no "
"overlap in their patient populations. However, their diagnostic records "
"(such as medical images and blood tests) are of the same type."
msgstr "这里的联邦学习特指的是水平场景的联邦学习，也就是样本的联合。这种模式适用于各个参与方业务相同，但触达的客户群不同，这种情况可以联合多方的样本来训练一个性能更好或者泛化性能更好的联合模型。比如在医疗场景，每个医院都有自己独特的病人群，各个地区的医院之间几乎是互不重叠，但是他们对于病历的检查记录（如影像，血检等）又是相同类型的。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:67
msgid "|efb0c49844874e14ac2784f3ffaca62f|"
msgstr ""

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:69
msgid "federate_learning.png"
msgstr "使用SecretFlow进行联邦学习"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:81

msgid "Training process:"
msgstr "训练流程："

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:83
msgid "Each participant downloads the latest model from the server."
msgstr "各个参与方从服务器下载最新的模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:84

msgid ""
"Each participant trains the model using its local data and uploads "
"encrypted gradient (or encrypted parameter) to the server. The server "
"collects the encrypted gradients (or parameters) from all participants, "
"performs secure aggregation, and updates the model parameters "
"accordingly."
msgstr ""
"每个参与方利用本方的本地数据训练模型，将梯度加密（或者将参数加密）上传给服务器，服务器得到各方上传上来的加密梯度（加密参数）在服务端进行安全聚合，用聚合后的梯度更新模型参数。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:85
msgid "The server returns the updated model to each participant."
msgstr "服务器将更新后的模型返回给各个参与方"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:86
msgid ""
"Each participant updates its local model and prepares for the next "
"training round."
msgstr "各个参与方更新各自的模型，准备下一次训练"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:98

msgid "Federated Learning on SecretFlow"
msgstr "使用SecretFlow进行联邦学习"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:120

msgid ""
"Create three entities [Alice, Bob, Charlie] in the SecretFlow "
"environment. Alice, Bob and Charlie are the three PYUs, where Alice and "
"Bob act as clients, and Charlie acts as the server."
msgstr ""
"在secretflow环境创造3个实体[Alice，Bob，Charlie]，其中 Alice, Bob和Charlie "
"是三个PYU，Alice和Bob角色是client，Charlie角色是server。 "

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:211

msgid "Prepare Training Data"
msgstr "准备训练数据"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:213
msgid "Alice and Bob each own half the data."
msgstr "Alice 和 Bob 各自拥有一半的数据。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:241

msgid ""
"``x_train``, ``y_train``, ``x_test``, ``y_test`` are all ``FedNdarray``. "
"Let’s take a look at the data obtained from ``FedNdarray``. "
"``FedNdarray`` is a virtual ``Ndarray`` built on a multi-party concept to"
" protect data privacy. The underlying data is stored separately by each "
"participant, and operations on ``FedNdarray`` are performed locally by "
"each participant on their own data. Neither the server nor other clients "
"have access to the raw data. For demonstration purposes, we will manually"
" download the data to the driver. **This data will be used later for "
"comparison with a single-party model**."
msgstr ""
"``x_train``, ``y_train``, ``x_test``, ``y_test`` 都是 "
"``FedNdarray``.我们来看一下获得到的FedNdarray数据，FedNdarray是一个构建在多方概念上的虚拟的Ndarray，目的是保护数据隐私。底层数据存储在各个参与方，对于FedNdarray的操作，实际上只是各个参与方对自己的local数据做操作。server端或者其他client不会接触到原始的数据。这里为了方便演示，我们手动把数据下载到driver端。"
" **这个数据在后面的单方模型对比使用**。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:268

msgid ""
"Let’s grab some samples from the dataset and visualize them to see what "
"the data looks like for both Alice and Bob."
msgstr "让我们从数据集中抓取一些样本，通过可视化的方法来看看，在Alice和Bob两方的数据是什么样？"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:330
msgid ""
"It can be seen from the two examples above that Alice and Bob have the "
"same data types and tasks, but the samples differ because they reach "
"different user groups. Now, let’s take the ``FedNdarray`` we obtained "
"earlier and split it into training and testing sets for the subsequent "
"training tasks."
msgstr "从上面两个例子可以看出，Alice和Bob的数据类型和任务都是一致的，但是由于触达的用户群不同，所以样本会有差别。让我们再次拿出之前已经得到的FedNdarray，并对他们做训练接和测试集的拆分来交给后面的训练任务。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:342
msgid "Define Model"
msgstr "定义模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:388
msgid "Training FL Model"
msgstr "训练模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:399
msgid "Import packages"
msgstr "导入包"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:421

msgid "Define model"
msgstr "定义模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:444

msgid ""
"Define the device list for the training participants, which includes the "
"PYUs of each participant prepared earlier."
msgstr "定义参与训练的device_list，即之前准备好的各个参与方的PYU。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:465

msgid ""
"Define aggregator The SecretFlow framework provides a variety of "
"aggregation schemes, including ``SecureAggregator`` and "
"``PPUAggregator``, which can be used for secure aggregation. To learn "
"more information about aggregation, see `Secure Aggregator "
"<../developer/algorithm/secure_aggregation.ipynb>`__."
msgstr ""
"隐语提供了多种聚合方案，SecureAggregator和PPUAggregator可用于安全聚合，更多安全聚合方案可以参考 `安全聚合 "
"<../developer/algorithm/secure_aggregation.ipynb>`__。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:516

msgid "Define FL model"
msgstr "定义联邦模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:590

msgid "Train FL model"
msgstr "训练模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1275
msgid "Contrast experiment to local training"
msgstr "对比单方模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1287
msgid "Model"
msgstr "模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1289
msgid "The model structure is consistent with the fl model above."
msgstr "模型结构和上面fl的模型保持一致。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1301
msgid "Data"
msgstr "数据"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1303
msgid ""
"Similarly, the data used is the MNIST dataset. For the single-party "
"model, we only used the horizontally segmented data from ``Alice``, with "
"a total of 10,000 samples."
msgstr "数据同样使用mnist数据集，单方模型这里我们只是用了切分后的 ``Alice`` 方数据共10000个样本。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1526

msgid ""
"The two experiments above simulate a typical training problem in a "
"horizontal federated learning scenario. Alice and Bob each have the same "
"type of data, but each party only has a portion of the samples. However, "
"their training objectives are the same. If Alice trains the model using "
"only her own data, she achieves an accuracy of 0.969. But if Bob’s data "
"is combined, a model with an accuracy close to 0.983 can be obtained. "
"Moreover, the model trained with data from multiple parties exhibits "
"better generalization performance."
msgstr "上面两个实验模拟了一个典型的水平联邦场景的训练问题，Alice和Bob拥有类型的图片，每一方只有样本的一部分数据，但是双方的训练目的是一致的如果Alice只用自己的一方数据来训练模型，能够得到一个精确度0.969的模型，但是如果联合Bob的数据之后，可以获得一个精确度接近0.983的模型，而且多方数据联合训练的模型的泛化性能也会更好。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1539
msgid "Summary"
msgstr "总结"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1541

msgid ""
"This tutorial introduces what federated learning is and how to perform "
"horizontal federated learning in ``SecretFlow``."
msgstr "本篇我们介绍了什么是联邦学习，以及如何在secretflow框架下进行水平联邦学习。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1542

msgid ""
"As shown in the experimental data, horizontal federated learning can "
"improve model performance by expanding the sample size and combining "
"multi-party training."
msgstr "从实验数据可以看出，水平联邦通过扩充样本量，联合多方训练可以提升模型效果。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1543

msgid ""
"This tutorial demonstrates using a SecureAggregator, and SecretFlow "
"provides various aggregation schemes. For more infomation, see `Secure "
"Aggregation <../developer/algorithm/secure_aggregation.ipynb>`__."
msgstr ""
"本文档使用了安全聚合（SecureAggregator）来做演示，secretflow提供了多种聚合方案，您可以在 `安全聚合 "
"<../developer/algorithm/secure_aggregation.ipynb>`__ 了解更多信息。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1544
msgid ""
"Next, you might want to try using different datasets. You’ll need to "
"perform vertical data splitting first, and then follow the process "
"outlined in this tutorial."
msgstr "接下来，你可能想尝试不同的数据集，您需要先将数据集进行垂直切分，然后按照本教程的流程进行。"



