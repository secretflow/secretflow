# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022 Ant Group Co., Ltd.
# This file is distributed under the same license as the SecretFlow package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: SecretFlow \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-07-22 12:05+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.15.0\n"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:9
msgid "Federated Learning for Image Classification"
msgstr "水平联邦：图像分类"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:20
#, fuzzy
msgid ""
"The following codes are demos only. It’s **NOT for production** due to "
"system security concerns, please **DO NOT** use it directly in "
"production."
msgstr "注意： 以下代码仅供演示用途，在演示过程中可能会揭露部分信息。请勿直接将此示例代码用于实际生产环境中。在实际部署前，请根据您的具体需求和安全标准进行必要的修改和调整。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:31
msgid ""
"In this tutorial, we will use the image classification task to show how "
"to complete the horizontal federated learning task in the ``SecretFlow`` "
"framework. The ``SecretFlow`` framework provides a user-friendly API that"
" makes it easy to apply your Keras or PyTorch model to a federated "
"learning scenario as a federated learning model. In the rest of the "
"tutorial we will show you how to turn your existing model into a "
"federated model in ``SecretFlow`` to complete federated multi-party "
"modeling tasks."
msgstr ""
"在这个教程中，我们将使用图像分类任务来介绍在 ``secretflow`` 框架下怎样来完成水平联邦学习任务。"
"``secretflow`` 框架提供了一套用户友好的api，可以很方便的将您的keras模型或者pytorch模型应用到联邦学习场景，"
"成为联邦学习模型。在接下来的教程中我们将手把手演示，如何将您已有的模型变成secretflow下的联邦模型，完成联邦多方建模任务。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:44
msgid "What is Federated Learning"
msgstr "水平联邦学习概念"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:55
msgid ""
"The federated learning discussed here is specifically focused on "
"horizontal scenarios, where each participant shares the same business but"
" reaches different customer groups. This allows samples from different "
"parties to be combined to train a joint model with improved performance. "
"An example of this scenario can be found in the medical field, where each"
" hospital has its own distinctive patient group and hospitals in "
"different regions largely do not overlap. However, their medical records "
"(such as images and blood tests) for diagnostic purposes are of the same "
"type."
msgstr "这里的联邦学习特指的是水平场景的联邦学习，也就是样本的联合。这种模式适用于各个参与方业务相同，但触达的客户群不同，这种情况可以联合多方的样本来训练一个性能更好或者泛化性能更好的联合模型。比如在医疗场景，每个医院都有自己独特的病人群，各个地区的医院之间几乎是互不重叠，但是他们对于病历的检查记录（如影像，血检等）又是相同类型的。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:67
msgid "|29eed3a02f304ffdb81a9cd3337b6547|"
msgstr ""

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:69
msgid "federate_learning.png"
msgstr "使用SecretFlow进行联邦学习"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:81
#, fuzzy
msgid "Training process:"
msgstr "训练模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:83
msgid "Each participant downloads the latest model from the server."
msgstr ""

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:84
#, fuzzy
msgid ""
"Each participant uses its own local data to train the model, and uploads "
"gradient encryption (or parameter encryption) to the server, which "
"obtains the encryption gradient (encryption parameter) uploaded by all "
"parties for security aggregation at the server, and updates model "
"parameters with the aggregated gradient."
msgstr ""
"训练流程： 1. 各个参与方从服务器下载最新的模型 2. "
"每个参与方利用本方的本地数据训练模型，将梯度加密（或者将参数加密）上传给服务器，服务器得到各方上传上来的加密梯度（加密参数）在服务端进行安全聚合，用聚合后的梯度更新模型参数。"
" 3. 服务器将更新后的模型返回给各个参与方 4. 各个参与方更新各自的模型，准备下一次训练。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:85
msgid "The server returns the updated model to each participant."
msgstr ""

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:86
msgid "Each participant updates their local model, and prepare next training."
msgstr ""

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:98
msgid "Federated learning on SecretFlow"
msgstr "使用SecretFlow进行联邦学习"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:120
msgid ""
"Create 3 entities in the Secretflow environment [Alice, Bob, Charlie]. "
"Alice, Bob and Charlie are the three PYUs. Alice and Bob to be the "
"clients and Charlie to be the server."
msgstr ""
"在secretflow环境创造3个实体[Alice，Bob，Charlie]，其中 Alice, Bob和Charlie "
"是三个PYU，Alice和Bob角色是client，Charlie角色是server。 "

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:211
msgid "Prepare Data"
msgstr "准备训练数据"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:213
msgid "Alice and Bob each own half the data."
msgstr "Alice 和 Bob 各自拥有一半的数据。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:241
#, fuzzy
msgid ""
"``x_train``, ``y_train``, ``x_test``, ``y_test`` are both ``FedNdarray``."
" Let’s take a look at the data obtained from FedNdarray. FedNdarray is a "
"virtual Ndarray built on a multi-party concept to protect data privacy. "
"The underlying data is stored in each participant. The FedNdarray "
"operation is actually performed by each participant on their own local "
"data. The server or other clients do not touch the original data. For "
"demonstration purposes, we will manually download the data to the driver."
" **This data will be used later in the unilateral model comparison**."
msgstr ""
"``x_train``, ``y_train``, ``x_test``, ``y_test`` 都是 "
"``FedNdarray``.我们来看一下获得到的FedNdarray数据，FedNdarray是一个构建在多方概念上的虚拟的Ndarray，目的是保护数据隐私。底层数据存储在各个参与方，对于FedNdarray的操作，实际上只是各个参与方对自己的local数据做操作。server端或者其他client不会接触到原始的数据。这里为了方便演示，我们手动把数据下载到driver端。"
" **这个数据在后面的单方模型对比使用**。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:268
#, fuzzy
msgid ""
"Let’s grab some samples from the data set, and just visually see, what "
"does the data look like for Both Alice and Bob?"
msgstr "让我们从数据集中抓取一些样本，通过可视化的方法来看看，在Alice和Bob两方的数据是什么样？"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:330
msgid ""
"It can be seen from the above two examples that the data types and tasks "
"of Alice and Bob are consistent, but the samples are different due to the"
" different user groups they reach."
msgstr "从上面两个例子可以看出，Alice和Bob的数据类型和任务都是一致的，但是由于触达的用户群不同，所以样本会有差别。让我们再次拿出之前已经得到的FedNdarray，并对他们做训练接和测试集的拆分来交给后面的训练任务。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:342
#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:421
msgid "Define Model"
msgstr "定义模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:388
msgid "Training FL Model"
msgstr "训练模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:399
msgid "Import packages"
msgstr "导入包"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:444
msgid ""
"Define the device list for participating training, which is the PYUS of "
"each participant prepared previously."
msgstr "定义参与训练的device_list，即之前准备好的各个参与方的PYU。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:465
msgid ""
"Define Aggregator The SecretFlow framework provides a variety of "
"aggregation schemes, including ``SecureAggregator`` and "
"``PPUAggregator``, which can be used for secure aggregation. To learn "
"more information about aggregation, see `Secure Aggregator "
"<../developer/algorithm/secure_aggregation.ipynb>`__."
msgstr ""
"隐语提供了多种聚合方案，SecureAggregator和PPUAggregator可用于安全聚合，更多安全聚合方案可以参考 `安全聚合 "
"<../developer/algorithm/secure_aggregation.ipynb>`__。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:516
#, fuzzy
msgid "Define FLModel"
msgstr "定义联邦模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:590
msgid "Lets run model"
msgstr "跑起来"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1275
msgid "Contrast experiment to local training"
msgstr "对比单方模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1287
msgid "Model"
msgstr "模型"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1289
msgid "The model structure is consistent with the fl model above."
msgstr "模型结构和上面fl的模型保持一致。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1301
msgid "Data"
msgstr "数据"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1303
#, fuzzy
msgid ""
"Here, we only used data after a horizontal segmentation, with a total of "
"10,000 samples for ``Alice``."
msgstr "数据同样使用mnist数据集，单方模型这里我们只是用了切分后的Alice方数据共20000个样本。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1526
#, fuzzy
msgid ""
"The two experiments above simulated a training problem in a typical "
"horizontal federation scenario, Alice and Bob have same type of data. "
"Each side had only a portion of the sample, but the training objectives "
"is the same. If Alice only uses her own data to train the model, could "
"only obtain a model with an accuracy of 0.969. However, if Bob’s data is "
"combined, a model with an accuracy close to 0.983 can be obtained. In "
"addition, the generalization performance of the model jointly trained "
"with multi-party data will also be better."
msgstr "上面两个实验模拟了一个典型的水平联邦场景的训练问题，Alice和Bob拥有类型的图片，每一方只有样本的一部分数据，但是双方的训练目的是一致的如果Alice只用自己的一方数据来训练模型，能够得到一个精确度0.969的模型，但是如果联合Bob的数据之后，可以获得一个精确度接近0.983的模型，而且多方数据联合训练的模型的泛化性能也会更好。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1539
msgid "Conclusion"
msgstr "总结"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1541
msgid ""
"This tutorial introduces what federated learning is and how to perform "
"horizontal federated learning in ``secretFlow``."
msgstr "本篇我们介绍了什么是联邦学习，以及如何在secretflow框架下进行水平联邦学习。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1542
msgid ""
"It can be seen from the experimental data that horizontal federation can "
"improve the model effect by expanding the sample size and combining "
"multi-party training."
msgstr "从实验数据可以看出，水平联邦通过扩充样本量，联合多方训练可以提升模型效果。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1543
msgid ""
"This tutorial uses a SecureAggregator to demonstrate, and secretflow "
"provides a variety of aggregation schemes，for more infomation, see "
"`Secure Aggregation <../developer/algorithm/secure_aggregation.ipynb>`__."
msgstr ""
"本文档使用了安全聚合（SecureAggregator）来做演示，secretflow提供了多种聚合方案，您可以在 `安全聚合 "
"<../developer/algorithm/secure_aggregation.ipynb>`__ 了解更多信息。"

#: ../../tutorial/Federate_Learning_for_Image_Classification.ipynb:1544
msgid ""
"next, you can use your data or model to explore how to do federate "
"learning."
msgstr "下一步，你可能想尝试不同的数据集，您需要先将数据集进行垂直切分，然后按照本教程的流程进行。"

