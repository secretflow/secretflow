#!/usr/bin/env python3
# *_* coding: utf-8 *_*

# Copyright 2022 Ant Group Co., Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging
import math
import multiprocessing
import os
from typing import Callable, Dict, Iterable, List, Tuple, Union

import secretflow.distributed as sfd
from secretflow.data import Partition
from secretflow.data.horizontal import HDataFrame
from secretflow.data.ndarray import FedNdarray
from secretflow.data.vertical import VDataFrame
from secretflow.device import PYU, Device, reveal, wait
from secretflow.device.device.pyu import PYUObject
from secretflow.distributed.const import DISTRIBUTION_MODE
from secretflow.utils.random import global_random
from secretflow_fl.ml.nn.callbacks.callbacklist import CallbackList
from secretflow_fl.ml.nn.sl.agglayer.agg_layer import AggLayer
from secretflow_fl.ml.nn.sl.agglayer.agg_method import AggMethod
from secretflow_fl.ml.nn.sl.base import SLBaseModel
from secretflow_fl.ml.nn.sl.strategy_dispatcher import dispatch_strategy
from secretflow_fl.security.privacy import DPStrategy


class SLModel:
    def __init__(
        self,
        base_model_dict: Dict[Device, Callable[[], "tensorflow.keras.Model"]] = {},
        device_y: PYU = None,
        model_fuse: Callable[[], "tensorflow.keras.Model"] = None,
        dp_strategy_dict: Dict[Device, DPStrategy] = None,
        random_seed: int = None,
        backend: str = "tensorflow",
        strategy="split_nn",
        agg_method: AggMethod = None,
        **kwargs,
    ):
        """Interface for vertical split learning
        Attributes:
            base_model_dict: Basemodel dictionary, key is PYU, value is the Basemodel defined by party.
            device_y: Define which model have label.
            model_fuse:  Fuse model definition.
            dp_strategy_dict: Dp strategy dictionary.
            random_seed: If specified, the initial value of the model will remain the same, which ensures reproducible.
            backend: name of backend engine, tensorflow or torch, default tensorflow
            strategy: Strategy of split learning.
            agg_method: agg method decide how to aggregate hiddens from each parties, default None(compatible with legacy mode)
        Keyword Args
            simulation: Only need when use simulation mode
            base_local_steps: Only for 'split_async' strategy, Number of rounds for local base update process
            fuse_local_steps: Only for 'split_async' strategy, Number of rounds for local fuse update process
            bound_param: Only for 'split_async' strategy, Parameter for limiting local gradient change
            loss_thres: Only for 'split_state_async' strategy, Loss threshold triggering switch state in splitStateAS strategy
            split_steps: Only for 'split_state_async' strategy, Number of batches triggering switch state in splitStateAS strategy
            max_fuse_local_steps: Only for 'split_state_async' strategy, Maximum number of rounds for fuse local update in splitStateAS strategy?
            compressor: Define strategy tensor compression algorithms to speed up transmission.
            device_agg: The party do aggregation, it can be a PYU, SPU, etc.
            use_base_loss: Optimize base model with base model local loss and return gradients.
            **kwargs: For custom strategies.
        """

        self.device_y = device_y
        self.dp_strategy_dict = dp_strategy_dict
        self.simulation = kwargs.pop("simulation", False)
        self.device_agg = kwargs.pop("device_agg", None)
        self.compressor = kwargs.pop("compressor", None)
        self.base_model_dict = base_model_dict
        self.backend = backend
        self.num_parties = len(base_model_dict)
        self.agglayer = AggLayer(
            device_agg=self.device_agg if self.device_agg else self.device_y,
            parties=list(base_model_dict.keys()),
            device_y=self.device_y,
            agg_method=agg_method,
            backend=backend,
            compressor=self.compressor,
        )
        self.pipeline_size = kwargs.get("pipeline_size", 1)
        assert self.pipeline_size >= 1, f"invalid pipeline size: {self.pipeline_size}"

        if backend.lower() == "tensorflow":
            import secretflow_fl.ml.nn.sl.backend.tensorflow.strategy  # noqa
        elif backend.lower() == "torch":
            import secretflow_fl.ml.nn.sl.backend.torch.strategy  # noqa
        else:
            raise Exception(f"Invalid backend = {backend}")
        worker_list = list(base_model_dict.keys())
        if device_y not in worker_list:
            worker_list.append(device_y)
        self._workers: Dict[PYU, SLBaseModel] = {}
        self.history = None
        num_gpus = kwargs.get("num_gpus", None)
        if num_gpus and sfd.get_distribution_mode() != DISTRIBUTION_MODE.DEBUG:
            raise NotImplementedError(
                "SLModel only support to use gpu in debug mode, try start with debug mode in sf.init()"
            )
        for device in worker_list:
            self._workers[device], self.check_skip_grad = dispatch_strategy(
                strategy,
                backend=backend,
                builder_base=(
                    base_model_dict[device]
                    if device in base_model_dict.keys()
                    else None
                ),
                builder_fuse=None if device != device_y else model_fuse,
                random_seed=random_seed,
                dp_strategy=(
                    dp_strategy_dict.get(device, None) if dp_strategy_dict else None
                ),
                device=device,
                **kwargs,
            )

    def handle_data(
        self,
        x: Union[
            VDataFrame,
            FedNdarray,
            List[Union[HDataFrame, VDataFrame, FedNdarray]],
        ],
        y: Union[FedNdarray, VDataFrame, PYUObject] = None,
        sample_weight: Union[FedNdarray, VDataFrame] = None,
        batch_size=32,
        shuffle=False,
        epochs=1,
        stage="train",
        random_seed=1234,
        dataset_builder: Dict = None,
    ):
        if isinstance(x, (VDataFrame, FedNdarray)):
            x = [x]
        for i in range(len(x)):
            if isinstance(x[i], (VDataFrame, HDataFrame)):
                x[i] = x[i].to_pandas()
        if isinstance(y, (VDataFrame)):
            y = y.to_pandas()
        worker_steps = []
        for device, worker in self._workers.items():
            if device == self.device_y and y is not None:
                if isinstance(y, FedNdarray):
                    y_partitions = y.partitions[device]
                elif isinstance(y, VDataFrame):
                    y_partitions = y.partitions[device].data
                else:
                    assert y.device == device, f"label must be located in device_y"
                    y_partitions = y

                s_w_partitions = (
                    sample_weight.partitions[device]
                    if sample_weight is not None
                    else None
                )
            else:
                y_partitions = None
                s_w_partitions = None
            if dataset_builder:
                # in dataset builder mode, xi cannot be none, or else datasetbuilder in worker cannot parse label
                xs = (
                    [
                        (
                            xi.partitions[device].data  # xi is FedDataframe
                            if isinstance(xi.partitions[device], Partition)
                            else xi.partitions[device]
                        )  # xi is FedNdarray
                        for xi in x
                    ]
                    if device in dataset_builder
                    else [None]
                )
                if device not in dataset_builder:
                    logging.warning(f"party={device} does not provide dataset_builder")
                    dataset_partition = None
                    if device in self.base_model_dict:
                        raise Exception(
                            "dataset builder must be supply when base_net is not none"
                        )
                else:
                    dataset_partition = dataset_builder[device]
                ret = worker.build_dataset_from_builder(
                    *xs,
                    y=y_partitions,
                    s_w=s_w_partitions,
                    batch_size=batch_size,
                    random_seed=random_seed,
                    stage=stage,
                    dataset_builder=dataset_partition,
                )
                worker_steps.append(ret)

            else:
                # if don't have feature, driver will pass None to device worker
                xs = (
                    [xi.partitions[device] for xi in x]
                    if device in self.base_model_dict
                    else [None]
                )
                xs = [t.data if isinstance(t, Partition) else t for t in xs]
                worker.build_dataset_from_numeric(
                    *xs,
                    y=y_partitions,
                    s_w=s_w_partitions,
                    batch_size=batch_size,
                    buffer_size=batch_size * 8,
                    shuffle=shuffle,
                    repeat_count=epochs,
                    stage=stage,
                    random_seed=random_seed,
                )
        parties_length = [shape[0] for shape in x[0].partition_shape().values()]
        assert len(set(parties_length)) == 1, "length of all parties must be same"
        steps_per_epoch = math.ceil(parties_length[0] / batch_size)
        if dataset_builder:
            worker_steps_per_epoch = reveal(worker_steps)
            worker_steps_per_epoch = [
                steps for steps in worker_steps_per_epoch if steps != -1
            ]
            assert len(set(worker_steps_per_epoch)) == 1, (
                f"steps_per_epoch of all parties must be same, got {set(worker_steps_per_epoch)}."
                "Please check whether the batchsize or steps_per_epoch of all parties are consistent"
            )
            # set worker_steps_per_epoch[0] to steps_per_epoch if databuilder return steps_per_epoch else use driver calculate result
            if worker_steps_per_epoch[0] > 0:
                steps_per_epoch = worker_steps_per_epoch[0]

        self._workers[self.device_y].set_steps_per_epoch(steps_per_epoch)
        return steps_per_epoch

    def handle_file(
        self,
        train_dict: Dict[PYU, str],
        label: Union[str, List[str], Tuple[str]] = None,
        sample_weight: Union[FedNdarray, VDataFrame] = None,
        batch_size=32,
        shuffle=False,
        epochs=1,
        stage="train",
        random_seed=1234,
        dataset_builder: Dict = None,
    ):
        worker_steps = []
        for device, worker in self._workers.items():
            s_w_partitions = (
                sample_weight.partitions[device] if sample_weight is not None else None
            )
            if dataset_builder:
                if device not in dataset_builder:
                    logging.warning("party={device} does not provide dataset_builder")
                    dataset_partition = None
                    if device in self.base_model_dict:
                        raise Exception(
                            "dataset builder must be supply when base_net is not none"
                        )
                else:
                    dataset_partition = dataset_builder[device]
                ret = worker.build_dataset_from_builder(
                    train_dict[device],
                    y=label if self.device_y == device else None,
                    s_w=s_w_partitions,
                    batch_size=batch_size,
                    random_seed=random_seed,
                    stage=stage,
                    dataset_builder=dataset_partition,
                )
                worker_steps.append(ret)

            else:
                ret = worker.build_dataset_from_csv(
                    file_path=train_dict[device],
                    label=label if self.device_y == device else None,
                    s_w=s_w_partitions,
                    batch_size=batch_size,
                    shuffle=shuffle,
                    repeat_count=epochs,
                    random_seed=random_seed,
                    stage=stage,
                )
                worker_steps.append(ret)
        worker_steps_per_epoch = reveal(worker_steps)
        worker_steps_per_epoch = [
            steps for steps in worker_steps_per_epoch if steps != -1
        ]
        assert len(set(worker_steps_per_epoch)) == 1, (
            "steps_per_epoch of all parties must be same, "
            "Please check whether the batchsize or steps_per_epoch of all parties are consistent"
        )
        steps_per_epoch = worker_steps_per_epoch[0]
        self._workers[self.device_y].set_steps_per_epoch(steps_per_epoch)

        return steps_per_epoch

    def fit(
        self,
        x: Union[
            VDataFrame,
            FedNdarray,
            List[Union[HDataFrame, VDataFrame, FedNdarray]],
            Dict[PYU, str],
        ],
        y: Union[VDataFrame, FedNdarray, PYUObject, str, List[str], Tuple[str]],
        batch_size=32,
        epochs=1,
        verbose=1,
        callbacks=None,
        validation_data: Tuple = None,
        shuffle=False,
        sample_weight=None,
        validation_freq=1,
        dp_spent_step_freq=None,
        dataset_builder: Callable[[List], Tuple[int, Iterable]] = None,
        audit_log_dir: str = None,
        audit_log_params: dict = {},
        early_stopping_batch_step: int = 0,
        early_stopping_warmup_step: int = 0,
        random_seed: int = None,
    ):
        """Vertical split learning training interface

        Args:
            x: Input data. It could be:

            - VDataFrame: a vertically aligned dataframe.
            - FedNdArray: a vertically aligned ndarray.
            - List[Union[HDataFrame, VDataFrame, FedNdarray]]: list of dataframe or ndarray.
            - Dict[PYU, str]: dict of PYU and its input data file path, for performance, dtypes need to be provided.

            y: Target data. It could be:
            - VDataFrame.
            - FedNdarray which has only one partition.
            - PYUObject.
            - str: when x is a Dict file path, y is the label name of the input dataset.

            batch_size: Number of samples per gradient update.
            epochs: Number of epochs to train the model
            verbose: 0, 1. Verbosity mode
            callbacks: List of Callback or Dict[device, Callback]. Callback can be secretflow_fl.ml.nn.callbacks:
            validation_data: of Data on which to validate, it could be:
            - A tuple of (test_data, test_label) with the data of type VDataFrame or FedNdarray.
            - A tuple of (test_data, test_label, valid_sample_weight)
            - A tuple of (Dict[PYU, str], str) when requires the file inputs just like x and y..
            shuffle: Whether shuffle dataset or not
            validation_freq: specifies how many training epochs to run before a new validation run is performed
            sample_weight: weights for the training samples
            dp_spent_step_freq: specifies how many training steps to check the budget of dp
            dataset_builder: Callable function, its input is `x` or `[x, y]` if y is set, it should return a
                dataset.
            audit_log_dir: If audit_log_dir is set, audit model will be enabled
            audit_log_params: Kwargs for saving audit model, eg: {'save_traces'=True, 'save_format'='h5'}
            random_seed: seed for prg, will only affect dataset shuffle
            dtypes: Dict[PYU, Dict[str, Dtype]]
        """
        if random_seed is None:
            random_seed = global_random(self.device_y, 100000)

        # record parameters
        params = locals()
        logging.info(f"SL Train Params: {params}")

        # sanity check
        assert (
            isinstance(batch_size, int) and batch_size > 0
        ), f"batch_size should be integer > 0"
        assert isinstance(validation_freq, int) and validation_freq >= 1
        if dp_spent_step_freq is not None:
            assert isinstance(dp_spent_step_freq, int) and dp_spent_step_freq >= 1

        # get basenet ouput num
        self.basenet_output_num = {
            device: reveal(worker.get_basenet_output_num())
            for device, worker in self._workers.items()
        }
        self.agglayer.set_basenet_output_num(self.basenet_output_num)

        # build dataset
        train_x, train_y = x, y
        if isinstance(train_x, Dict):
            assert isinstance(train_y, (str, List, Tuple)), (
                f"When the input x is type of Dict, the data will read from files, "
                f"and y must be a label name with type str/List[str]/Tuple[str]."
            )
            steps_per_epoch = self.handle_file(
                train_x,
                train_y,
                sample_weight=sample_weight,
                batch_size=batch_size,
                shuffle=shuffle,
                epochs=epochs,
                stage="train",
                random_seed=random_seed,
                dataset_builder=dataset_builder,
            )
        else:
            steps_per_epoch = self.handle_data(
                train_x,
                train_y,
                sample_weight=sample_weight,
                batch_size=batch_size,
                shuffle=shuffle,
                epochs=epochs,
                stage="train",
                random_seed=random_seed,
                dataset_builder=dataset_builder,
            )

        validation = False
        if validation_data is not None:
            assert isinstance(validation_data, tuple) and (
                len(validation_data) == 2 or len(validation_data) == 3
            ), f"validation_data must be tuple type with (test_x, test_y) or (test_x, test_y, valid_sample_weight)."
            validation = True
            logging.debug("validation_data provided")
            if len(validation_data) == 2:
                valid_x, valid_y = validation_data
                valid_sample_weight = None
            else:
                valid_x, valid_y, valid_sample_weight = validation_data
            assert (
                valid_x is not None and valid_y is not None
            ), f"Neither x nor y in validation data cannot be None."
            if isinstance(valid_x, Dict):
                assert isinstance(valid_y, (str, List, Tuple)), (
                    f"When the input x is type of Dict, the data will read from files, "
                    f"and y must be a label name with type str."
                )
                valid_steps = self.handle_file(
                    valid_x,
                    valid_y,
                    sample_weight=valid_sample_weight,
                    batch_size=batch_size,
                    epochs=epochs,
                    stage="eval",
                    dataset_builder=dataset_builder,
                )
            else:
                valid_steps = self.handle_data(
                    valid_x,
                    valid_y,
                    sample_weight=valid_sample_weight,
                    batch_size=batch_size,
                    epochs=epochs,
                    stage="eval",
                    dataset_builder=dataset_builder,
                )
        else:
            valid_x, valid_y, valid_sample_weight = None, None, None

        wait_steps = min(min(self.get_cpus()) * 2, 100)

        # setup callback list
        callbacks = CallbackList(
            callbacks=callbacks,
            add_history=True,
            add_progbar=verbose != 0,
            workers=self._workers,
            device_y=self.device_y,
            epochs=epochs,
            verbose=verbose,
            steps=steps_per_epoch,
        )

        callbacks.on_train_begin()

        for epoch in range(epochs):
            res = []
            report_list = []
            report_list.append(f"epoch: {epoch+1}/{epochs} - ")
            self._workers[self.device_y].reset_metrics()
            callbacks.on_epoch_begin(epoch=epoch)
            [worker.reset_data_iter(stage="train") for worker in self._workers.values()]
            f_data_buf = [None] * (self.pipeline_size - 1)
            for step in range(0, steps_per_epoch + self.pipeline_size - 1):
                if step < steps_per_epoch:
                    f_datas = {}
                    callbacks.on_train_batch_begin(step)

                    [
                        worker.get_batch_data(stage="train", epoch=epoch)
                        for worker in self._workers.values()
                    ]

                    callbacks.on_base_forward_begin()
                    # 1. Local calculation of basenet
                    [worker.base_forward() for worker in self._workers.values()]
                    callbacks.on_base_forward_end()

                    for device, worker in self._workers.items():
                        f_data = worker.pack_forward_data()
                        f_datas[device] = f_data
                    f_data_buf.append(f_datas)
                # clean up buffer
                f_datas = f_data_buf.pop(0)
                # Async transfer hiddens to label side
                if f_datas is None:
                    continue
                # During pipeline strategy, the backpropagation process of the model will lag n cycles behind the forward propagation process.
                step = step - self.pipeline_size + 1

                # do agglayer forward
                callbacks.on_agglayer_forward_begin(hiddens=f_datas)
                # TODO(ian-huu): move `agg_hiddens.to(device_y)` after `on_agglayer_forward_end`
                agg_hiddens = self.agglayer.forward(f_datas)
                callbacks.on_agglayer_forward_end(agg_hiddens)

                # 3. Fusenet do local calculates and return gradients
                callbacks.on_fuse_forward_begin()
                # TODO(ian-huu): split fuse_net forward and backward for callbacks
                self._workers[self.device_y].fuse_net(agg_hiddens)
                callbacks.on_fuse_backward_end()
                gradients = self._workers[self.device_y].get_gradients()
                # In some strategies, we need to bypass the backpropagation step.
                skip_gradient = False
                if self.check_skip_grad:
                    skip_gradient = reveal(
                        self._workers[self.device_y].get_skip_gradient()
                    )

                if not skip_gradient:
                    # do agglayer backward
                    callbacks.on_agglayer_backward_begin(gradients)
                    scatter_gradients = self.agglayer.backward(gradients)
                    callbacks.on_agglayer_backward_end(scatter_gradients)
                    [
                        worker.set_gradients(scatter_gradients[device])
                        for device, worker in self._workers.items()
                        if device in scatter_gradients.keys()
                    ]
                    callbacks.on_base_backward_begin()
                    [
                        worker.base_backward()
                        for device, worker in self._workers.items()
                        if device in scatter_gradients.keys()
                    ]
                    callbacks.on_base_backward_end()

                # for EarlyStoppingBatch, evalute model every early_stopping_batch_step
                if (
                    early_stopping_batch_step > 0
                    and step > early_stopping_warmup_step
                    and step % early_stopping_batch_step == 0
                ):
                    wait(res)
                    res = []
                    # as evaluation will change metrics' state(training stage),
                    # we temporarily save it here, and recover later
                    self._workers[self.device_y].staging_metric_states()

                    # validation
                    self._workers[self.device_y].reset_metrics()

                    callbacks.on_test_begin()
                    res = []
                    [
                        worker.reset_data_iter(stage="eval")
                        for worker in self._workers.values()
                    ]
                    for val_step in range(0, valid_steps):
                        callbacks.on_test_batch_begin(batch=val_step)
                        f_datas = {}  # driver end

                        [
                            worker.get_batch_data(stage="eval", epoch=epoch)
                            for worker in self._workers.values()
                        ]

                        callbacks.on_base_forward_begin()
                        # 1. Local calculation of basenet
                        [worker.base_forward() for worker in self._workers.values()]
                        callbacks.on_base_forward_end()

                        for device, worker in self._workers.items():
                            f_data = worker.pack_forward_data()
                            f_datas[device] = f_data
                        agg_hiddens = self.agglayer.forward(f_datas)

                        metrics = self._workers[self.device_y].evaluate(agg_hiddens)
                        res.append(metrics)
                        if len(res) == wait_steps:
                            wait(res)
                            res = []
                        callbacks.on_test_batch_end(batch=val_step)
                    wait(res)
                    callbacks.on_test_end(metrics)

                    callbacks.on_train_batch_end(step)

                    # recover metrics's state(training stage)
                    self._workers[self.device_y].recover_metric_states()

                    if callbacks.stop_training[0]:
                        break
                else:
                    callbacks.on_train_batch_end(step)

                res.append(gradients)

                if self.dp_strategy_dict is not None and dp_spent_step_freq is not None:
                    current_step = epoch * steps_per_epoch + step
                    if current_step % dp_spent_step_freq == 0:
                        privacy_device = {}
                        for device, dp_strategy in self.dp_strategy_dict.items():
                            privacy_dict = dp_strategy.get_privacy_spent(current_step)
                            privacy_device[device] = privacy_dict
                if len(res) == wait_steps:
                    wait(res)
                    res = []
            assert (
                len(f_data_buf) == 0
            ), f"hiddens buffer unfinished, len: {len(f_data_buf)}"
            if validation and epoch % validation_freq == 0:
                callbacks.on_test_begin()
                # validation
                self._workers[self.device_y].reset_metrics()
                [
                    worker.reset_data_iter(stage="eval")
                    for worker in self._workers.values()
                ]
                res = []
                for step in range(0, valid_steps):
                    callbacks.on_test_batch_begin(batch=step)
                    f_datas = {}  # driver end
                    [
                        worker.get_batch_data(stage="eval", epoch=epoch)
                        for worker in self._workers.values()
                    ]

                    callbacks.on_base_forward_begin()
                    # 1. Local calculation of basenet
                    [worker.base_forward() for worker in self._workers.values()]
                    callbacks.on_base_forward_end()

                    for device, worker in self._workers.items():
                        f_data = worker.pack_forward_data()
                        f_datas[device] = f_data
                    callbacks.on_agglayer_forward_begin(agg_hiddens)
                    agg_hiddens = self.agglayer.forward(f_datas)
                    callbacks.on_agglayer_forward_end(agg_hiddens)

                    metrics = self._workers[self.device_y].evaluate(agg_hiddens)
                    res.append(metrics)
                    if len(res) == wait_steps:
                        wait(res)
                        res = []
                    callbacks.on_test_batch_end(batch=step)
                wait(res)
                callbacks.on_test_end(metrics)
                # save checkpoint
                # TODO: Use checkpoint callback rewrite this logic @Juxing
                if audit_log_dir is not None:
                    epoch_base_model_path = {
                        device: os.path.join(
                            audit_log_dir,
                            "base_model",
                            device.party,
                            str(epoch),
                        )
                        for device in self._workers.keys()
                    }
                    epoch_fuse_model_path = os.path.join(
                        audit_log_dir,
                        "fuse_model",
                        str(epoch),
                    )
                    self.save_model(
                        base_model_path=epoch_base_model_path,
                        fuse_model_path=epoch_fuse_model_path,
                        is_test=self.simulation,
                        **audit_log_params,
                    )
            callbacks.on_epoch_end(epoch)
            # TODO: Need EarlystopCallback
            if callbacks.stop_training[0]:
                break

        callbacks.on_train_end()
        return callbacks.history

    def predict(
        self,
        x: Union[
            VDataFrame,
            FedNdarray,
            List[Union[HDataFrame, VDataFrame, FedNdarray]],
            Dict[PYU, str],
        ],
        batch_size=32,
        verbose=0,
        dataset_builder: Callable[[List], Tuple[int, Iterable]] = None,
        callbacks=None,
    ):
        """Vertical split learning offline prediction interface

        Args:
            x: Input data. It could be:

            - VDataFrame: a vertically aligned dataframe.
            - FedNdArray: a vertically aligned ndarray.
            - List[Union[HDataFrame, VDataFrame, FedNdarray]]: list of dataframe or ndarray.

            batch_size: Number of samples per gradient update, Int
            verbose: 0, 1. Verbosity mode
            dataset_builder: Callable function, its input is `x` or `[x, y]` if y is set, it should return
              steps_per_epoch and iterable dataset. Dataset builder is mainly for building graph dataset.
            callbacks: List of `keras.callbacks.Callback` instances.
        """

        assert (
            isinstance(batch_size, int) and batch_size > 0
        ), f"batch_size should be integer > 0"
        if isinstance(x, Dict):
            predict_steps = self.handle_file(
                x,
                None,
                batch_size=batch_size,
                stage="eval",
                epochs=1,
                dataset_builder=dataset_builder,
            )
        else:
            predict_steps = self.handle_data(
                x,
                None,
                batch_size=batch_size,
                stage="eval",
                epochs=1,
                dataset_builder=dataset_builder,
            )

        # setup callback list
        callbacks = CallbackList(
            callbacks=callbacks,
            add_history=True,
            add_progbar=verbose != 0,
            workers=self._workers,
            device_y=self.device_y,
            verbose=verbose,
            steps=predict_steps,
        )
        result = []
        wait_steps = min(min(self.get_cpus()) * 2, 100)
        res = []
        callbacks.on_predict_begin()
        [worker.reset_data_iter(stage="eval") for worker in self._workers.values()]
        for step in range(0, predict_steps):
            callbacks.on_predict_batch_begin(step)
            forward_data_dict = {}

            [
                worker.get_batch_data(stage="eval", epoch=0)
                for device, worker in self._workers.items()
                if device in self.base_model_dict
            ]

            callbacks.on_base_forward_begin()
            # 1. Local calculation of basenet
            [
                worker.base_forward()
                for device, worker in self._workers.items()
                if device in self.base_model_dict
            ]
            callbacks.on_base_forward_end()

            for device, worker in self._workers.items():
                if device not in self.base_model_dict:
                    continue
                f_data = worker.pack_forward_data()
                forward_data_dict[device] = f_data
            callbacks.on_agglayer_forward_begin(forward_data_dict)
            agg_hiddens = self.agglayer.forward(forward_data_dict)

            y_pred = self._workers[self.device_y].predict(agg_hiddens)
            result.append(y_pred)

            callbacks.on_predict_batch_end(batch=step)
            res.append(y_pred)
            if len(res) == wait_steps:
                wait(res)
                res = []
        wait(res)
        callbacks.on_predict_end()
        return result

    @reveal
    def evaluate(
        self,
        x: Union[
            VDataFrame,
            FedNdarray,
            List[Union[HDataFrame, VDataFrame, FedNdarray]],
        ],
        y: Union[VDataFrame, FedNdarray, PYUObject],
        batch_size: int = 32,
        sample_weight=None,
        verbose=1,
        dataset_builder: Dict = None,
        random_seed: int = None,
        callbacks=None,
    ):
        """Vertical split learning evaluate interface

        Args:
            x: Input data. It could be:

            - VDataFrame: a vertically aligned dataframe.
            - FedNdArray: a vertically aligned ndarray.
            - List[Union[HDataFrame, VDataFrame, FedNdarray]]: list of dataframe or ndarray.

            y: Target data. It could be a VDataFrame or FedNdarray which has only one partition, or a PYUObject.
            batch_size: Integer or `Dict`. Number of samples per batch of
                computation. If unspecified, `batch_size` will default to 32.
            sample_weight: Optional Numpy array of weights for the test samples,
                used for weighting the loss function.
            verbose: Verbosity mode. 0 = silent, 1 = progress bar.
            dataset_builder: Callable function, its input is `x` or `[x, y]` if y is set, it should return dataset.
            random_seed: Seed for prgs, will only affect shuffle
            callbacks: List of `secretflow_fl.ml.nn.callbacks.Callback` instances.
        Returns:
            metrics: federate evaluate result
        """

        assert (
            isinstance(batch_size, int) and batch_size > 0
        ), f"batch_size should be integer > 0"

        if random_seed is None:
            random_seed = global_random(self.device_y, 100000)
        evaluate_steps = self.handle_data(
            x,
            y,
            sample_weight=sample_weight,
            batch_size=batch_size,
            stage="eval",
            epochs=1,
            random_seed=random_seed,
            dataset_builder=dataset_builder,
        )
        metrics = None
        self._workers[self.device_y].reset_metrics()

        callbacks = CallbackList(
            callbacks=callbacks,
            add_history=True,
            add_progbar=verbose != 0,
            workers=self._workers,
            device_y=self.device_y,
            verbose=verbose,
            steps=evaluate_steps,
        )
        callbacks.on_test_begin()
        [worker.reset_data_iter(stage="eval") for worker in self._workers.values()]
        wait_steps = min(min(self.get_cpus()) * 2, 100)
        for step in range(0, evaluate_steps):
            callbacks.on_test_batch_begin(step)
            f_datas = {}  # driver端

            [
                worker.get_batch_data(stage="eval", epoch=0)
                for device, worker in self._workers.items()
            ]

            callbacks.on_base_forward_begin()
            # 1. Local calculation of basenet
            [worker.base_forward() for device, worker in self._workers.items()]
            callbacks.on_base_forward_end()

            for device, worker in self._workers.items():
                f_data = worker.pack_forward_data()
                f_datas[device] = f_data

            agg_hiddens = self.agglayer.forward(f_datas)

            metrics = self._workers[self.device_y].evaluate(agg_hiddens)
            if (step + 1) % wait_steps == 0:
                wait(metrics)
            callbacks.on_test_batch_end(batch=step)

        callbacks.on_test_end(metrics)
        return metrics

    def save_model(
        self,
        base_model_path: Union[str, Dict[PYU, str]] = None,
        fuse_model_path: str = None,
        is_test=False,
        **kwargs,
    ):
        """Vertical split learning save model interface

        Args:
            base_model_path: base model path,only support format like 'a/b/c', where c is the model name
            fuse_model_path: fuse model path
            is_test: whether is test mode
            kwargs: other argument inherit from tf or torch
        Examples:
            >>> save_params = {'save_traces' : True,
            >>>                'save_format' : 'h5',}
            >>> slmodel.save_model(base_model_path,
            >>>                    fuse_model_path,)
            >>>                    is_test=True,)
            >>> # just passing params in
            >>> slmodel.save_model(base_model_path,
            >>>                    fuse_model_path,
            >>>                    is_test=True,
            >>>                    save_traces=True,
            >>>                    save_format='h5')
        """
        assert isinstance(
            base_model_path, (str, Dict)
        ), f"Model path accepts string or dict but got {type(base_model_path)}."
        assert fuse_model_path is not None, "Fuse model path cannot be empty"
        if isinstance(base_model_path, str):
            base_model_path = {
                device: base_model_path for device in self.base_model_dict.keys()
            }

        res = []
        for device, worker in self._workers.items():
            if device not in self.base_model_dict.keys():
                continue
            assert (
                device in base_model_path
            ), f"Should provide a path for device {device}."
            assert not base_model_path[device].endswith(
                "/"
            ), f"model path should be 'a/b/c' not 'a/b/c/'"
            base_model_dir, base_model_name = base_model_path[device].rsplit("/", 1)

            if is_test:
                # only execute when unittest
                base_model_dir = os.path.join(
                    base_model_dir, device.__str__().strip("_")
                )
            res.append(
                worker.save_base_model(
                    os.path.join(base_model_dir, base_model_name), **kwargs
                )
            )

        res.append(
            self._workers[self.device_y].save_fuse_model(fuse_model_path, **kwargs)
        )
        wait(res)

    def load_model(
        self,
        base_model_path: Union[str, Dict[PYU, str]] = None,
        fuse_model_path: str = None,
        is_test=False,
        base_custom_objects=None,
        fuse_custom_objects=None,
    ):
        """Vertical split learning load model interface

        Args:
            base_model_path: base model path
            fuse_model_path: fuse model path
            is_test: whether is test mode
            base_custom_objects: Optional dictionary mapping names (strings) to custom
                classes or functions of the base model to be considered during deserialization
            fuse_custom_objects: Optional dictionary mapping names (strings) to custom
                classes or functions of the base model to be considered during deserialization.
        """
        assert isinstance(
            base_model_path, (str, Dict)
        ), f"Model path accepts string or dict but got {type(base_model_path)}."
        assert fuse_model_path is not None, "Fuse model path cannot be empty"
        if isinstance(base_model_path, str):
            base_model_path = {
                device: base_model_path for device in self.base_model_dict.keys()
            }
        res = []
        for device, worker in self._workers.items():
            if device not in self.base_model_dict.keys():
                continue
            assert (
                device in base_model_path
            ), f"Should provide a path for device {device}."
            assert not base_model_path[device].endswith(
                "/"
            ), f"model path should be 'a/b/c' not 'a/b/c/'"
            base_model_dir, base_model_name = base_model_path[device].rsplit("/", 1)

            if is_test:
                # only execute when unittest
                base_model_dir = os.path.join(
                    base_model_dir, device.__str__().strip("_")
                )
            res.append(
                worker.load_base_model(
                    os.path.join(base_model_dir, base_model_name),
                    custom_objects=base_custom_objects,
                )
            )

        res.append(
            self._workers[self.device_y].load_fuse_model(
                fuse_model_path, custom_objects=fuse_custom_objects
            )
        )
        wait(res)

    def export_model(
        self,
        base_model_path: Union[str, Dict[PYU, str]] = None,
        fuse_model_path: str = None,
        save_format="tf",
        is_test=False,
        **kwargs,
    ):
        """Vertical split learning export model interface

        Args:
            base_model_path: base model path,only support format like 'a/b/c', where c is the model name
            fuse_model_path: fuse model path
            save_format: what format to export
            kwargs: other argument inherit from onnx safer
        """
        assert isinstance(
            base_model_path, (str, Dict)
        ), f"Model path accepts string or dict but got {type(base_model_path)}."
        assert fuse_model_path is not None, "Fuse model path cannot be empty"
        if isinstance(base_model_path, str):
            base_model_path = {
                device: base_model_path for device in self.base_model_dict.keys()
            }

        res = []
        base_input_output_infos = {}
        for device, worker in self._workers.items():
            if device not in self.base_model_dict.keys():
                continue
            assert (
                device in base_model_path
            ), f"Should provide a path for device {device}."
            assert not base_model_path[device].endswith(
                "/"
            ), f"model path should be 'a/b/c' not 'a/b/c/'"
            base_model_dir, base_model_name = base_model_path[device].rsplit("/", 1)

            if is_test:
                # only execute when unittest
                base_model_dir = os.path.join(
                    base_model_dir, device.__str__().strip("_")
                )

            input_output_info = worker.export_base_model(
                os.path.join(base_model_dir, base_model_name),
                save_format=save_format,
                **kwargs,
            )
            res.append(input_output_info)
            base_input_output_infos[device] = input_output_info

        fuse_input_output_info = self._workers[self.device_y].export_fuse_model(
            fuse_model_path, save_format=save_format, **kwargs
        )
        res.append(fuse_input_output_info)
        wait(res)
        return base_input_output_infos, fuse_input_output_info

    def get_cpus(self) -> List[int]:
        return reveal(
            [device(lambda: multiprocessing.cpu_count())() for device in self._workers]
        )
