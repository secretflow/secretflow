{
  ".": {
    "secretflow": "secretflow",
    "First-party SecretFlow components.": "官方SecretFlow组件"
  },
  "data_filter/condition_filter:1.0.0": {
    "data_filter": "数据过滤",
    "condition_filter": "行级过滤",
    "Filter the table based on a single column's values and condition.\nWarning: the party responsible for condition filtering will directly send the sample distribution to other participants.\nMalicious participants can obtain the distribution of characteristics by repeatedly calling with different filtering values.\nAudit the usage of this component carefully.": "根据单个列的值和条件筛选表。\n警告：负责条件过滤的一方将直接将样本分发发送给其他参与者。\n恶意参与者可以通过使用不同的过滤值重复调用来获得特征的分布。\n仔细审核此组件的使用情况。",
    "1.0.0": "1.0.0",
    "comparator": "比较条件",
    "Comparator to use for comparison. Must be one of '==','<','<=','>','>=','IN','NOTNULL'": "用于比较的条件。必须是 '=='、'<'、'<='、'>'、'>='、'IN'、'NOTNULL' 之一",
    "bound_value": "条件值",
    "Input a value for comparison; if the comparison condition is IN, you can input multiple values separated by ','; if the comparison condition is NOTNULL, the input is not needed.": "输入一个值进行比较；如果比较条件为IN，则可以输入多个以“，”分隔的值；如果比较条件为NOTNULL，则不需要输入。",
    "float_epsilon": "浮点数误差值",
    "Epsilon value for floating point comparison. WARNING: due to floating point representation in computers, set this number slightly larger if you want filter out the values exactly at desired boundary. for example, abs(1.001 - 1.002) is slightly larger than 0.001, and therefore may not be filter out using == and epsilson = 0.001": "用于浮点比较的Epsilon值。警告：由于计算机中的浮点表示，如果您想在所需的边界处过滤掉值，请将此数字设置得稍大一些。例如，abs（1.001-1.002）略大于0.001，因此可能无法使用==和epsilson=0.001进行过滤",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "feature": "特征列",
    "Feature to operate on.": "要操作的特征列",
    "output_ds": "输出数据集",
    "Output vertical table that satisfies the condition.": "输出满足条件的表",
    "output_ds_else": "输出数据集",
    "Output vertical table that does not satisfies the condition.": "输出不满足条件的表"
  },
  "data_filter/expr_condition_filter:1.0.0": {
    "data_filter": "数据过滤",
    "expr_condition_filter": "自定义行过滤",
    "Only row-level filtering is supported, column processing is not available;\nthe custom expression must comply with SQLite syntax standards": "仅支持行级过滤，不支持列处理;\n自定义表达式必须符合 SQLite 语法标准",
    "1.0.0": "1.0.0",
    "expr": "表达式",
    "The custom expression must comply with SQLite syntax standards": "自定义表达式必须符合 SQLite 语法标准",
    "input_ds": "输入数据集",
    "Input vertical or individual table": "输入表可以是联合表或样本表",
    "output_ds": "输出数据集",
    "Output table that satisfies the condition": "输出满足条件的表",
    "output_ds_else": "输出数据集",
    "Output table that does not satisfies the condition": "输出不满足条件的表"
  },
  "data_filter/feature_filter:1.0.0": {
    "data_filter": "数据过滤",
    "feature_filter": "列级过滤",
    "Drop features from the dataset.": "从数据集中删除特征",
    "1.0.0": "1.0.0",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "drop_features": "删除的特征",
    "Features to drop.": "删除的特征",
    "output_ds": "输出数据集",
    "Output vertical table.": "输出联合表"
  },
  "data_filter/sample:1.0.0": {
    "data_filter": "数据过滤",
    "sample": "采样",
    "Sample data set.": "支持随机采样、等距采样和分层采样",
    "1.0.0": "1.0.0",
    "sample_algorithm": "采样算法",
    "sample algorithm and parameters": "采样算法和参数",
    "random": "随机",
    "Random sample.": "随机采样。",
    "frac": "采样比例",
    "Proportion of the dataset to sample in the set. The fraction should be larger than 0.": "数据集与集合中样本的比例。分数应大于0。",
    "random_state": "随机种子",
    "Specify the random seed of the shuffling.": "指定洗牌的随机种子。",
    "replacement": "放回",
    "If true, sampling with replacement. If false, sampling without replacement.": "如果为真，则放回采样。如果为假，则不放回采样。",
    "system": "等距",
    "system sample.": "等距采样",
    "Proportion of the dataset to sample in the set. The fraction should be larger than 0 and less than or equal to 0.5.": "数据集与集合中样本的比例。该分数应大于0且小于或等于0.5。",
    "stratify": "分层",
    "stratify sample.": "分层采样",
    "observe_feature": "观测特征",
    "stratify sample observe feature.": "分层采样观测特征。",
    "replacements": "放回",
    "quantiles": "分位点",
    "stratify sample quantiles": "分层采样分位点",
    "weights": "权重",
    "stratify sample weights": "分层采样权重",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "output_ds": "输出数据集",
    "Output sampled dataset.": "输出联合表",
    "report": "报告",
    "Output sample report": "输出样本报告"
  },
  "data_prep/psi:1.0.0": {
    "data_prep": "数据准备",
    "psi": "隐私求交",
    "PSI between two parties.": "双方之间的隐私求交",
    "1.0.0": "1.0.0",
    "protocol": "求交协议",
    "PSI protocol.": "求交协议（ECDH比较通用和稳定，适合低带宽场景。KKRT适合高带宽场景。RR22是最新的隐私求交协议，性能最佳。）",
    "PROTOCOL_ECDH": "PROTOCOL_ECDH",
    "ECDH protocol.": "ECDH协议。",
    "CURVE_25519": "25519曲线",
    "CURVE_FOURQ": "FOURQ曲线",
    "CURVE_SM2": "SM2曲线",
    "CURVE_SECP256K1": "SECP256K1曲线",
    "PROTOCOL_RR22": "PROTOCOL_RR22",
    "RR22 protocol.": "RR22协议。",
    "PROTOCOL_KKRT": "PROTOCOL_KKRT",
    "KKRT protocol.": "KKRT协议。",
    "sort_result": "是否重排序",
    "If false, output is not promised to be aligned. Warning: disable this option may lead to errors in the following components. DO NOT TURN OFF if you want to append other components.": "如果置为否，输出不保证对齐。警告：禁用此选项可能会导致后续组件出错。如果要附加其他组件，请不要关闭。",
    "receiver_parties": "结果接收方",
    "Party names of receiver for result, all party will be receivers default; if only one party receive result, the result will be single-party table, hence you can not connect it to component with union table input.": "选择结果接收方，默认选择全部数据参与方为结果接收方；如接收方为一方，则产出结果为单边样本表，不可连接输入需为联合表的组件。",
    "allow_empty_result": "求交结果是否允许为空",
    "Whether to allow the result to be empty, if allowed, an empty file will be saved, if not, an error will be reported.": "是否允许结果为空，如果允许，将保存一个空文件，如果不允许，将报错。",
    "join_type": "求交类型",
    "join type, default is inner join.": "求交类型，默认为inner join。",
    "inner_join": "inner join",
    "Inner join": "inner join",
    "left_join": "left join",
    "Left join": "left join",
    "left_side": "左表数据方",
    "Required for left join": "左表数据方",
    "full_join": "full join",
    "Full join": "full join",
    "difference": "差集",
    "Difference": "差集",
    "input_ds1_keys_duplicated": "表一关联键重复",
    "Whether key columns have duplicated rows, default is True.": "关联建是否重复（如果关联键重复，默认求交结果会膨胀，如果不重复，跳过重复检查，如果不确定，请选择是）。",
    "input_ds2_keys_duplicated": "表二关联键重复",
    "input_ds1": "表一",
    "Individual table for party 1": "参与方1的表",
    "keys": "关联键",
    "Column(s) used to join.": "用于联接的列。",
    "input_ds2": "表二",
    "Individual table for party 2": "参与方2的表",
    "output_ds": "PSI输出",
    "Output vertical table": "输出表",
    "report": "输出报告",
    "Output psi report": "输出psi报告"
  },
  "data_prep/psi_tp:1.0.0": {
    "data_prep": "数据准备",
    "psi_tp": "三方隐私求交",
    "PSI between three parties.": "三方之间的隐私求交",
    "1.0.0": "1.0.0",
    "ecdh_curve": "椭圆曲线类型",
    "Curve type for ECDH PSI.": "椭圆曲线类型",
    "CURVE_25519": "25519曲线",
    "CURVE_FOURQ": "FOURQ曲线",
    "CURVE_SM2": "SM2曲线",
    "CURVE_SECP256K1": "SECP256K1曲线",
    "input_ds1": "表一",
    "Individual table for party 1": "参与方1的表",
    "keys1": "关联键",
    "Column(s) used to join.": "用于联接的列。",
    "input_ds2": "表二",
    "Individual table for party 2": "参与方2的表",
    "keys2": "关联键",
    "input_ds3": "表三",
    "Individual table for party 3": "参与方3的表",
    "keys3": "关联键",
    "output_ds": "输出表",
    "Output vertical table": "输出联合表"
  },
  "data_prep/train_test_split:1.0.0": {
    "data_prep": "数据准备",
    "train_test_split": "随机分割",
    "Split datasets into random train and test subsets.\n- Please check: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html": "将数据集拆分为随机的训练子集和测试子集\n- 请检查：https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html",
    "1.0.0": "1.0.0",
    "train_size": "训练子集大小",
    "Proportion of the dataset to include in the train subset. The sum of test_size and train_size should be in the (0, 1] range.": "要包含在训练子集中的数据集的比例。测试子集大小 和 训练子集大小 的总和应在 (0, 1] 范围内。",
    "test_size": "测试子集大小",
    "Proportion of the dataset to include in the test subset. The sum of test_size and train_size should be in the (0, 1] range.": "要包含在测试子集中的数据集的比例。测试子集大小 和 训练子集大小 的总和应在 (0, 1] 范围内。",
    "random_state": "数据打乱的随机种子",
    "Specify the random seed of the shuffling.": "指定数据打乱的随机种子",
    "shuffle": "数据打乱",
    "Whether to shuffle the data before splitting.": "拆分前是否对数据进行数据打乱",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "train_ds": "训练数据子集",
    "Output train dataset.": "输出训练数据子集",
    "test_ds": "测试数据子集",
    "Output test dataset.": "输出测试数据子集"
  },
  "data_prep/unbalance_psi:1.0.0": {
    "data_prep": "data_prep",
    "unbalance_psi": "非平衡隐私求交",
    "Unbalance psi with cache.": "和非平衡隐私求交数据缓存配合使用，可提高两方数据量级差异大的情况下隐私求交的效率。",
    "1.0.0": "1.0.0",
    "join_type": "求交类型",
    "join type, default is inner join.": "求交类型，默认为inner join。",
    "inner_join": "inner join",
    "Inner join": "inner join",
    "left_join": "left join",
    "Left join": "left join",
    "left_side": "左表数据方",
    "Required for left join": "left join时，左表数据方",
    "full_join": "full join",
    "Full join": "full join",
    "difference": "差集",
    "Difference": "差集",
    "allow_empty_result": "允许空结果",
    "Whether to allow the result to be empty, if allowed, an empty file will be saved, if not, an error will be reported.": "是否允许结果为空，如果允许，将保存一个空文件，如果不允许，将报错。",
    "receiver_parties": "结果接收方",
    "Party names of receiver for result, all party will be receivers default; if only one party receive result, the result will be single-party table, hence you can not connect it to component with union table input.": "选择结果接收方，默认选择全部数据参与方为结果接收方；如接收方为一方，则产出结果为单边样本表，不可连接输入需为联合表的组件。",
    "client_ds": "查询方数据集",
    "Client dataset.": "查询方数据集。",
    "keys": "小样本方关联键",
    "Keys to be used for psi.": "查询方用于psi的关联键。",
    "cache": "密文数据缓存",
    "Server cache.": "密文数据缓存",
    "output_ds": "求交结果",
    "Output table": "求交结果"
  },
  "data_prep/unbalance_psi_cache:1.0.0": {
    "data_prep": "data_prep",
    "unbalance_psi_cache": "非平衡隐私求交数据缓存",
    "Generate cache for unbalance psi on both sides.": "仅可和非平衡隐私求交配合使用，用于大样本方缓存数据的生成。",
    "1.0.0": "1.0.0",
    "client": "缓存接收方",
    "Party of client(party with the smaller dataset).": "数据量更少的一方，通常为缓存接收方。",
    "input_ds": "提供方输入表",
    "Input vertical table.": "提供方输入表",
    "keys": "大样本方关联键",
    "Keys to be used for psi.": "数据提供方用于psi的关联键。",
    "output_cache": "密文数据缓存",
    "Output cache.": "密文数据缓存"
  },
  "data_prep/union:1.0.0": {
    "data_prep": "数据准备",
    "union": "表union",
    "Perform a horizontal merge of two data tables, supporting the individual table or vertical table on the same node.": "横向合并两个数据表，分别支持同节点的联合表或样本表合并",
    "1.0.0": "1.0.0",
    "input_ds1": "输入数据集一",
    "The first input table": "第一个输入表",
    "input_ds2": "输入数据集二",
    "The second input table": "第二个输入表",
    "output_ds": "输出数据集",
    "Output table": "输出表"
  },
  "io/data_sink:1.0.0": {
    "io": "IO系列",
    "data_sink": "数据导出",
    "export data to an external data source": "将数据导出到外部数据源",
    "1.0.0": "1.0.0",
    "output_party": "output_party",
    "output party": "输出方",
    "output_uri": "output_uri",
    "output uri, the uri format is datamesh:///{relative_path}?domaindata_id={domaindata_id}&datasource_id={datasource_id}&partition_spec={partition_spec}": "输出 URI，URI 格式为 datamesh:///{relative_path}？domaindata_id={domaindata_id}&datasource_id={datasource_id}&partition_spec={partition_spec}",
    "input_data": "input_data",
    "Input dist data": "输入数据"
  },
  "io/data_source:1.0.0": {
    "io": "IO系列",
    "data_source": "数据导入",
    "import data from an external data source": "从外部数据源导入SF",
    "1.0.0": "1.0.0",
    "party": "参与方",
    "": "",
    "uri": "URI",
    "input uri, the uri format is datamesh:///{relative_path}?domaindata_id={domaindata_id}&datasource_id={datasource_id}&partition_spec={partition_spec}": "输入 URI，URI 格式为 datamesh:///{relative_path}？domaindata_id={domaindata_id}&datasource_id={datasource_id}&partition_spec={partition_spec}",
    "columns": "列信息",
    "table column info, json format, for example {\"col1\": \"ID\", \"col2\":\"FEATURE\", \"col3\":\"LABEL\"}": "数据表中列信息，json 格式，例如 {\"col1\": \"ID\", \"col2\":\"FEATURE\", \"col3\":\"LABEL\"}",
    "output_ds": "output_ds",
    "output dataset": "输出数据集"
  },
  "io/identity:1.0.0": {
    "io": "IO系列",
    "identity": "恒等",
    "map any input to output": "将任何输入映射到输出",
    "1.0.0": "1.0.0",
    "input_data": "input_data",
    "Input data": "输入数据",
    "output_data": "output_data",
    "Output data": "输出数据"
  },
  "io/read_data:1.0.0": {
    "io": "io",
    "read_data": "读取数据",
    "read model or rules from sf cluster": "从sf集群读取模型或规则",
    "1.0.0": "1.0.0",
    "generalized_linear_model": "广义线性模型",
    "Whether to dump the complete generalized linear model. The complete generalized linear model contains link, y_scale, offset_col, and so on.": "是否保存完整的广义线性模型信息，完整的广义线性模型包含link、y_scale、offset_col等信息。",
    "input_data": "输入模型或者规则文件",
    "Input dist data": "输入模型或者规则文件",
    "output_data": "输出数据",
    "Output rules or models in DistData.meta": "在DistData.meta中输出规则或模型"
  },
  "io/write_data:1.0.0": {
    "io": "io",
    "write_data": "写入数据",
    "write model or rules back to sf cluster": "将模型或规则写回sf集群",
    "1.0.0": "1.0.0",
    "rule or model protobuf by json format": "json格式的规则或模型protobuf",
    "write_data_type": "写入数据类型",
    "which rule or model is writing": "正在编写哪个规则或模型",
    "input_data": "输入模型或者规则文件",
    "Input dist data. Rule reconstructions may need hidden info in original rule for security considerations.": "输入模型或者规则文件。出于安全考虑，规则重建可能需要原始规则中的隐藏信息。",
    "output_data": "输出数据",
    "Output rules or models in sf cluster format": "以sf集群格式输出规则或模型"
  },
  "ml.eval/biclassification_eval:1.0.0": {
    "ml.eval": "模型评估",
    "biclassification_eval": "二分类评估",
    "Statistics evaluation for a bi-classification model on a dataset.\n1. summary_report: SummaryReport\n2. eq_frequent_bin_report: List[EqBinReport]\n3. eq_range_bin_report: List[EqBinReport]\n4. head_report: List[PrReport]\nreports for fpr = 0.001, 0.005, 0.01, 0.05, 0.1, 0.2": "数据集上二分类模型的统计评估\n1. summary_report: 总结报告\n2. eq_frequent_bin_report: 等频分箱报告\n3. eq_range_bin_report: 等距分箱报告\n4. head_report: \nFPR = 0.001， 0.005， 0.01， 0.05， 0.1， 0.2 的精度报告",
    "1.0.0": "1.0.0",
    "bucket_size": "分桶数",
    "Number of buckets.": "分桶数",
    "min_item_cnt_per_bucket": "每个桶的最小项目数",
    "Min item cnt per bucket. If any bucket doesn't meet the requirement, error raises. For security reasons, we require this parameter to be at least 5.": "每个桶的最小项目数量；如果任何一个分桶不符合要求，则会引发错误出于安全原因，我们要求此参数至少为 5",
    "input_ds": "输入数据表",
    "Input table with prediction and label, usually is a result from a prediction component.": "包含预测和标签的输入数据表，通常是预测组件的结果",
    "label": "标签",
    "The label name to use in the dataset.": "数据集中要使用的标签名称",
    "prediction": "预测",
    "The prediction result column name to use in the dataset.": "要在数据集中使用的预测结果列名",
    "report": "报告",
    "Output report.": "输出报告"
  },
  "ml.eval/prediction_bias_eval:1.0.0": {
    "ml.eval": "模型评估",
    "prediction_bias_eval": "预测偏差评估",
    "Calculate prediction bias, ie. average of predictions - average of labels.": "计算预测偏差，即 预测平均值 - 标签平均值",
    "1.0.0": "1.0.0",
    "bucket_num": "分桶数",
    "Num of bucket.": "分桶数",
    "min_item_cnt_per_bucket": "每个桶的最小项目数",
    "Min item cnt per bucket. If any bucket doesn't meet the requirement, error raises. For security reasons, we require this parameter to be at least 2.": "每个桶的最小项目数量；如果任何一个分桶不符合要求，则会引发错误出于安全原因，我们要求此参数至少为 2",
    "bucket_method": "分桶方法",
    "Bucket method.": "分桶方法",
    "input_ds": "输入数据表",
    "Input table with prediction and label, usually is a result from a prediction component.": "带有预测和标签的输入数据表，通常是预测组件的结果。",
    "label": "标签列",
    "The label name to use in the dataset.": "上游训练使用的标签列",
    "prediction": "预测结果列名",
    "The prediction result column name to use in the dataset.": "预测组件中填写的预测结果列名",
    "report": "报告",
    "Output report.": "输出报告"
  },
  "ml.eval/regression_eval:1.0.0": {
    "ml.eval": "评估模型",
    "regression_eval": "回归模型评估",
    "Statistics evaluation for a regression model on a dataset.\nContained Statistics:\nR2 Score (r2_score): It is a statistical measure that represents the proportion of the variance in the dependent variable that can be predicted from the independent variables. It ranges from 0 to 1, where a higher value indicates a better fit.\nMean Absolute Error (mean_abs_err): It calculates the average absolute difference between the predicted and actual values. It provides a measure of the average magnitude of the errors.\nMean Absolute Percentage Error (mean_abs_percent_err): It calculates the average absolute percentage difference between the predicted and actual values. It measures the average magnitude of the errors in terms of percentages.\nSum of Squared Errors (sum_squared_errors): It calculates the sum of the squared differences between the predicted and actual values. It provides an overall measure of the model's performance.\nMean Squared Error (mean_squared_errors): It calculates the average of the squared differences between the predicted and actual values. It is widely used as a loss function in regression problems.\nRoot Mean Squared Error (root_mean_squared_errors): It is the square root of the mean squared error. It provides a measure of the average magnitude of the errors in the original scale of the target variable.\nMean of True Values (y_true_mean): It calculates the average of the actual values in the target variable. It can be useful for establishing a baseline for the model's performance.\nMean of Predicted Values (y_pred_mean): It calculates the average of the predicted values. It can be compared with the y_true_mean to get an idea of the model's bias.\nResidual Histograms (residual_hists): It represents the distribution of the differences between the predicted and actual values. It helps to understand the spread and pattern of the errors.": "在数据集上对回归模型进行统计评估。\n包含的统计信息：\nR2得分（r2_score）：它是一种统计度量，表示因变量中可以从自变量中预测的方差比例。它的取值范围从0到1，值越高表示拟合效果越好。\n平均绝对误差（mean_abs_err）：它计算预测值和实际值之间的平均绝对差。它提供了误差的平均大小的度量。\n平均绝对百分比误差（mean_abs_percent_err）：它计算预测值和实际值之间的平均绝对百分比差。它以百分比的形式衡量误差的平均大小。\n误差平方和（sum_squared_errors）：它计算预测值和实际值之间的差值的平方和。它提供了对模型性能的整体衡量。\n均方误差（mean_squared_errors）：它计算预测值和实际值之间的差值的平方的平均值。它广泛用作回归问题中的损失函数。\n均方根误差（root_mean_squared_errors）：它是均方误差的平方根。它提供了目标变量原始标度中误差的平均幅度的测量。\n真值的平均值（y_true_mean）：它计算目标变量中实际值的平均值。它可以用于建立模型性能的基准。\n预测值的平均值（y_pred_mean）：它计算预测值的平均值。它可以与y_true_mean进行比较，以了解模型的偏差。\n残差直方图（residual_hists）：它表示预测值和实际值之间的差异分布。它有助于理解误差的传播和模式。",
    "1.0.0": "1.0.0",
    "bucket_size": "桶大小",
    "Number of buckets for residual histogram.": "残差直方图的桶数。",
    "input_ds": "输入数据表",
    "Input table with prediction and label, usually is a result from a prediction component.": "带有预测和标签的输入数据表，通常是预测组件的结果。",
    "label": "标签",
    "The label name to use in the dataset.": "要在数据集中使用的标签名称。",
    "prediction": "预测",
    "The prediction result column name to use in the dataset.": "要在数据集中使用的预测结果列名。",
    "report": "报告",
    "Output report.": "输出报告"
  },
  "ml.eval/ss_pvalue:1.0.0": {
    "ml.eval": "模型评估",
    "ss_pvalue": "P-VALUE评估",
    "Calculate P-Value for LR model training on vertical partitioning dataset by using secret sharing.\nFor large dataset(large than 10w samples & 200 features),\nrecommend to use [Ring size: 128, Fxp: 40] options for SPU device.": "使用秘密共享计算逻辑回归或广义线性回归模型训练的P值",
    "1.0.0": "1.0.0",
    "input_model": "模型",
    "Input model.": "输入模型",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "report": "报告",
    "Output P-Value report.": "输出P-VALUE结果表"
  },
  "ml.predict/serving_model_inferencer:1.0.0": {
    "ml.predict": "模型预测",
    "serving_model_inferencer": "模型包回测",
    "batch predicting online service models in offline": "离线批量预测在线服务模型",
    "1.0.0": "1.0.0",
    "receiver": "接收方",
    "Party of receiver.": "接收方",
    "pred_name": "预测结果列名",
    "Column name for predictions.": "预测结果列名",
    "serving_model": "服务模型包",
    "Input serving model.": "输入服务模型包",
    "input_ds": "特征数据集",
    "Input vertical table or individual table.": "输入垂直表格或单独表格。",
    "saved_columns": "保存列",
    "which columns should be saved with prediction result": "哪些列应与预测结果一起保存",
    "output_ds": "预测",
    "Output prediction.": "输出预测结果表"
  },
  "ml.predict/sgb_predict:1.0.0": {
    "ml.predict": "模型预测",
    "sgb_predict": "SecureBoost预测",
    "Predict using SGB model.": "使用 SGB 模型进行预测",
    "1.0.0": "1.0.0",
    "receiver": "结果接收方",
    "Party of receiver.": "结果接收方",
    "pred_name": "预测结果列名",
    "Name for prediction column": "预测结果列名",
    "save_ids": "保存id列",
    "Whether to save ids columns into output prediction table. If true, input feature_dataset must contain id columns, and receiver party must be id owner.": "是否将 id 列保存到输出预测表中；如果为 true，则输入feature_dataset必须包含 id 列，并且接收方必须是 id 所有者",
    "save_label": "保存标签列",
    "Whether or not to save real label columns into output pred file. If true, input feature_dataset must contain label columns and receiver party must be label owner.": "是否将真实的标签列保存到输出预测文件中；如果为 true，则输入feature_dataset必须包含标签列，并且接收方必须是标签所有者",
    "input_model": "模型",
    "model": "模型",
    "input_ds": "特征数据集",
    "Input vertical table.": "输入联合表",
    "saved_features": "保存特征列",
    "which features should be saved with prediction result": "哪些特征应该与预测结果一起保存",
    "output_ds": "预测",
    "Output prediction.": "输出预测结果表"
  },
  "ml.predict/ss_glm_predict:1.1.0": {
    "ml.predict": "模型预测",
    "ss_glm_predict": "SSGLM预测",
    "Predict using the SSGLM model.": "使用 SSGLM 模型进行预测",
    "1.1.0": "1.1.0",
    "receiver": "结果接收方",
    "Party of receiver.": "结果接收方",
    "pred_name": "预测结果列名",
    "Column name for predictions.": "预测结果列名",
    "save_ids": "保存id列",
    "Whether to save ids columns into output prediction table. If true, input feature_dataset must contain id columns, and receiver party must be id owner.": "是否将 id 列保存到输出预测表中；如果为 true，则输入feature_dataset必须包含 id 列，并且接收方必须是 id 所有者",
    "save_label": "保存标签列",
    "Whether or not to save real label columns into output pred file. If true, input feature_dataset must contain label columns and receiver party must be label owner.": "是否将真实的标签列保存到输出 pred 文件中；如果为 true，则输入feature_dataset必须包含标签列，并且接收方必须是标签所有者",
    "input_model": "模型",
    "Input model.": "输入模型",
    "input_ds": "特征数据集",
    "Input vertical table.": "输入联合表",
    "saved_features": "保存特征列",
    "which features should be saved with prediction result": "哪些特征应该与预测结果一起保存",
    "output_ds": "预测",
    "Output prediction.": "输出预测结果表"
  },
  "ml.predict/ss_sgd_predict:1.0.0": {
    "ml.predict": "模型预测",
    "ss_sgd_predict": "逻辑回归预测",
    "Predict using the SS-SGD model.": "使用 SS-SGD 模型进行预测",
    "1.0.0": "1.0.0",
    "batch_size": "训练批数据量",
    "The number of training examples utilized in one iteration.": "一次迭代中使用的训练示例数",
    "receiver": "结果接收方",
    "Party of receiver.": "接收结果接收方",
    "pred_name": "预测结果列名",
    "Column name for predictions.": "预测结果列名",
    "save_ids": "保存id列",
    "Whether to save ids columns into output prediction table. If true, input feature_dataset must contain id columns, and receiver party must be id owner.": "是否将 id 列保存到输出预测表中；如果为 true，则输入feature_dataset必须包含 id 列，并且接收方必须是 id 所有者",
    "save_label": "保存标签列",
    "Whether or not to save real label columns into output pred file. If true, input feature_dataset must contain label columns and receiver party must be label owner.": "是否将真实的标签列保存到输出预测文件中；如果为 true，则输入feature_dataset必须包含标签列，并且接收方必须是标签所有者",
    "input_model": "模型",
    "Input model.": "输入模型",
    "input_ds": "特征数据集",
    "Input vertical table.": "输入联合表",
    "saved_features": "保存特征列",
    "which features should be saved with prediction result": "哪些特征应该与预测结果一起保存",
    "output_ds": "预测",
    "Output prediction.": "输出预测结果表"
  },
  "ml.predict/ss_xgb_predict:1.0.0": {
    "ml.predict": "模型预测",
    "ss_xgb_predict": "SS-XGB预测",
    "Predict using the SS-XGB model.": "使用 SS-XGB 模型进行预测",
    "1.0.0": "1.0.0",
    "receiver": "结果接收方",
    "Party of receiver.": "结果接收方",
    "pred_name": "预测结果列名",
    "Column name for predictions.": "预测结果列名",
    "save_ids": "保存id列",
    "Whether to save ids columns into output prediction table. If true, input feature_dataset must contain id columns, and receiver party must be id owner.": "是否将 id 列保存到输出预测表中；如果为 true，则输入feature_dataset必须包含 id 列，并且接收方必须是 id 所有者",
    "save_label": "保存标签列",
    "Whether or not to save real label columns into output pred file. If true, input feature_dataset must contain label columns and receiver party must be label owner.": "是否将真实的标签列保存到输出预测文件中；如果为 true，则输入feature_dataset必须包含标签列，并且接收方必须是标签所有者",
    "input_model": "模型",
    "model": "模型",
    "input_ds": "特征数据集",
    "Input vertical table.": "输入联合表",
    "saved_features": "保存特征列",
    "which features should be saved with prediction result": "哪些特征应该与预测结果一起保存",
    "output_ds": "预测",
    "Output prediction.": "输出预测结果表"
  },
  "ml.train/sgb_train:1.0.0": {
    "ml.train": "模型训练",
    "sgb_train": "SecureBoost训练",
    "Provides both classification and regression tree boosting (also known as GBDT, GBM)\nfor vertical split dataset setting by using secure boost.\n- SGB is short for SecureBoost. Compared to its safer counterpart SS-XGB, SecureBoost focused on protecting label holder.\n- Check https://arxiv.org/abs/1901.08755.": "使用Secure Boosting为垂直拆分数据集设置提供分类和回归树Boosting(也称为 GBDT、GBM)SGB是SecureBoost的缩写与更安全的SS-XGB相比, SecureBoost专注于保护标签持有人\n - 详细信息请参阅: https: //arxiv.org/abs/1901.08755",
    "1.0.0": "1.0.0",
    "num_boost_round": "训练轮数",
    "Number of boosting iterations.": "Boosting迭代次数",
    "max_depth": "最大深度",
    "Maximum depth of a tree.": "树的最大深度",
    "learning_rate": "学习率",
    "Step size shrinkage used in update to prevent overfitting.": "更新中使用的步长收缩以防止过度拟合",
    "objective": "目标",
    "Specify the learning objective.": "指定学习目标",
    "reg_lambda": "叶子节点权重L2正则项",
    "L2 regularization term on weights.": "权重的 L2 正则化项",
    "gamma": "最小分裂阈值",
    "Greater than 0 means pre-pruning enabled. If gain of a node is less than this value, it would be pruned.": "大于 0 表示已启用预修剪；如果节点的增益小于此值，则将其修剪",
    "colsample_by_tree": "每棵树子样本比率",
    "Subsample ratio of columns when constructing each tree.": "构造每棵树时列的子样本比率",
    "sketch_eps": "分裂系数",
    "This roughly translates into O(1 / sketch_eps) number of bins.": "大致相当于 O(1 / 分裂系数) 个箱",
    "base_score": "初始预测分数",
    "The initial prediction score of all instances, global bias.": "所有实例的初始预测分数，全局偏差",
    "seed": "种子",
    "Pseudorandom number generator seed.": "伪随机数生成器种子",
    "fixed_point_parameter": "HEU定点参数",
    "Any floating point number encoded by heu, will multiply a scale and take the round, scale = 2 ** fixed_point_parameter. larger value may mean more numerical accuracy, but too large will lead to overflow problem.": "由heu编码的任何浮点数将乘以一个刻度并四舍五入, 刻度 = 2 ** HEU定点参数; 较大的值可能意味着更高的数值精度, 但太大会导致溢出问题",
    "first_tree_with_label_holder_feature": "第一棵树是否使用标签持有人自己的特征",
    "Whether to train the first tree with label holder's own features.": "是否使用标签持有人自己的特征训练第一棵树",
    "batch_encoding_enabled": "批量编码是否启用",
    "If use batch encoding optimization.": "是否使用批量编码优化",
    "enable_quantization": "启用量化",
    "Whether enable quantization of g and h.": "是否启用g和h的量化",
    "quantization_scale": "量化刻度",
    "Scale the sum of g to the specified value.": "将g的总和缩放到指定的值",
    "max_leaf": "最大叶子",
    "Maximum leaf of a tree. Only effective if train leaf wise.": "树的最大叶子;仅在叶子-wise训练时有效",
    "rowsample_by_tree": "行采样比率",
    "Row sub sample ratio of the training instances.": "训练实例的行子采样比率",
    "enable_goss": "启用GOSS",
    "Whether to enable GOSS.": "是否启用GOSS",
    "top_rate": "顶部比例",
    "GOSS-specific parameter. The fraction of large gradients to sample.": "GOSS特定参数;采样的大梯度的比例",
    "bottom_rate": "底部比例",
    "GOSS-specific parameter. The fraction of small gradients to sample.": "GOSS特定参数;采样的小梯度的比例",
    "tree_growing_method": "树生长方法",
    "How to grow tree?": "如何生长树",
    "enable_early_stop": "是否开启早停",
    "Whether to enable early stop during training.": "当选择的指标达到指定条件时，提前停止模型训练并产出结果",
    "enable_monitor": "是否查看评估指标",
    "Whether to enable monitoring performance during training.": "是否打印的模型评估指标",
    "eval_metric": "数据评估指标",
    "Use what metric for monitoring and early stop? Currently support ['roc_auc', 'rmse', 'mse', 'tweedie_deviance', 'tweedie_nll']": "选择一个模型评估指标来进行监测、早停",
    "validation_fraction": "验证集比例",
    "Early stop specific parameter. Only effective if early stop enabled. The fraction of samples to use as validation set.": "提前停止的特定参数。仅当启用提前停止时有效。用作验证集的样本比例。",
    "stopping_rounds": "停止轮次",
    "Early stop specific parameter. If more than 'stopping_rounds' consecutive rounds without improvement, training will stop. Only effective if early stop enabled": "提前停止的特定参数。如果连续超过'停止轮次'没有改善，训练将停止。仅当启用提前停止时有效。",
    "stopping_tolerance": "停止容忍度",
    "Early stop specific parameter. If metric on validation set is no longer improving by at least this amount, then consider not improving.": "如果最佳模型的移动平均线和参考移动平均线之间的比率大于或等于停止容忍度，模型会停止训练",
    "tweedie_variance_power": "Tweedie分布的power参数",
    "Parameter that controls the variance of the Tweedie distribution.": "控制Tweedie分布方差的参数",
    "save_best_model": "保存最佳模型",
    "Whether to save the best model on validation set during training.": "是否在训练期间保存在验证集上的最佳模型。",
    "input_ds": "训练数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be used for training.": "哪些特征应该用于训练",
    "label": "标签",
    "Label of train dataset.": "训练数据集的标签",
    "output_model": "输出模型",
    "Output model.": "输出模型"
  },
  "ml.train/ss_glm_train:1.1.0": {
    "ml.train": "模型训练",
    "ss_glm_train": "SSGLM训练",
    "generalized linear model (GLM) is a flexible generalization of ordinary linear regression.\nThe GLM generalizes linear regression by allowing the linear model to be related to the response\nvariable via a link function and by allowing the magnitude of the variance of each measurement to\nbe a function of its predicted value.": "广义线性模型（GLM）是普通线性回归的一种灵活的推广；该模型允许因变量的偏差分布有除了正态分布之外的其它分布；此模型假设实验者所量测的随机变量的分布函数与实验中系统性效应（即非随机的效应）可经由一链接函数（link function）建立可解释其相关性的函数",
    "1.1.0": "1.1.0",
    "epochs": "训练轮数",
    "The number of complete pass through the training data.": "通过完整训练数据的次数",
    "learning_rate": "学习率",
    "The step size at each iteration in one iteration.": "一次迭代中每次迭代的步长",
    "batch_size": "训练批数据量",
    "The number of training examples utilized in one iteration.": "一次迭代中使用的训练样本数",
    "link_type": "链接函数类型",
    "link function type": "链接函数类型",
    "label_dist_type": "样本分布类型",
    "label distribution type": "样本分布类型",
    "tweedie_power": "tweedie_power",
    "Tweedie distribution power parameter": "Tweedie分布的power参数",
    "dist_scale": "样本分布尺度的猜测值",
    "A guess value for distribution's scale": "样本分布尺度的猜测值",
    "iter_start_irls": "IRLS初始化轮数",
    "run a few rounds of IRLS training as the initialization of w, 0 disable": "运行几轮IRLS训练作为SGD训练的初始化w，0禁用",
    "decay_epoch": "decay_epoch",
    "decay learning interval": "衰减学习区间",
    "decay_rate": "decay_rate",
    "decay learning rate": "衰减学习率",
    "optimizer": "优化器",
    "which optimizer to use: IRLS(Iteratively Reweighted Least Squares) or SGD(Stochastic Gradient Descent)": "使用哪个优化器：IRLS（迭代加权最小二乘法）或SGD（随机梯度下降法）",
    "l2_lambda": "l2_lambda",
    "L2 regularization term": "L2正则系数",
    "infeed_batch_size_limit": "输入批次大小限制",
    "size of a single block, default to 8w * 100. increase the size will increase memory cost, but may decrease running time. Suggested to be as large as possible. (too large leads to OOM)": "单个块的大小，默认8w * 100。增加大小将增加内存成本，但可能会减少运行时间。建议尽可能大。（过大导致内存溢出）",
    "fraction_of_validation_set": "验证集占比",
    "fraction of training set to be used as the validation set. ineffective for 'weight' stopping_metric": "用于验证集的训练集比例。对于'weight'停止指标无效",
    "random_state": "随机状态",
    "random state for validation split": "验证集划分的随机状态",
    "stopping_metric": "停止指标",
    "use what metric as the condition for early stop? Must be one of ['deviance', 'MSE', 'RMSE', 'AUC', 'weight']. only logit link supports AUC metric (note that AUC is very, very expensive in MPC)": "使用哪个指标作为早停的条件？必须是['偏差', '均方误差', '均方根误差', 'AUC', '权重']之一。只有逻辑回归链接支持AUC指标（注意，在多方计算中AUC非常占用资源）",
    "stopping_rounds": "停止轮数",
    "If the model is not improving for stopping_rounds, the training process will be stopped, for 'weight' stopping metric, stopping_rounds is fixed to be 1": "如果模型在停止轮数设定期间没有提升，则训练过程将被停止。对于'权重'停止指标，停止轮数固定为1",
    "stopping_tolerance": "停止容差",
    "the model is considered as not improving, if the metric is not improved by tolerance over best metric in history. If metric is 'weight' and tolerance == 0, then early stop is disabled.": "如果模型在度量指标上相对历史最佳指标的改善未达到设定的容忍度，则认为模型未有改进。若度量指标为'weight'并且容忍度为0，则不启用提前停止功能。",
    "report_metric": "报告指标",
    "Whether to report the value of stopping metric. Only effective if early stop is enabled. If this option is set to true, metric will be revealed and logged.": "是否报告终止指标的值。这仅在启用提前停止时有效。如果此选项被设置为真，则会公开并记录该指标。",
    "exp_mode": "exp模式",
    "If you do not know the details of this parameter, please do not modify this parameter! Specify the mode of exp taylor approx, currently only supports 'taylor', 'pade' and 'prime' modes. The default value is 'taylor'. 'taylor': use taylor approx, variable precision and cost, higher exp_iters, higher cost. 'pade': use pade approx, high precision, high cost. 'prime': use prime approx, best precision, 3/4 cost of taylor (8 iter), only support for SEMI2K FM128 case. Although it has great presicion and performance inside valid domain, the approximation can be wildly inaccurate outside the valid domain. Suppose x -> exp(x), then valid domain is: x in ((47 - offset - 2fxp)/log_2(e), (125 - 2fxp - offset)/log_2(e)). That's why we need clamping x to this range. However, clamping action is expensive, so we need to set a reasonable offset to control the valid range of exp prime method, and avoid clamping for best performance.": "如果您不知道此参数的详细信息，请不要修改此参数！指定 exp taylor approx 的模式，目前仅支持 'taylor'、'pade' 和 'prime' 模式。默认值为 'taylor'。'Taylor'：使用 Taylor 近似值，精度和成本可变，exp_iters更高，成本更高。'pade'： 使用 pade approx，精度高，成本高。'prime'：使用素数近似值，最佳精度，泰勒成本的 3/4（8 迭代），仅支持 SEMI2K FM128 情况。尽管它在有效域内具有出色的精度和性能，但在有效域之外，近似值可能非常不准确。假设 x -> exp（x），则有效域为：x in （（47 - offset - 2fxp）/log_2（e）， （125 - 2fxp - offset）/log_2（e））。这就是为什么我们需要将 x 限制到这个范围。但是，限制动作是昂贵的，因此我们需要设置一个合理的偏移量来控制 exp prime 方法的有效范围，并尽量避免限制上下界以获得最佳性能。",
    "exp_iters": "exp拟合迭代次数",
    "If you do not know the details of this parameter, please do not modify this parameter! Specify the number of iterations of exp taylor approx, Only takes effect when using exp mode 'taylor'. Increasing this value will improve the accuracy of exp approx, but will quickly degrade performance.": "如果您不知道此参数的详细信息，请不要修改此参数！指定 exp 泰勒模拟的迭代次数，仅在使用 exp 模式 'taylor' 时生效。增加此值将提高 exp 模拟的精度，但会很快降低性能。",
    "exp_prime_offset": "exp质数方法偏移量",
    "If you do not know the details of this parameter, please do not modify this parameter! Specify the offset of exp prime approx, only takes effect when using exp mode 'prime'. control the valid range of exp prime method. Suppose x -> exp(x), then valid domain is: x in ((47 - offset - 2fxp)/log_2(e), (125 - 2fxp - offset)/log_2(e)) default to be 13.": "如果您不知道此参数的详细信息，请不要修改此参数！指定 exp prime 模拟的偏移量，仅在使用 exp 模式 'prime' 时生效。控制 EXP 质数方法的有效范围。假设 x -> exp（x），则有效域为：x in （（47 - offset - 2fxp）/log_2（e）， （125 - 2fxp - offset）/log_2（e）） 默认为 13。",
    "exp_prime_lower_bound_clamp": "exp质数方法是否限制下界",
    "If you do not know the details of this parameter, please do not modify this parameter! Specify whether to use lower bound for exp prime mode, only takes effect when using exp mode 'prime'. when calculating x -> exp(x), exp prime is only effective for x in ((47 - offset - 2fxp)/log_2(e), (125 - 2fxp - offset)/log_2(e)). If true, use clamp value below the lower bound, otherwise leave the value unchanged. lower bound is set to be (48 - offset - 2fxp)/log_2(e). Enable clamping will avoid large numerical errors when x < lower bound. Disable clamping will leave the value unchanged, which may cause large numerical errors when x < lower bound. However, clamping cost is very high, if we are certain x is in the valid range, it is recommended to disable clamping.": "如果您不知道此参数的详细信息，请不要修改此参数！指定 exp prime 模式是否限制下限，仅在使用 exp mode 'prime' 时生效。在计算 x -> exp（x） 时，exp prime 仅对 （（47 - offset - 2fxp）/log_2（e）， （125 - 2fxp - offset）/log_2（e）） 中的 x 有效。如果为 true，则使用低于下限的 clamp 值，否则保持该值不变。下限设置为 （48 - 偏移量 - 2fxp）/log_2 （e）。开启限制将避免在 x <下限时出现较大的数值误差。禁用限制将使值输入保持不变，当 x <下限时，这可能会导致较大的数值误差。但是，限制成本非常高，如果我们确定 x 在有效范围内，建议禁用限制。",
    "exp_prime_higher_bound_clamp": "exp质数方法是否限制上界",
    "If you do not know the details of this parameter, please do not modify this parameter! Specify whether to use upper bound for exp prime mode, only takes effect when using exp mode 'prime'. when calculating x -> exp(x), exp prime is only effective for x in ((47 - offset - 2fxp)/log_2(e), (125 - 2fxp - offset)/log_2(e)). If true, use clamp value above the upper bound, otherwise leave the value unchanged. upper bound is set to be (125 - 2fxp - offset)/log_2(e). Enable clamping will avoid large numerical errors when x > upper bound. Disable clamping will leave the value unchanged, which may cause large numerical errors when x > upper bound. However, clamping cost is very high, if we are certain x is in the valid range, it is recommended to disable clamping.": "如果您不知道此参数的详细信息，请不要修改此参数！指定 exp prime 模式是否限制上限，仅在使用 exp mode 'prime' 时生效。在计算 x -> exp（x） 时，exp prime 仅对 （（47 - offset - 2fxp）/log_2（e）， （125 - 2fxp - offset）/log_2（e）） 中的 x 有效。如果为 true，则使用高于上限的 clamp 值，否则保持值不变。上限设置为 （125 - 2fxp - offset）/log_2（e）。开启限制将避免在 x >上限时出现较大的数值误差。禁用限制将使输入保持不变，当 x >上限时，这可能会导致较大的数值误差。但是，限制成本非常高，如果我们确定 x 在有效范围内，建议禁用限制。",
    "report_weights": "模型报告",
    "If this option is set to true, model will be revealed and model details are visible to all parties": "如果此选项设置为true，模型会被转换到明文，并且模型的详细信息对各方都可见",
    "input_ds": "训练数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be used for training.": "哪些特征应该用于训练",
    "offset": "偏移列",
    "Specify a column to use as the offset": "指定要用作偏移量的列",
    "weight": "权重列",
    "Specify a column to use for the observation weights": "指定用于观测权重的列",
    "label": "标签列",
    "Label of train dataset.": "训练数据集的标签",
    "output_model": "输出模型",
    "Output model.": "输出模型",
    "report": "报告",
    "If report_weights is true, report model details": "如果report_weights为true，则报告模型详细信息"
  },
  "ml.train/ss_sgd_train:1.0.0": {
    "ml.train": "模型训练",
    "ss_sgd_train": "逻辑回归训练",
    "Train both linear and logistic regression\nlinear models for vertical partitioning dataset with mini batch SGD training solver by using secret sharing.\n- SS-SGD is short for secret sharing SGD training.": "训练线性回归和逻辑回归\n使用秘密共享的具有 mini batch SGD 垂直分区数据集的线性模型\n- SS-SGD是秘密共享SGD训练的缩写",
    "1.0.0": "1.0.0",
    "epochs": "迭代次数",
    "The number of complete pass through the training data.": "通过完整训练数据的次数",
    "learning_rate": "学习率",
    "The step size at each iteration in one iteration.": "一次迭代中每次迭代的步长",
    "batch_size": "训练批数据量",
    "The number of training examples utilized in one iteration.": "一次迭代中使用的训练示例数",
    "sig_type": "sigmoid 函数拟合方法",
    "Sigmoid approximation type.": "sigmoid 函数拟合方法",
    "reg_type": "回归类型",
    "Regression type": "回归类型",
    "penalty": "正则化项类型",
    "The penalty(aka regularization term) to be used.": "要使用的penalty（又名正则化项）",
    "l2_norm": "L2正则系数",
    "L2 regularization term.": "L2正则系数",
    "eps": "eps",
    "If the change rate of weights is less than this threshold, the model is considered to be converged, and the training stops early. 0 to disable.": "如果权重的变化率小于此阈值，则认为模型已收敛，训练提前停止；0 表示禁用",
    "report_weights": "模型报告",
    "If this option is set to true, model will be revealed and model details are visible to all parties": "如果此选项设置为true，模型会被转换到明文，并且模型的详细信息对各方都可见",
    "input_ds": "训练数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be used for training.": "哪些特征应该用于训练",
    "label": "标签",
    "Label of train dataset.": "训练数据集的标签",
    "output_model": "输出模型",
    "Output model.": "输出模型",
    "report": "报告",
    "If report_weights is true, report model details": "如果report_weights为true，则报告模型详细信息"
  },
  "ml.train/ss_xgb_train:1.0.0": {
    "ml.train": "模型训练",
    "ss_xgb_train": "SS-XGB训练",
    "This method provides both classification and regression tree boosting (also known as GBDT, GBM)\nfor vertical partitioning dataset setting by using secret sharing.\n- SS-XGB is short for secret sharing XGB.\n- More details: https://arxiv.org/pdf/2005.08479.pdf": "该方法通过使用秘密共享为垂直分割数据集设置提供分类和回归树提升（也称为 GBDT、GBM）\n- SS-XGB是秘密共享XGB的缩写\n- 更多详情： https://arxiv.org/pdf/2005.08479.pdf",
    "1.0.0": "1.0.0",
    "num_boost_round": "训练轮数",
    "Number of boosting iterations.": "Boosting迭代次数",
    "max_depth": "最大深度",
    "Maximum depth of a tree.": "树的最大深度",
    "learning_rate": "学习率",
    "Step size shrinkage used in updates to prevent overfitting.": "更新中使用的步长收缩以防止过度拟合",
    "objective": "目的",
    "Specify the learning objective.": "指定学习目标",
    "reg_lambda": "叶子节点权重L2正则项",
    "L2 regularization term on weights.": "权重的 L2 正则化项",
    "subsample": "子样本比率",
    "Subsample ratio of the training instances.": "训练实例的子样本比率",
    "colsample_by_tree": "每棵树子样本比率",
    "Subsample ratio of columns when constructing each tree.": "构造每棵树时列的子样本比率",
    "sketch_eps": "分裂系数",
    "This roughly translates into O(1 / sketch_eps) number of bins.": "箱数大致为 O（1 / sketch_eps） 个",
    "base_score": "初始预测分数",
    "The initial prediction score of all instances, global bias.": "所有实例的初始预测分数，全局偏差",
    "seed": "种子",
    "Pseudorandom number generator seed.": "伪随机数生成器种子",
    "input_ds": "训练数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be used for training.": "哪些特征应该用于训练",
    "label": "标签",
    "Label of train dataset.": "训练数据集的标签",
    "output_model": "输出模型",
    "Output model.": "输出模型"
  },
  "model/model_export:1.0.0": {
    "model": "模型",
    "model_export": "模型导出",
    "The model_export component supports converting and\npackaging the rule files generated by preprocessing and\npostprocessing components, as well as the model files generated\nby model operators, into a Secretflow-Serving model package. The\nlist of components to be exported must contain exactly one model\ntrain or model predict component, and may include zero or\nmultiple preprocessing and postprocessing components.": "model_export组件支持转换和\n打包预处理生成的规则文件\n后处理组件以及生成的模型文件\n由模型运算符将其转换为Secretflow Serving模型包。这个\n要导出的组件列表必须只包含一个模型\n训练或模型预测组件，可能包括零或\n多个预处理和后处理组件。",
    "1.0.0": "1.0.0",
    "model_name": "模型名称",
    "model's name": "模型名称",
    "model_desc": "模型描述",
    "Describe what the model does": "描述模型的作用",
    "input_datasets": "输入数据集",
    "The input data IDs for all components to be exported. Their order must remain consistent with the sequence in which the components were executed.": "待导出的所有组件的输入数据ID。其顺序必须与执行组件的顺序保持一致。",
    "output_datasets": "输出数据集",
    "The output data IDs for all components to be exported. Their order must remain consistent with the sequence in which the components were executed.": "待导出的所有组件的输出数据ID。其顺序必须与执行组件的顺序保持一致。",
    "component_eval_params": "组件执行参数",
    "The eval parameters (in JSON format) for all components to be exported. Their order must remain consistent with the sequence in which the components were executed.": "待导出的所有组件的eval参数（JSON格式）。其顺序必须与执行组件的顺序保持一致。",
    "he_mode": "HE模式",
    "If enabled, it will export a homomorphic encryption model. Currently, only SGD and GLM models for two-party scenarios are supported.": "开启后，导出同态加密的模型，当前仅支持2方场景的sgd以及glm模型",
    "output_package": "打包输出",
    "output tar package uri": "输出tar包的uri",
    "report": "报告",
    "report dumped model's input schemas": "报表转储模型的输入架构"
  },
  "postprocessing/score_card_transformer:1.0.0": {
    "postprocessing": "后处理",
    "score_card_transformer": "评分卡转换",
    "Transform the predicted result (a probability value) produced by the logistic regression model into a more understandable score (for example, a score of up to 1000 points)": "将逻辑回归模型产出的预测值结果（一个概率值）转化为一个更易理解的分数（比如最高为1000分的评分）",
    "1.0.0": "1.0.0",
    "positive": "positive标签值",
    "Value for positive cases.": "positive为正例值",
    "predict_score_name": "转换后列名",
    "": "",
    "scaled_value": "scaledValue",
    "Set a benchmark score that can be adjusted for specific business scenarios": "设定一个基准分数，可根据具体的业务场景调整",
    "odd_base": "odds",
    "the odds value at given score baseline, odds = p / (1-p)": "在给定的分数基准点处的odds值，odds = p / (1-p)",
    "pdo": "pdo",
    "points to double the odds": "全名points to double the odds，指odds值翻倍时，分数的变化量",
    "min_score": "minscore",
    "An integer of [0,999] is supported": "支持输入[0,999]的整数",
    "max_score": "maxscore",
    "An integer of [1,1000] is supported": "支持输入[1,1000]的整数",
    "input_ds": "输入表",
    "predict result table": "预测结果表",
    "predict_name": "预测结果列名",
    "output_ds": "输出表",
    "output table": "输出表"
  },
  "preprocessing/binary_op:1.0.0": {
    "preprocessing": "预处理",
    "binary_op": "二元操作",
    "Perform binary operation binary_op(f1, f2) and assign the result to f3, f3 can be new or old. Currently f1, f2 and f3 all belong to a single party.": "执行二元操作 binary_op(f1, f2) 并将结果分配给 f3，f3 可以是新的或旧的。目前 f1、f2 和 f3 都属于同一个方。",
    "1.0.0": "1.0.0",
    "What kind of binary operation we want to do, currently only supports +, -, *, /": "我们想要进行何种二元操作，目前仅支持 +、-、*、/",
    "new_feature_name": "新特征名称",
    "Name of the newly generated feature.": "新生成特征的名称。",
    "as_label": "作为标签",
    "If True, the generated feature will be marked as label in schema.": "如果为 True，则生成的特征将在模式中标记为标签。",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表。",
    "f1": "特征1",
    "Feature 1 to operate on.": "要操作的特征1。",
    "f2": "特征2",
    "Feature 2 to operate on.": "要操作的特征2。",
    "output_ds": "输出数据集",
    "Output vertical table.": "输出联合表。",
    "output_rule": "输出规则",
    "feature gen rule": "特征生成规则"
  },
  "preprocessing/case_when:1.0.0": {
    "preprocessing": "预处理",
    "case_when": "交叉决策",
    "1.0.0": "1.0.0",
    "rules": "规则",
    "input CaseWhen rules": "输入交叉决策规则",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "output_ds": "输出数据集",
    "output_dataset": "输出数据集",
    "output_rule": "输出规则",
    "case when substitution rule": "预处理替换规则"
  },
  "preprocessing/cast:1.0.0": {
    "preprocessing": "预处理",
    "cast": "类型转换",
    "For conversion between basic data types, such as converting float to string.": "用于基本数据类型之间的转换，例如将浮点转换为字符串。",
    "1.0.0": "1.0.0",
    "astype": "转换后类型",
    "single-choice, options available are string, integer, float": "单选，可选择string、integer、float",
    "integer": "integer",
    "float": "float",
    "string": "string",
    "input_ds": "输入表",
    "The input table": "输入表",
    "columns": "待转换特征列",
    "Multiple-choice, options available are string, integer, float, boolean": "多选，可选择不同类型，包括string、integer、float、boolean",
    "output_ds": "输出表",
    "The output table": "输出表",
    "output_rule": "输出规则",
    "The output rules": "类型转换规则"
  },
  "preprocessing/feature_calculate:1.0.0": {
    "preprocessing": "预处理",
    "feature_calculate": "特征计算",
    "Generate a new feature by performing calculations on an origin feature": "对原特征进行操作生成新特征",
    "1.0.0": "1.0.0",
    "rules": "规则",
    "input CalculateOpRules rules": "输入特征计算规则",
    "input_ds": "输入数据集",
    "Input vertical table": "输入联合表",
    "features": "特征列",
    "Feature(s) to operate on": "要操作的特征列",
    "output_ds": "输出数据集",
    "output_dataset": "输出数据集",
    "output_rule": "输出规则",
    "feature calculate rule": "特征计算规则"
  },
  "preprocessing/fillna:1.0.0": {
    "preprocessing": "预处理",
    "fillna": "异常值填充",
    "Fill null/nan or other specificed outliers in dataset": "替换数据集集中的空值和异常值",
    "1.0.0": "1.0.0",
    "nan_is_null": "将浮点数中的nan当作空值",
    "Whether floating-point NaN values are considered null, take effect with float columns": "是否将浮点数中的nan当作空值，只对浮点数列生效",
    "float_outliers": "浮点列异常值",
    "These outlier value are considered null, take effect with float columns": "这些异常值被视为空值，只对浮点数列生效",
    "int_outliers": "整型列异常值",
    "These outlier value are considered null, take effect with int columns": "这些异常值被视为空值，只对整型数列生效",
    "str_outliers": "字符列异常值",
    "These outlier value are considered null, take effect with str columns": "这些异常值被视为空值，只对字符类型列生效",
    "str_fill_strategy": "字符列替换策略",
    "Replacement strategy for str column. If \"most_frequent\", then replace missing using the most frequent value along each column. If \"constant\", then replace missing values with fill_value_str.": "str列的替换策略。如果为“most_frequency”，则使用每列中最频繁的值替换空值。如果为“常量”，则用fill_value_str参数指定的值替换空值。",
    "fill_value_str": "字符列填充值",
    "For str type data. If method is 'constant' use this value for filling null.": "对于str类型的数据。如果方法是“常量”，请使用此值来填充null。",
    "int_fill_strategy": "整型列替换策略",
    "Replacement strategy for int column. If \"mean\", then replace missing values using the mean along each column. If \"median\", then replace missing values using the median along each column If \"most_frequent\", then replace missing using the most frequent value along each column. If \"constant\", then replace missing values with fill_value_int.": "int列的替换策略。如果为“平均值”，则使用每列的平均值替换缺失的值。如果为“中位数”，则使用每列的中位数替换缺失值。如果为“most_frequency”，则用每列的最频繁值替换缺失值。如果为“常量”，则用fill_value_int替换缺失的值。",
    "fill_value_int": "整型列填充值",
    "For int type data. If method is 'constant' use this value for filling null.": "对于int类型的数据。如果方法是“常量”，请使用此值来填充null。",
    "float_fill_strategy": "浮点列替换策略",
    "Replacement strategy for float column. If \"mean\", then replace missing values using the mean along each column. If \"median\", then replace missing values using the median along each column If \"most_frequent\", then replace missing using the most frequent value along each column. If \"constant\", then replace missing values with fill_value_float.": "浮子柱的更换策略。如果为“平均值”，则使用每列的平均值替换缺失的值。如果为“中位数”，则使用每列的中位数替换缺失值如果为“most_frequency”，则用每列的最频繁值替换缺失值。如果为“常量”，则用fill_value_float替换缺失的值。",
    "fill_value_float": "浮点列填充值",
    "For float type data. If method is 'constant' use this value for filling null.": "用于浮点型数据。如果方法是“常量”，请使用此值来填充null。",
    "bool_fill_strategy": "布尔列替换策略",
    "Replacement strategy for bool column. If \"most_frequent\", then replace missing using the most frequent value along each column. If \"constant\", then replace missing values with fill_value_bool.": "布尔列的替换策略。如果为“most_frequency”，则使用每列中最频繁的值替换缺失的值。如果为“常量”，则用fill_value_bool替换缺失的值。",
    "fill_value_bool": "布尔列填充值",
    "For bool type data. If method is 'constant' use this value for filling null.": "对于布尔类型数据。如果方法是“常量”，请使用此值来填充null。",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表。",
    "fill_na_features": "需要替换的列",
    "Features to fill.": "需要替换的列",
    "output_ds": "输出数据集",
    "Output vertical table.": "输出联合表。",
    "output_rule": "输出规则",
    "fill value rule": "填充值规则"
  },
  "preprocessing/onehot_encode:1.0.0": {
    "preprocessing": "预处理",
    "onehot_encode": "onehot_encode",
    "1.0.0": "1.0.0",
    "drop": "丢弃",
    "drop unwanted category based on selection": "onehot编码在丢弃一个枚举值的时候，才可满秩，可选择是否丢弃或者丢弃哪一个枚举值",
    "no_drop": "不丢弃",
    "do not drop": "不丢弃",
    "first": "丢弃第一列",
    "drop the first category in each feature.": "删除每个特征中的第一个类别。",
    "mode": "丢弃众数",
    "drop the mode category in each feature": "删除每个特征中的众数。",
    "min_frequency": "最小频率",
    "Specifies the minimum frequency below which a category will be considered infrequent, [0, 1), 0 disable": "指定类别将被视为不频繁的最低频率，[0，1），0禁用",
    "report_rules": "报告规则",
    "Whether to report rule details": "是否报告规则详细信息",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表。",
    "features": "特征列",
    "Features to encode.": "要编码的功能。",
    "output_ds": "输出数据集",
    "output dataset": "输出数据集",
    "output_rule": "输出规则",
    "onehot rule": "onehot规则",
    "report": "报告",
    "report rules details if report_rules is true": "如果report_rules为true，则报告规则详细信息"
  },
  "preprocessing/sql_processor:1.0.0": {
    "preprocessing": "预处理",
    "sql_processor": "SQL特征工程处理",
    "sql processor": "SQL特征工程处理",
    "1.0.0": "1.0.0",
    "sql": "SQL",
    "sql for preprocessing, for example SELECT a, b, a+b": "用于特征工程处理的sql表达式，例如 SELECT a、b、a+b",
    "input_ds": "input_ds",
    "Input table": "输入表",
    "output_ds": "output_ds",
    "Output table": "输出表",
    "output_rule": "output_rule",
    "Output rule": "输出规则"
  },
  "preprocessing/substitution:1.0.0": {
    "preprocessing": "预处理",
    "substitution": "特征工程应用",
    "unified substitution component": "统一的特征工程规则应用组件",
    "1.0.0": "1.0.0",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表。",
    "input_rule": "输入规则",
    "Input preprocessing rules": "输入预处理规则",
    "output_ds": "输出数据集",
    "output_dataset": "输出数据集"
  },
  "preprocessing/vert_binning:1.0.0": {
    "preprocessing": "预处理",
    "vert_binning": "常规分箱",
    "Generate equal frequency or equal range binning rules for vertical partitioning datasets.": "为垂直分区数据集生成等频或等距分箱规则",
    "1.0.0": "1.0.0",
    "binning_method": "分箱方式",
    "How to bin features with numeric types: \"quantile\"(equal frequency)/\"eq_range\"(equal range)": "如何对特征进行分箱：“quantile”（等频）/“eq_range”（等距）",
    "bin_num": "bin_num",
    "Max bin counts for one features.": "一个特征的最大分箱数",
    "report_rules": "报告规则",
    "Whether report binning rules.": "是否有报表装箱规则。",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be binned.": "应对哪些特征进行分箱",
    "output_ds": "输出数据集",
    "Output vertical table.": "输出联合表",
    "output_rule": "分箱规则",
    "Output bin rule.": "输出分箱规则",
    "report": "报告",
    "report rules details if report_rules is true": "如果report_rules为true，则报告规则详细信息"
  },
  "preprocessing/vert_woe_binning:1.0.0": {
    "preprocessing": "预处理",
    "vert_woe_binning": "WOE分箱",
    "Generate Weight of Evidence (WOE) binning rules for vertical partitioning datasets.": "为垂直分割数据集生成 Weight of Evidence （WOE） 分箱规则",
    "1.0.0": "1.0.0",
    "secure_device_type": "安全设备类型",
    "Use SPU(Secure multi-party computation or MPC) or HEU(Homomorphic encryption or HE) to secure bucket summation.": "使用 SPU（安全多方计算, MPC）或 HEU（同态加密, HE）来保护桶求和",
    "binning_method": "分箱方式",
    "How to bin features with numeric types: \"quantile\"(equal frequency)/\"chimerge\"(ChiMerge from AAAI92-019: https://www.aaai.org/Papers/AAAI/1992/AAAI92-019.pdf)/\"eq_range\"(equal range)": "如何使用数值类型对特征进行分箱：“分位数”（等频）/“chimerge”（来自 AAAI92-019 的 ChiMerge：https://www.aaai.org/Papers/AAAI/1992/AAAI92-019.pdf）/“等宽”（等宽分箱）",
    "bin_num": "分箱个数",
    "Max bin counts for one features.": "一个特征的最大分箱数",
    "positive_label": "正值标签",
    "Which value represent positive value in label.": "哪个值表示标签中的正值",
    "chimerge_init_bins": "chimerge初始分箱数",
    "Max bin counts for initialization binning in ChiMerge.": "在 ChiMerge 中初始化分箱的最大分箱数",
    "chimerge_target_bins": "chimerge目标分箱数",
    "Stop merging if remaining bin counts is less than or equal to this value.": "在 ChiMerge 中如果剩余箱计数小于或等于此值，则停止合并",
    "chimerge_target_pvalue": "chimerge目标 p-value 值",
    "Stop merging if biggest pvalue of remaining bins is greater than this value.": "在 ChiMerge 中如果剩余分箱的最大 p-value 大于此值，则停止合并",
    "report_rules": "报告规则",
    "Whether report binning rules.": "是否有报表装箱规则。",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "which features should be binned. WARNING: WOE won't be effective for features with enumeration count <=2.": "应对哪些特征进行分箱。警告: WOE 对于枚举计数 <=2 的特征无效",
    "label": "标签",
    "Label of input data.": "输入数据的标签",
    "output_ds": "输出数据集",
    "Output vertical table.": "输出联合表",
    "output_rule": "分箱规则",
    "Output WOE rule.": "输出 WOE 规则",
    "report": "报告",
    "report rules details if report_rules is true": "如果report_rules为true，则报告规则详细信息"
  },
  "stats/groupby_statistics:1.0.0": {
    "stats": "统计",
    "groupby_statistics": "分组统计",
    "Get a groupby of statistics, like pandas groupby statistics.\nCurrently only support VDataframe.": "获取分组统计信息，参考pandas的分组统计。\n目前仅支持 VDataframe。",
    "1.0.0": "1.0.0",
    "aggregation_config": "聚合配置",
    "input groupby aggregation config": "输入聚合配置",
    "max_group_size": "最大组数",
    "The maximum number of groups allowed": "允许的最大组数",
    "input_ds": "输入数据集",
    "Input table.": "输入表",
    "by": "特征列",
    "by what columns should we group the values": "我们应该按哪些列进行分组",
    "report": "报告",
    "Output groupby statistics report.": "输出分组统计信息报告"
  },
  "stats/ss_pearsonr:1.0.0": {
    "stats": "统计",
    "ss_pearsonr": "相关系数矩阵",
    "Calculate Pearson's product-moment correlation coefficient for vertical partitioning dataset\nby using secret sharing.\n- For large dataset(large than 10w samples & 200 features), recommend to use [Ring size: 128, Fxp: 40] options for SPU device.": "通过使用秘密共享计算垂直分区数据集的皮尔逊乘积矩相关系数\n- 对于大型数据集（大于10w样本和200个特征），建议使用SPU设备的[Ring size：128，Fxp：40]选项",
    "1.0.0": "1.0.0",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "Specify which features to calculate correlation coefficient with. If empty, all features will be used": "指定要计算相关系数的特征；如果为空，则将使用所有特征",
    "report": "报告",
    "Output Pearson's product-moment correlation coefficient report.": "输出相关系数矩阵表"
  },
  "stats/ss_vif:1.0.0": {
    "stats": "统计",
    "ss_vif": "VIF指标计算",
    "Calculate Variance Inflation Factor(VIF) for vertical partitioning dataset\nby using secret sharing.\n- For large dataset(large than 10w samples & 200 features), recommend to use [Ring size: 128, Fxp: 40] options for SPU device.": "通过使用秘密共享计算垂直分区数据集的方差膨胀因子 （VIF）\n- 对于大型数据集（大于10w样本和200个特征），建议使用SPU设备的[Ring size：128，Fxp：40]选项",
    "1.0.0": "1.0.0",
    "input_ds": "输入数据集",
    "Input vertical table.": "输入联合表",
    "feature_selects": "特征列",
    "Specify which features to calculate VIF with. If empty, all features will be used.": "指定要用于计算 VIF 的特征；如果为空，则将使用所有特征",
    "report": "报告",
    "Output Variance Inflation Factor(VIF) report.": "输出VIF指标计算结果表"
  },
  "stats/stats_psi:1.0.0": {
    "stats": "统计",
    "stats_psi": "群体稳定性",
    "population stability index.": "Population Stability Index，根据基准列和测试列，计算特征的稳定性",
    "1.0.0": "1.0.0",
    "input_base_ds": "输入基准数据",
    "Input base vertical table.": "输入基准表",
    "feature_selects": "特征选择",
    "which features should be binned.": "分箱依赖的特征",
    "input_test_ds": "输入测试数据",
    "Input test vertical table.": "输入测试表",
    "input_rule": "分箱规则",
    "Input bin rule.": "输入分箱规则",
    "report": "报告",
    "Output population stability index.": "输出群体稳定性指数"
  },
  "stats/table_statistics:1.0.0": {
    "stats": "统计",
    "table_statistics": "全表统计",
    "Get a table of statistics,\nincluding each column's\n1. datatype\n2. total_count\n3. count\n4. count_na\n5. na_ratio\n6. min\n7. max\n8. mean\n9. var\n10. std\n11. sem\n12. skewness\n13. kurtosis\n14. q1\n15. q2\n16. q3\n17. moment_2\n18. moment_3\n19. moment_4\n20. central_moment_2\n21. central_moment_3\n22. central_moment_4\n23. sum\n24. sum_2\n25. sum_3\n26. sum_4\n- moment_2 means E[X^2].\n- central_moment_2 means E[(X - mean(X))^2].\n- sum_2 means sum(X^2).": "获取一个统计表，\n包括每列的\n1. datatype（数据类型）\n2. total_count（总数）\n3.count（非nan总数）\n4.count_na（nan总数）\n5.na_ratio（nan比例）\n6.min\n7.max\n8.mean\n9.var\n10.std\n11.sem(standard error of the mean)\n12.skewness(偏度)\n13.kurtosis(峰度)\n14.q1(分位数)\n15.q2\n16.q3\n17.moment_2\n18.moment_3\n19.moment_4\n20.central_ment_2\n21.central_ment_3\n22.central_ment_4\n23.sum\n24.sum_2\n25.sum_3\n26.sum_4\n-moment_2 表示 E[X^2]。\n-central_ment_2 表示 E[(X - mean(X))^2]。\n-sum_2表示 sum(X^2)。",
    "1.0.0": "1.0.0",
    "input_ds": "输入数据集",
    "Input table.": "输入表",
    "features": "特征",
    "perform statistics on these columns": "对这些列执行统计",
    "report": "报告",
    "Output table statistics report.": "输出全表统计结果表"
  }
}
