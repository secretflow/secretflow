# application configurations.
applications:
  # enable auto tune or not.
  enable_tune: true
  # which dataset to run (all/bank/cifar10/[bank, drive, ...]/...)
  dataset: all
  # which model to run (all/dnn/deepfm/[dnn,vgg16,...]/...)
  model: all
  # which attack to run (all/lia/fia/[no_attack,lia,...]/...)
  attack: all
  # which defenses to run (all/grad_avg/[no_defense,mid,mixup,...]/...)
  defense: all
  # whether to run a simple test with small dataset and small epoch.
  simple: false
  # whether to use gpu to accelerate.
  use_gpu: false
  # whether using debug mode to run sf or not
  debug_mode: true
  # a random seed can be set to achieve reproducibility
  random_seed: ~
# path configurations.
paths:
  # the dataset store path, you can put the datasets here, or will auto download.
  datasets: ~
  # the autoattack result store path.
  autoattack_path: ~

# Resources configurations.
# Only needed when using sim mode and need to indicate the cpu/gpu nums manually.
resources:
  # The names and memory capacities of all GPUs included in your cluster.
  gpu:
    # Suppose you have an 'V100' GPU with 4GB
    V100: 4000000000 # 4GB

# When there are multiple ray clusters in your machine, specify one to connect.
ray:
  # the existing ray cluster's address for connection (ip:port), default to None.
  address: ~

# tuner parameters
tune:
  applications:
    creditcard:
      dnn:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 28, 64 ]
        alice_feature_nums_range: [ 25 ]
        dnn_base_units_size_range_alice: [ [ -0.5, -1 ],[ -1 ],[ -0.5, -1, -1 ], ]
        dnn_base_units_size_range_bob: [ [ 4 ] ]
        dnn_fuse_units_size_range: [ [ 1 ],[ -1, -1, 1 ], ]
        dnn_embedding_dim_range: ~
    bank:
      dnn:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 32, 64 ]
        alice_feature_nums_range: [ 9, 1, 5, 10, 15 ]
        dnn_base_units_size_range_alice: [ [ 128, -1 ], [ -1 ], ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 1 ], [ 128, 1 ] ]
      deepfm:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 32, 64 ]
        alice_feature_nums_range: [ 9, 1, 5, 10, 15 ]
        dnn_base_units_size_range_alice: [ [ 128, -1 ], [ 128, 128, -1 ], [ -1 ], ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 64 ], [ 64, 64 ] ]
        deepfm_embedding_dim_range: [ 8, 16 ]
    drive:
      dnn:
        train_batch_size: [ 64, 128 ]
        alice_feature_nums_range: [ 28 ]
    movielens:
      dnn:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 64, 128 ]
        alice_feature_nums_range: [ 1, 2, 3, 4, 5 ]
        dnn_base_units_size_range_alice: [ [ 256, -1 ], [ 256, 128, -1 ] ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 1 ], [ 256, 128, 1 ] ]
        dnn_embedding_dim_range: [ 8 ]
      deepfm:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 64 ]
        alice_feature_nums_range: [ 1, 2, 3, 4, 5 ]
        dnn_base_units_size_range_alice: [ [ -1 ], [ 256, -1 ], [ 256, 128, -1 ] ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 256, 32 ], [ 256, 256, 32 ] ]
        deepfm_embedding_dim_range: [ 4 ]
    criteo:
      dnn:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 32, 64 ]
        alice_feature_nums_range: [ 2, 5, 13, 18, 37 ]
        dnn_base_units_size_range_alice: [ [ 200, 100, -1 ], [ -1 ] ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 64, 1 ] ]
        dnn_embedding_dim_range: [ 16 ]
      deepfm:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 32, 64 ]
        alice_feature_nums_range: [ 2, 5, 13, 18, 37 ]
        dnn_base_units_size_range_alice: [ [ 256, 128, -1 ], [ 256, -1 ],[ -1 ], ]
        dnn_base_units_size_range_bob: ~
        dnn_fuse_units_size_range: [ [ 64 ], [ 64, 64 ] ]
        deepfm_embedding_dim_range: [ 8, 16 ]
    mnist:
      vgg16:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 4608 ]
        # 3 * vgg_resize * vgg_resize // 2
        alice_feature_nums_range: [ 18816 ]
        # 512 * 3 * 3 * 2 = 9216
        dnn_fuse_units_size_range: [ [ 9216, 4096 ],
                                     [ 9216, 4096, 4096 ],
                                     [ 9216, 4096, 4096, 4096 ],
                                     [ 9216, 4096, 4096, 4096, 4096 ], ]
      resnet18:
        train_batch_size: [ 64, 128 ]
        hidden_size_range: [ 512 ]
        # 1 * 28 * 14
        alice_feature_nums_range: [ 392 ]
        # 512 * 2 = 1024
        dnn_fuse_units_size_range: [ [ 1024 ],
                                     [ 1024, 512 ], ]
    cifar10:
      vgg16:
        train_batch_size: [ 64, 128 ]
        # 32 * 16 * 3 = 1536
        alice_feature_nums_range: [ 1536 ]
        # 512 * 3 * 3 * 2 = 9216
        dnn_fuse_units_size_range: [ [ 9216, 4096 ],
                                     [ 9216, 4096, 4096 ],
                                     [ 9216, 4096, 4096, 4096 ],
                                     [ 9216, 4096, 4096, 4096, 4096 ], ]
      resnet18:
        train_batch_size: [ 64, 128 ]
        # 1 * 28 * 14
        alice_feature_nums_range: [ 1536 ]
        # 512 * 2 = 1024
        dnn_fuse_units_size_range: [ [ 1024 ],
                                     [ 1024, 512 ] ]
      resnet20:
        train_batch_size: [ 64, 128 ]
        # 32 * 16 * 3 = 1536
        alice_feature_nums_range: [ 1536 ]
      cnn:
        train_batch_size: [ 64, 128 ]
        # 32 * 16 * 3 = 1536
        alice_feature_nums_range: [ 1536 ]
  attacks:
    norm: ~
    exploit:
      alpha_acc: [ 0.8,1 ] # 0 - 1
      alpha_grad: [ 0.01,0.1 ] # 0 -1  log
      alpha_kl: [ 0.01,0.1 ] # 0-1
    fia:
      # attack_epochs: [2,5] # < 120
      optim_lr: [ 0.001, 0.0001 ]
    fsha:
      ~
    grad_lia:
      ~
    lia:
      T: [ 0.7, 0.8 ]  # near 0.8
      alpha: [ 0.9, 0.999 ]  # (0,1) near 0.9
      lr: [ 0.00002, 0.002 ]
      ema_decay: [ 0.8, 0.999 ]
      lambda_u: [ 40, 60 ]  # 40 - 60
    replace:
      # blurred does not support embedding layer, so shutdown,
      # blurred: [true,false]
      gamma: [ 10,30 ] # 1 - 20
    replay:
      target_nums: [ 50,100 ]
    batch_lia:
      lr: [ 0.001,0.01,0.1 ]
  defenses:
    de_identification:
      subset_num: [ 3,5,7 ]
    grad_avg:
      ~
    mixup:
      lam: [ 0.4,0.5,0.6 ]
    mid:
      ~
    fed_pass: ~
    cae: ~